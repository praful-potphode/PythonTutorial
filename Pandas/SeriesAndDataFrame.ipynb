{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is a Series?\n",
    "Technically, Pandas Series is a one-dimensional labeled array capable of holding any data type.\n",
    "In layman terms, Pandas Series is nothing but a column in an excel sheet. As depicted in the picture below, columns with Name, Age and Designation representing a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    3\n",
      "2    4\n",
      "3    5\n",
      "4    6\n",
      "5    2\n",
      "6    9\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "# Program to Create series with scalar values  \n",
    "Data =[1, 3, 4, 5, 6, 2, 9]  # Numeric data \n",
    "  \n",
    "# Creating series with default index values \n",
    "s = pd.Series(Data)     \n",
    "print(s, end='\\n')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    3\n",
      "c    4\n",
      "d    5\n",
      "e    6\n",
      "f    2\n",
      "g    9\n",
      "dtype: int64,"
     ]
    }
   ],
   "source": [
    "# predefined index values \n",
    "Index =['a', 'b', 'c', 'd', 'e', 'f', 'g']  \n",
    "  \n",
    "# Creating series with predefined index values \n",
    "si = pd.Series(Data, Index) \n",
    "print(si, end=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "d    4\n",
      "e    5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "# Program to Create Dictionary series \n",
    "dictionary ={'a':1, 'b':2, 'c':3, 'd':4, 'e':5}  \n",
    "  \n",
    "# Creating series of Dictionary type \n",
    "sd = pd.Series(dictionary)  \n",
    "print(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [2, 3, 4]\n",
      "1    [5, 6, 7]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "# Program to Create ndarray series \n",
    "Data =[[2, 3, 4], [5, 6, 7]] # Defining 2darray \n",
    "\n",
    "# Creating series of 2darray \n",
    "snd = pd.Series(Data)\t \n",
    "print(snd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   first  second\n",
      "a    1.0       5\n",
      "b    2.0       6\n",
      "c    3.0       7\n",
      "d    4.0       8\n",
      "e    NaN       9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "# Program to Create Data Frame with two dictionaries \n",
    "dict1 ={'a':1, 'b':2, 'c':3, 'd':4}\t # Define Dictionary 1 \n",
    "dict2 ={'a':5, 'b':6, 'c':7, 'd':8, 'e':9} # Define Dictionary 2 \n",
    "Data = {'first':dict1, 'second':dict2} # Define Data with dict1 and dict2 \n",
    "df = pd.DataFrame(Data) # Create DataFrame \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>designation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>First -&gt;</th>\n",
       "      <td>a</td>\n",
       "      <td>10</td>\n",
       "      <td>CEO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Second -&gt;</th>\n",
       "      <td>b</td>\n",
       "      <td>20</td>\n",
       "      <td>VP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Third -&gt;</th>\n",
       "      <td>c</td>\n",
       "      <td>30</td>\n",
       "      <td>SVP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fourth -&gt;</th>\n",
       "      <td>d</td>\n",
       "      <td>40</td>\n",
       "      <td>AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fifth -&gt;</th>\n",
       "      <td>e</td>\n",
       "      <td>50</td>\n",
       "      <td>DEV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name  age designation\n",
       "First ->      a   10         CEO\n",
       "Second ->     b   20          VP\n",
       "Third ->      c   30         SVP\n",
       "Fourth ->     d   40          AM\n",
       "Fifth ->      e   50         DEV"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dict = { \n",
    "'name' : [\"a\", \"b\", \"c\", \"d\", \"e\"],\n",
    "'age' : [10,20, 30, 40, 50],\n",
    "'designation': [\"CEO\", \"VP\", \"SVP\", \"AM\", \"DEV\"]\n",
    "}\n",
    "df = pd.DataFrame( my_dict, \n",
    "index = [\n",
    "\"First -> \",\n",
    "\"Second -> \", \n",
    "\"Third -> \", \n",
    "\"Fourth -> \", \n",
    "\"Fifth -> \"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(First ->      a\n",
       " Second ->     b\n",
       " Third ->      c\n",
       " Fourth ->     d\n",
       " Fifth ->      e\n",
       " Name: name, dtype: object,\n",
       " First ->      10\n",
       " Second ->     20\n",
       " Third ->      30\n",
       " Fourth ->     40\n",
       " Fifth ->      50\n",
       " Name: age, dtype: int64,\n",
       " First ->      CEO\n",
       " Second ->      VP\n",
       " Third ->      SVP\n",
       " Fourth ->      AM\n",
       " Fifth ->      DEV\n",
       " Name: designation, dtype: object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_name = df.name\n",
    "series_age = df.age\n",
    "series_designation = df.designation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "First ->      a\n",
       "Second ->     b\n",
       "Third ->      c\n",
       "Fourth ->     d\n",
       "Fifth ->      e\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "First ->      10\n",
       "Second ->     20\n",
       "Third ->      30\n",
       "Fourth ->     40\n",
       "Fifth ->      50\n",
       "Name: age, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "First ->      CEO\n",
       "Second ->      VP\n",
       "Third ->      SVP\n",
       "Fourth ->      AM\n",
       "Fifth ->      DEV\n",
       "Name: designation, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_designation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First -&gt;</th>\n",
       "      <th>Second -&gt;</th>\n",
       "      <th>Third -&gt;</th>\n",
       "      <th>Fourth -&gt;</th>\n",
       "      <th>Fifth -&gt;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     First ->  Second ->  Third ->  Fourth ->  Fifth -> \n",
       "name         a          b         c          d         e\n",
       "age         10         20        30         40        50"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_from_series = pd.DataFrame([series_name, series_age])\n",
    "df_from_series\n",
    "# the row indexes of Series become the column while the columns become the row index value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>First -&gt;</th>\n",
       "      <td>a</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Second -&gt;</th>\n",
       "      <td>b</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Third -&gt;</th>\n",
       "      <td>c</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fourth -&gt;</th>\n",
       "      <td>d</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fifth -&gt;</th>\n",
       "      <td>e</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name age\n",
       "First ->      a  10\n",
       "Second ->     b  20\n",
       "Third ->      c  30\n",
       "Fourth ->     d  40\n",
       "Fifth ->      e  50"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_from_series.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First -&gt;</th>\n",
       "      <th>Second -&gt;</th>\n",
       "      <th>Third -&gt;</th>\n",
       "      <th>Fourth -&gt;</th>\n",
       "      <th>Fifth -&gt;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     First ->  Second ->  Third ->  Fourth ->  Fifth -> \n",
       "name         a          b         c          d         e"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is true even if we provide a single Series to create a DataFrame\n",
    "df_from_series_single = pd.DataFrame([series_name])\n",
    "df_from_series_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the mean of a Series\n",
    "series_age.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the size of the Series\n",
    "series_age.size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CEO', 'VP', 'SVP', 'AM', 'DEV'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Getting all unique items in a series\n",
    "series_designation.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c', 'd', 'e']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting a python list out of a Series\n",
    "series_name.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Series in module pandas.core.series object:\n",
      "\n",
      "class Series(pandas.core.base.IndexOpsMixin, pandas.core.generic.NDFrame)\n",
      " |  Series(data=None, index=None, dtype=None, name=None, copy=False, fastpath=False)\n",
      " |  \n",
      " |  One-dimensional ndarray with axis labels (including time series).\n",
      " |  \n",
      " |  Labels need not be unique but must be a hashable type. The object\n",
      " |  supports both integer- and label-based indexing and provides a host of\n",
      " |  methods for performing operations involving the index. Statistical\n",
      " |  methods from ndarray have been overridden to automatically exclude\n",
      " |  missing data (currently represented as NaN).\n",
      " |  \n",
      " |  Operations between Series (+, -, /, *, **) align values based on their\n",
      " |  associated index values-- they need not be the same length. The result\n",
      " |  index will be the sorted union of the two indexes.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  data : array-like, Iterable, dict, or scalar value\n",
      " |      Contains data stored in Series.\n",
      " |  \n",
      " |      .. versionchanged:: 0.23.0\n",
      " |         If data is a dict, argument order is maintained for Python 3.6\n",
      " |         and later.\n",
      " |  \n",
      " |  index : array-like or Index (1d)\n",
      " |      Values must be hashable and have the same length as `data`.\n",
      " |      Non-unique index values are allowed. Will default to\n",
      " |      RangeIndex (0, 1, 2, ..., n) if not provided. If both a dict and index\n",
      " |      sequence are used, the index will override the keys found in the\n",
      " |      dict.\n",
      " |  dtype : str, numpy.dtype, or ExtensionDtype, optional\n",
      " |      Data type for the output Series. If not specified, this will be\n",
      " |      inferred from `data`.\n",
      " |      See the :ref:`user guide <basics.dtypes>` for more usages.\n",
      " |  name : str, optional\n",
      " |      The name to give to the Series.\n",
      " |  copy : bool, default False\n",
      " |      Copy input data.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Series\n",
      " |      pandas.core.base.IndexOpsMixin\n",
      " |      pandas.core.generic.NDFrame\n",
      " |      pandas.core.base.PandasObject\n",
      " |      pandas.core.accessor.DirNamesMixin\n",
      " |      pandas.core.base.SelectionMixin\n",
      " |      pandas.core.indexing.IndexingMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __add__(left, right)\n",
      " |  \n",
      " |  __and__(self, other)\n",
      " |  \n",
      " |  __array__(self, dtype=None) -> numpy.ndarray\n",
      " |      Return the values as a NumPy array.\n",
      " |      \n",
      " |      Users should not call this directly. Rather, it is invoked by\n",
      " |      :func:`numpy.array` and :func:`numpy.asarray`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : str or numpy.dtype, optional\n",
      " |          The dtype to use for the resulting NumPy array. By default,\n",
      " |          the dtype is inferred from the data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray\n",
      " |          The values in the series converted to a :class:`numpy.ndarary`\n",
      " |          with the specified `dtype`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      array : Create a new array from data.\n",
      " |      Series.array : Zero-copy view to the array backing the Series.\n",
      " |      Series.to_numpy : Series method for similar behavior.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> ser = pd.Series([1, 2, 3])\n",
      " |      >>> np.asarray(ser)\n",
      " |      array([1, 2, 3])\n",
      " |      \n",
      " |      For timezone-aware data, the timezones may be retained with\n",
      " |      ``dtype='object'``\n",
      " |      \n",
      " |      >>> tzser = pd.Series(pd.date_range('2000', periods=2, tz=\"CET\"))\n",
      " |      >>> np.asarray(tzser, dtype=\"object\")\n",
      " |      array([Timestamp('2000-01-01 00:00:00+0100', tz='CET', freq='D'),\n",
      " |             Timestamp('2000-01-02 00:00:00+0100', tz='CET', freq='D')],\n",
      " |            dtype=object)\n",
      " |      \n",
      " |      Or the values may be localized to UTC and the tzinfo discarded with\n",
      " |      ``dtype='datetime64[ns]'``\n",
      " |      \n",
      " |      >>> np.asarray(tzser, dtype=\"datetime64[ns]\")  # doctest: +ELLIPSIS\n",
      " |      array(['1999-12-31T23:00:00.000000000', ...],\n",
      " |            dtype='datetime64[ns]')\n",
      " |  \n",
      " |  __array_ufunc__(self, ufunc: Callable, method: str, *inputs: Any, **kwargs: Any)\n",
      " |  \n",
      " |  __div__ = __truediv__(left, right)\n",
      " |  \n",
      " |  __divmod__(left, right)\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |  \n",
      " |  __float__(self)\n",
      " |  \n",
      " |  __floordiv__(left, right)\n",
      " |  \n",
      " |  __ge__(self, other)\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |  \n",
      " |  __gt__(self, other)\n",
      " |  \n",
      " |  __iadd__(self, other)\n",
      " |  \n",
      " |  __iand__(self, other)\n",
      " |  \n",
      " |  __ifloordiv__(self, other)\n",
      " |  \n",
      " |  __imod__(self, other)\n",
      " |  \n",
      " |  __imul__(self, other)\n",
      " |  \n",
      " |  __init__(self, data=None, index=None, dtype=None, name=None, copy=False, fastpath=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __int__(self)\n",
      " |  \n",
      " |  __ior__(self, other)\n",
      " |  \n",
      " |  __ipow__(self, other)\n",
      " |  \n",
      " |  __isub__(self, other)\n",
      " |  \n",
      " |  __itruediv__(self, other)\n",
      " |  \n",
      " |  __ixor__(self, other)\n",
      " |  \n",
      " |  __le__(self, other)\n",
      " |  \n",
      " |  __len__(self) -> int\n",
      " |      Return the length of the Series.\n",
      " |  \n",
      " |  __long__ = __int__(self)\n",
      " |  \n",
      " |  __lt__(self, other)\n",
      " |  \n",
      " |  __matmul__(self, other)\n",
      " |      Matrix multiplication using binary `@` operator in Python>=3.5.\n",
      " |  \n",
      " |  __mod__(left, right)\n",
      " |  \n",
      " |  __mul__(left, right)\n",
      " |  \n",
      " |  __ne__(self, other)\n",
      " |  \n",
      " |  __or__(self, other)\n",
      " |  \n",
      " |  __pow__(left, right)\n",
      " |  \n",
      " |  __radd__(left, right)\n",
      " |  \n",
      " |  __rand__(self, other)\n",
      " |  \n",
      " |  __rdiv__ = __rtruediv__(left, right)\n",
      " |  \n",
      " |  __rdivmod__(left, right)\n",
      " |  \n",
      " |  __repr__(self) -> str\n",
      " |      Return a string representation for a particular Series.\n",
      " |  \n",
      " |  __rfloordiv__(left, right)\n",
      " |  \n",
      " |  __rmatmul__(self, other)\n",
      " |      Matrix multiplication using binary `@` operator in Python>=3.5.\n",
      " |  \n",
      " |  __rmod__(left, right)\n",
      " |  \n",
      " |  __rmul__(left, right)\n",
      " |  \n",
      " |  __ror__(self, other)\n",
      " |  \n",
      " |  __rpow__(left, right)\n",
      " |  \n",
      " |  __rsub__(left, right)\n",
      " |  \n",
      " |  __rtruediv__(left, right)\n",
      " |  \n",
      " |  __rxor__(self, other)\n",
      " |  \n",
      " |  __setitem__(self, key, value)\n",
      " |  \n",
      " |  __sub__(left, right)\n",
      " |  \n",
      " |  __truediv__(left, right)\n",
      " |  \n",
      " |  __xor__(self, other)\n",
      " |  \n",
      " |  add(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Return Addition of series and other, element-wise (binary operator `add`).\n",
      " |      \n",
      " |      Equivalent to ``series + other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.radd\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  agg = aggregate(self, func, axis=0, *args, **kwargs)\n",
      " |  \n",
      " |  aggregate(self, func, axis=0, *args, **kwargs)\n",
      " |      Aggregate using one or more operations over the specified axis.\n",
      " |      \n",
      " |      .. versionadded:: 0.20.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function, str, list or dict\n",
      " |          Function to use for aggregating the data. If a function, must either\n",
      " |          work when passed a Series or when passed to Series.apply.\n",
      " |      \n",
      " |          Accepted combinations are:\n",
      " |      \n",
      " |          - function\n",
      " |          - string function name\n",
      " |          - list of functions and/or function names, e.g. ``[np.sum, 'mean']``\n",
      " |          - dict of axis labels -> functions, function names or list of such.\n",
      " |      axis : {0 or 'index'}\n",
      " |              Parameter needed for compatibility with DataFrame.\n",
      " |      *args\n",
      " |          Positional arguments to pass to `func`.\n",
      " |      **kwargs\n",
      " |          Keyword arguments to pass to `func`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar, Series or DataFrame\n",
      " |      \n",
      " |          The return can be:\n",
      " |      \n",
      " |          * scalar : when Series.agg is called with single function\n",
      " |          * Series : when DataFrame.agg is called with a single function\n",
      " |          * DataFrame : when DataFrame.agg is called with several functions\n",
      " |      \n",
      " |          Return scalar, Series or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.apply : Invoke function on a Series.\n",
      " |      Series.transform : Transform function producing a Series with like indexes.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      `agg` is an alias for `aggregate`. Use the alias.\n",
      " |      \n",
      " |      A passed user-defined-function will be passed a Series for evaluation.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.agg('min')\n",
      " |      1\n",
      " |      \n",
      " |      >>> s.agg(['min', 'max'])\n",
      " |      min   1\n",
      " |      max   4\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  align(self, other, join='outer', axis=None, level=None, copy=True, fill_value=None, method=None, limit=None, fill_axis=0, broadcast_axis=None)\n",
      " |      Align two objects on their axes with the specified join method.\n",
      " |      \n",
      " |      Join method is specified for each axis Index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame or Series\n",
      " |      join : {'outer', 'inner', 'left', 'right'}, default 'outer'\n",
      " |      axis : allowed axis of the other object, default None\n",
      " |          Align on index (0), columns (1), or both (None).\n",
      " |      level : int or level name, default None\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      copy : bool, default True\n",
      " |          Always returns new objects. If copy=False and no reindexing is\n",
      " |          required then original objects are returned.\n",
      " |      fill_value : scalar, default np.NaN\n",
      " |          Value to use for missing values. Defaults to NaN, but can be any\n",
      " |          \"compatible\" value.\n",
      " |      method : {'backfill', 'bfill', 'pad', 'ffill', None}, default None\n",
      " |          Method to use for filling holes in reindexed Series:\n",
      " |      \n",
      " |          - pad / ffill: propagate last valid observation forward to next valid.\n",
      " |          - backfill / bfill: use NEXT valid observation to fill gap.\n",
      " |      \n",
      " |      limit : int, default None\n",
      " |          If method is specified, this is the maximum number of consecutive\n",
      " |          NaN values to forward/backward fill. In other words, if there is\n",
      " |          a gap with more than this number of consecutive NaNs, it will only\n",
      " |          be partially filled. If method is not specified, this is the\n",
      " |          maximum number of entries along the entire axis where NaNs will be\n",
      " |          filled. Must be greater than 0 if not None.\n",
      " |      fill_axis : {0 or 'index'}, default 0\n",
      " |          Filling axis, method and limit.\n",
      " |      broadcast_axis : {0 or 'index'}, default None\n",
      " |          Broadcast values along this axis, if aligning two objects of\n",
      " |          different dimensions.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      (left, right) : (Series, type of other)\n",
      " |          Aligned objects.\n",
      " |  \n",
      " |  all(self, axis=0, bool_only=None, skipna=True, level=None, **kwargs)\n",
      " |      Return whether all elements are True, potentially over an axis.\n",
      " |      \n",
      " |      Returns True unless there at least one element within a series or\n",
      " |      along a Dataframe axis that is False or equivalent (e.g. zero or\n",
      " |      empty).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          Indicate which axis or axes should be reduced.\n",
      " |      \n",
      " |          * 0 / 'index' : reduce the index, return a Series whose index is the\n",
      " |            original column labels.\n",
      " |          * 1 / 'columns' : reduce the columns, return a Series whose index is the\n",
      " |            original index.\n",
      " |          * None : reduce all axes, return a scalar.\n",
      " |      \n",
      " |      bool_only : bool, default None\n",
      " |          Include only boolean columns. If None, will attempt to use everything,\n",
      " |          then use only boolean data. Not implemented for Series.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If the entire row/column is NA and skipna is\n",
      " |          True, then the result will be True, as for an empty row/column.\n",
      " |          If skipna is False, then NA are treated as True, because these are not\n",
      " |          equal to zero.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar.\n",
      " |      **kwargs : any, default None\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series\n",
      " |          If level is specified, then, Series is returned; otherwise, scalar\n",
      " |          is returned.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.all : Return True if all elements are True.\n",
      " |      DataFrame.any : Return True if one (or more) elements are True.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> pd.Series([True, True]).all()\n",
      " |      True\n",
      " |      >>> pd.Series([True, False]).all()\n",
      " |      False\n",
      " |      >>> pd.Series([]).all()\n",
      " |      True\n",
      " |      >>> pd.Series([np.nan]).all()\n",
      " |      True\n",
      " |      >>> pd.Series([np.nan]).all(skipna=False)\n",
      " |      True\n",
      " |      \n",
      " |      **DataFrames**\n",
      " |      \n",
      " |      Create a dataframe from a dictionary.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'col1': [True, True], 'col2': [True, False]})\n",
      " |      >>> df\n",
      " |         col1   col2\n",
      " |      0  True   True\n",
      " |      1  True  False\n",
      " |      \n",
      " |      Default behaviour checks if column-wise values all return True.\n",
      " |      \n",
      " |      >>> df.all()\n",
      " |      col1     True\n",
      " |      col2    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Specify ``axis='columns'`` to check if row-wise values all return True.\n",
      " |      \n",
      " |      >>> df.all(axis='columns')\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Or ``axis=None`` for whether every value is True.\n",
      " |      \n",
      " |      >>> df.all(axis=None)\n",
      " |      False\n",
      " |  \n",
      " |  any(self, axis=0, bool_only=None, skipna=True, level=None, **kwargs)\n",
      " |      Return whether any element is True, potentially over an axis.\n",
      " |      \n",
      " |      Returns False unless there at least one element within a series or\n",
      " |      along a Dataframe axis that is True or equivalent (e.g. non-zero or\n",
      " |      non-empty).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          Indicate which axis or axes should be reduced.\n",
      " |      \n",
      " |          * 0 / 'index' : reduce the index, return a Series whose index is the\n",
      " |            original column labels.\n",
      " |          * 1 / 'columns' : reduce the columns, return a Series whose index is the\n",
      " |            original index.\n",
      " |          * None : reduce all axes, return a scalar.\n",
      " |      \n",
      " |      bool_only : bool, default None\n",
      " |          Include only boolean columns. If None, will attempt to use everything,\n",
      " |          then use only boolean data. Not implemented for Series.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If the entire row/column is NA and skipna is\n",
      " |          True, then the result will be False, as for an empty row/column.\n",
      " |          If skipna is False, then NA are treated as True, because these are not\n",
      " |          equal to zero.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar.\n",
      " |      **kwargs : any, default None\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series\n",
      " |          If level is specified, then, Series is returned; otherwise, scalar\n",
      " |          is returned.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.any : Numpy version of this method.\n",
      " |      Series.any : Return whether any element is True.\n",
      " |      Series.all : Return whether all elements are True.\n",
      " |      DataFrame.any : Return whether any element is True over requested axis.\n",
      " |      DataFrame.all : Return whether all elements are True over requested axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      For Series input, the output is a scalar indicating whether any element\n",
      " |      is True.\n",
      " |      \n",
      " |      >>> pd.Series([False, False]).any()\n",
      " |      False\n",
      " |      >>> pd.Series([True, False]).any()\n",
      " |      True\n",
      " |      >>> pd.Series([]).any()\n",
      " |      False\n",
      " |      >>> pd.Series([np.nan]).any()\n",
      " |      False\n",
      " |      >>> pd.Series([np.nan]).any(skipna=False)\n",
      " |      True\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      Whether each column contains at least one True element (the default).\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2], \"B\": [0, 2], \"C\": [0, 0]})\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |      0  1  0  0\n",
      " |      1  2  2  0\n",
      " |      \n",
      " |      >>> df.any()\n",
      " |      A     True\n",
      " |      B     True\n",
      " |      C    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Aggregating over the columns.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [True, False], \"B\": [1, 2]})\n",
      " |      >>> df\n",
      " |             A  B\n",
      " |      0   True  1\n",
      " |      1  False  2\n",
      " |      \n",
      " |      >>> df.any(axis='columns')\n",
      " |      0    True\n",
      " |      1    True\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [True, False], \"B\": [1, 0]})\n",
      " |      >>> df\n",
      " |             A  B\n",
      " |      0   True  1\n",
      " |      1  False  0\n",
      " |      \n",
      " |      >>> df.any(axis='columns')\n",
      " |      0    True\n",
      " |      1    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      Aggregating over the entire DataFrame with ``axis=None``.\n",
      " |      \n",
      " |      >>> df.any(axis=None)\n",
      " |      True\n",
      " |      \n",
      " |      `any` for an empty DataFrame is an empty Series.\n",
      " |      \n",
      " |      >>> pd.DataFrame([]).any()\n",
      " |      Series([], dtype: bool)\n",
      " |  \n",
      " |  append(self, to_append, ignore_index=False, verify_integrity=False)\n",
      " |      Concatenate two or more Series.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      to_append : Series or list/tuple of Series\n",
      " |          Series to append with self.\n",
      " |      ignore_index : bool, default False\n",
      " |          If True, do not use the index labels.\n",
      " |      verify_integrity : bool, default False\n",
      " |          If True, raise Exception on creating index with duplicates.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Concatenated Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      concat : General function to concatenate DataFrame or Series objects.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Iteratively appending to a Series can be more computationally intensive\n",
      " |      than a single concatenate. A better solution is to append values to a\n",
      " |      list and then concatenate the list with the original Series all at\n",
      " |      once.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s1 = pd.Series([1, 2, 3])\n",
      " |      >>> s2 = pd.Series([4, 5, 6])\n",
      " |      >>> s3 = pd.Series([4, 5, 6], index=[3, 4, 5])\n",
      " |      >>> s1.append(s2)\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      0    4\n",
      " |      1    5\n",
      " |      2    6\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s1.append(s3)\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      4    5\n",
      " |      5    6\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      With `ignore_index` set to True:\n",
      " |      \n",
      " |      >>> s1.append(s2, ignore_index=True)\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      4    5\n",
      " |      5    6\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      With `verify_integrity` set to True:\n",
      " |      \n",
      " |      >>> s1.append(s2, verify_integrity=True)\n",
      " |      Traceback (most recent call last):\n",
      " |      ...\n",
      " |      ValueError: Indexes have overlapping values: [0, 1, 2]\n",
      " |  \n",
      " |  apply(self, func, convert_dtype=True, args=(), **kwds)\n",
      " |      Invoke function on values of Series.\n",
      " |      \n",
      " |      Can be ufunc (a NumPy function that applies to the entire Series)\n",
      " |      or a Python function that only works on single values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |          Python function or NumPy ufunc to apply.\n",
      " |      convert_dtype : bool, default True\n",
      " |          Try to find better dtype for elementwise function results. If\n",
      " |          False, leave as dtype=object.\n",
      " |      args : tuple\n",
      " |          Positional arguments passed to func after the series value.\n",
      " |      **kwds\n",
      " |          Additional keyword arguments passed to func.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          If func returns a Series object the result will be a DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.map: For element-wise operations.\n",
      " |      Series.agg: Only perform aggregating type operations.\n",
      " |      Series.transform: Only perform transforming type operations.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Create a series with typical summer temperatures for each city.\n",
      " |      \n",
      " |      >>> s = pd.Series([20, 21, 12],\n",
      " |      ...               index=['London', 'New York', 'Helsinki'])\n",
      " |      >>> s\n",
      " |      London      20\n",
      " |      New York    21\n",
      " |      Helsinki    12\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Square the values by defining a function and passing it as an\n",
      " |      argument to ``apply()``.\n",
      " |      \n",
      " |      >>> def square(x):\n",
      " |      ...     return x ** 2\n",
      " |      >>> s.apply(square)\n",
      " |      London      400\n",
      " |      New York    441\n",
      " |      Helsinki    144\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Square the values by passing an anonymous function as an\n",
      " |      argument to ``apply()``.\n",
      " |      \n",
      " |      >>> s.apply(lambda x: x ** 2)\n",
      " |      London      400\n",
      " |      New York    441\n",
      " |      Helsinki    144\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Define a custom function that needs additional positional\n",
      " |      arguments and pass these additional arguments using the\n",
      " |      ``args`` keyword.\n",
      " |      \n",
      " |      >>> def subtract_custom_value(x, custom_value):\n",
      " |      ...     return x - custom_value\n",
      " |      \n",
      " |      >>> s.apply(subtract_custom_value, args=(5,))\n",
      " |      London      15\n",
      " |      New York    16\n",
      " |      Helsinki     7\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Define a custom function that takes keyword arguments\n",
      " |      and pass these arguments to ``apply``.\n",
      " |      \n",
      " |      >>> def add_custom_values(x, **kwargs):\n",
      " |      ...     for month in kwargs:\n",
      " |      ...         x += kwargs[month]\n",
      " |      ...     return x\n",
      " |      \n",
      " |      >>> s.apply(add_custom_values, june=30, july=20, august=25)\n",
      " |      London      95\n",
      " |      New York    96\n",
      " |      Helsinki    87\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Use a function from the Numpy library.\n",
      " |      \n",
      " |      >>> s.apply(np.log)\n",
      " |      London      2.995732\n",
      " |      New York    3.044522\n",
      " |      Helsinki    2.484907\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  argsort(self, axis=0, kind='quicksort', order=None)\n",
      " |      Override ndarray.argsort. Argsorts the value, omitting NA/null values,\n",
      " |      and places the result in the same locations as the non-NA values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or \"index\"}\n",
      " |          Has no effect but is accepted for compatibility with numpy.\n",
      " |      kind : {'mergesort', 'quicksort', 'heapsort'}, default 'quicksort'\n",
      " |          Choice of sorting algorithm. See np.sort for more\n",
      " |          information. 'mergesort' is the only stable algorithm.\n",
      " |      order : None\n",
      " |          Has no effect but is accepted for compatibility with numpy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Positions of values within the sort order with -1 indicating\n",
      " |          nan values.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.argsort\n",
      " |  \n",
      " |  autocorr(self, lag=1)\n",
      " |      Compute the lag-N autocorrelation.\n",
      " |      \n",
      " |      This method computes the Pearson correlation between\n",
      " |      the Series and its shifted self.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      lag : int, default 1\n",
      " |          Number of lags to apply before performing autocorrelation.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      float\n",
      " |          The Pearson correlation between self and self.shift(lag).\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.corr : Compute the correlation between two Series.\n",
      " |      Series.shift : Shift index by desired number of periods.\n",
      " |      DataFrame.corr : Compute pairwise correlation of columns.\n",
      " |      DataFrame.corrwith : Compute pairwise correlation between rows or\n",
      " |          columns of two DataFrame objects.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If the Pearson correlation is not well defined return 'NaN'.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([0.25, 0.5, 0.2, -0.05])\n",
      " |      >>> s.autocorr()  # doctest: +ELLIPSIS\n",
      " |      0.10355...\n",
      " |      >>> s.autocorr(lag=2)  # doctest: +ELLIPSIS\n",
      " |      -0.99999...\n",
      " |      \n",
      " |      If the Pearson correlation is not well defined, then 'NaN' is returned.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 0, 0, 0])\n",
      " |      >>> s.autocorr()\n",
      " |      nan\n",
      " |  \n",
      " |  between(self, left, right, inclusive=True)\n",
      " |      Return boolean Series equivalent to left <= series <= right.\n",
      " |      \n",
      " |      This function returns a boolean vector containing `True` wherever the\n",
      " |      corresponding Series element is between the boundary values `left` and\n",
      " |      `right`. NA values are treated as `False`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      left : scalar or list-like\n",
      " |          Left boundary.\n",
      " |      right : scalar or list-like\n",
      " |          Right boundary.\n",
      " |      inclusive : bool, default True\n",
      " |          Include boundaries.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Series representing whether each element is between left and\n",
      " |          right (inclusive).\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.gt : Greater than of series and other.\n",
      " |      Series.lt : Less than of series and other.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This function is equivalent to ``(left <= ser) & (ser <= right)``\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([2, 0, 4, 8, np.nan])\n",
      " |      \n",
      " |      Boundary values are included by default:\n",
      " |      \n",
      " |      >>> s.between(1, 4)\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      4    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      With `inclusive` set to ``False`` boundary values are excluded:\n",
      " |      \n",
      " |      >>> s.between(1, 4, inclusive=False)\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      2    False\n",
      " |      3    False\n",
      " |      4    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      `left` and `right` can be any scalar value:\n",
      " |      \n",
      " |      >>> s = pd.Series(['Alice', 'Bob', 'Carol', 'Eve'])\n",
      " |      >>> s.between('Anna', 'Daniel')\n",
      " |      0    False\n",
      " |      1     True\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  combine(self, other, func, fill_value=None)\n",
      " |      Combine the Series with a Series or scalar according to `func`.\n",
      " |      \n",
      " |      Combine the Series and `other` using `func` to perform elementwise\n",
      " |      selection for combined Series.\n",
      " |      `fill_value` is assumed when value is missing at some index\n",
      " |      from one of the two objects being combined.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar\n",
      " |          The value(s) to be combined with the `Series`.\n",
      " |      func : function\n",
      " |          Function that takes two scalars as inputs and returns an element.\n",
      " |      fill_value : scalar, optional\n",
      " |          The value to assume when an index is missing from\n",
      " |          one Series or the other. The default specifies to use the\n",
      " |          appropriate NaN value for the underlying dtype of the Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of combining the Series with the other object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.combine_first : Combine Series values, choosing the calling\n",
      " |          Series' values first.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Consider 2 Datasets ``s1`` and ``s2`` containing\n",
      " |      highest clocked speeds of different birds.\n",
      " |      \n",
      " |      >>> s1 = pd.Series({'falcon': 330.0, 'eagle': 160.0})\n",
      " |      >>> s1\n",
      " |      falcon    330.0\n",
      " |      eagle     160.0\n",
      " |      dtype: float64\n",
      " |      >>> s2 = pd.Series({'falcon': 345.0, 'eagle': 200.0, 'duck': 30.0})\n",
      " |      >>> s2\n",
      " |      falcon    345.0\n",
      " |      eagle     200.0\n",
      " |      duck       30.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Now, to combine the two datasets and view the highest speeds\n",
      " |      of the birds across the two datasets\n",
      " |      \n",
      " |      >>> s1.combine(s2, max)\n",
      " |      duck        NaN\n",
      " |      eagle     200.0\n",
      " |      falcon    345.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      In the previous example, the resulting value for duck is missing,\n",
      " |      because the maximum of a NaN and a float is a NaN.\n",
      " |      So, in the example, we set ``fill_value=0``,\n",
      " |      so the maximum value returned will be the value from some dataset.\n",
      " |      \n",
      " |      >>> s1.combine(s2, max, fill_value=0)\n",
      " |      duck       30.0\n",
      " |      eagle     200.0\n",
      " |      falcon    345.0\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  combine_first(self, other)\n",
      " |      Combine Series values, choosing the calling Series's values first.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series\n",
      " |          The value(s) to be combined with the `Series`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of combining the Series with the other object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.combine : Perform elementwise operation on two Series\n",
      " |          using a given function.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Result index will be the union of the two indexes.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s1 = pd.Series([1, np.nan])\n",
      " |      >>> s2 = pd.Series([3, 4])\n",
      " |      >>> s1.combine_first(s2)\n",
      " |      0    1.0\n",
      " |      1    4.0\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  corr(self, other, method='pearson', min_periods=None)\n",
      " |      Compute correlation with `other` Series, excluding missing values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series\n",
      " |          Series with which to compute the correlation.\n",
      " |      method : {'pearson', 'kendall', 'spearman'} or callable\n",
      " |          Method used to compute correlation:\n",
      " |      \n",
      " |          - pearson : Standard correlation coefficient\n",
      " |          - kendall : Kendall Tau correlation coefficient\n",
      " |          - spearman : Spearman rank correlation\n",
      " |          - callable: Callable with input two 1d ndarrays and returning a float.\n",
      " |      \n",
      " |          .. versionadded:: 0.24.0\n",
      " |              Note that the returned matrix from corr will have 1 along the\n",
      " |              diagonals and will be symmetric regardless of the callable's\n",
      " |              behavior.\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations needed to have a valid result.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      float\n",
      " |          Correlation with other.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> def histogram_intersection(a, b):\n",
      " |      ...     v = np.minimum(a, b).sum().round(decimals=1)\n",
      " |      ...     return v\n",
      " |      >>> s1 = pd.Series([.2, .0, .6, .2])\n",
      " |      >>> s2 = pd.Series([.3, .6, .0, .1])\n",
      " |      >>> s1.corr(s2, method=histogram_intersection)\n",
      " |      0.3\n",
      " |  \n",
      " |  count(self, level=None)\n",
      " |      Return number of non-NA/null observations in the Series.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a smaller Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      int or Series (if level specified)\n",
      " |          Number of non-null values in the Series.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([0.0, 1.0, np.nan])\n",
      " |      >>> s.count()\n",
      " |      2\n",
      " |  \n",
      " |  cov(self, other, min_periods=None)\n",
      " |      Compute covariance with Series, excluding missing values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series\n",
      " |          Series with which to compute the covariance.\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations needed to have a valid result.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      float\n",
      " |          Covariance between Series and other normalized by N-1\n",
      " |          (unbiased estimator).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s1 = pd.Series([0.90010907, 0.13484424, 0.62036035])\n",
      " |      >>> s2 = pd.Series([0.12528585, 0.26962463, 0.51111198])\n",
      " |      >>> s1.cov(s2)\n",
      " |      -0.01685762652715874\n",
      " |  \n",
      " |  cummax(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative maximum over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      maximum.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs :\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.Expanding.max : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      Series.max : Return the maximum over\n",
      " |          Series axis.\n",
      " |      Series.cummax : Return cumulative maximum over Series axis.\n",
      " |      Series.cummin : Return cumulative minimum over Series axis.\n",
      " |      Series.cumsum : Return cumulative sum over Series axis.\n",
      " |      Series.cumprod : Return cumulative product over Series axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cummax()\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3    5.0\n",
      " |      4    5.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cummax(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                    columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the maximum\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cummax()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  3.0  1.0\n",
      " |      \n",
      " |      To iterate over columns and find the maximum in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cummax(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  2.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  1.0\n",
      " |  \n",
      " |  cummin(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative minimum over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      minimum.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs :\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.Expanding.min : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      Series.min : Return the minimum over\n",
      " |          Series axis.\n",
      " |      Series.cummax : Return cumulative maximum over Series axis.\n",
      " |      Series.cummin : Return cumulative minimum over Series axis.\n",
      " |      Series.cumsum : Return cumulative sum over Series axis.\n",
      " |      Series.cumprod : Return cumulative product over Series axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cummin()\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    2.0\n",
      " |      3   -1.0\n",
      " |      4   -1.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cummin(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                    columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the minimum\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cummin()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  2.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      To iterate over columns and find the minimum in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cummin(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |  \n",
      " |  cumprod(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative product over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      product.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs :\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.Expanding.prod : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      Series.prod : Return the product over\n",
      " |          Series axis.\n",
      " |      Series.cummax : Return cumulative maximum over Series axis.\n",
      " |      Series.cummin : Return cumulative minimum over Series axis.\n",
      " |      Series.cumsum : Return cumulative sum over Series axis.\n",
      " |      Series.cumprod : Return cumulative product over Series axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cumprod()\n",
      " |      0     2.0\n",
      " |      1     NaN\n",
      " |      2    10.0\n",
      " |      3   -10.0\n",
      " |      4    -0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cumprod(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                    columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the product\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cumprod()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  6.0  NaN\n",
      " |      2  6.0  0.0\n",
      " |      \n",
      " |      To iterate over columns and find the product in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cumprod(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  2.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |  \n",
      " |  cumsum(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return cumulative sum over a DataFrame or Series axis.\n",
      " |      \n",
      " |      Returns a DataFrame or Series of the same size containing the cumulative\n",
      " |      sum.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The index or the name of the axis. 0 is equivalent to None or 'index'.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs :\n",
      " |          Additional keywords have no effect but might be accepted for\n",
      " |          compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.Expanding.sum : Similar functionality\n",
      " |          but ignores ``NaN`` values.\n",
      " |      Series.sum : Return the sum over\n",
      " |          Series axis.\n",
      " |      Series.cummax : Return cumulative maximum over Series axis.\n",
      " |      Series.cummin : Return cumulative minimum over Series axis.\n",
      " |      Series.cumsum : Return cumulative sum over Series axis.\n",
      " |      Series.cumprod : Return cumulative product over Series axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([2, np.nan, 5, -1, 0])\n",
      " |      >>> s\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    5.0\n",
      " |      3   -1.0\n",
      " |      4    0.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      By default, NA values are ignored.\n",
      " |      \n",
      " |      >>> s.cumsum()\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    7.0\n",
      " |      3    6.0\n",
      " |      4    6.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      To include NA values in the operation, use ``skipna=False``\n",
      " |      \n",
      " |      >>> s.cumsum(skipna=False)\n",
      " |      0    2.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[2.0, 1.0],\n",
      " |      ...                    [3.0, np.nan],\n",
      " |      ...                    [1.0, 0.0]],\n",
      " |      ...                    columns=list('AB'))\n",
      " |      >>> df\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  0.0\n",
      " |      \n",
      " |      By default, iterates over rows and finds the sum\n",
      " |      in each column. This is equivalent to ``axis=None`` or ``axis='index'``.\n",
      " |      \n",
      " |      >>> df.cumsum()\n",
      " |           A    B\n",
      " |      0  2.0  1.0\n",
      " |      1  5.0  NaN\n",
      " |      2  6.0  1.0\n",
      " |      \n",
      " |      To iterate over columns and find the sum in each row,\n",
      " |      use ``axis=1``\n",
      " |      \n",
      " |      >>> df.cumsum(axis=1)\n",
      " |           A    B\n",
      " |      0  2.0  3.0\n",
      " |      1  3.0  NaN\n",
      " |      2  1.0  1.0\n",
      " |  \n",
      " |  diff(self, periods=1)\n",
      " |      First discrete difference of element.\n",
      " |      \n",
      " |      Calculates the difference of a Series element compared with another\n",
      " |      element in the Series (default is element in previous row).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for calculating difference, accepts negative\n",
      " |          values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          First differences of the Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.pct_change: Percent change over given number of periods.\n",
      " |      Series.shift: Shift index by desired number of periods with an\n",
      " |          optional time freq.\n",
      " |      DataFrame.diff: First discrete difference of object.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For boolean dtypes, this uses :meth:`operator.xor` rather than\n",
      " |      :meth:`operator.sub`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Difference with previous row\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 1, 2, 3, 5, 8])\n",
      " |      >>> s.diff()\n",
      " |      0    NaN\n",
      " |      1    0.0\n",
      " |      2    1.0\n",
      " |      3    1.0\n",
      " |      4    2.0\n",
      " |      5    3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Difference with 3rd previous row\n",
      " |      \n",
      " |      >>> s.diff(periods=3)\n",
      " |      0    NaN\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    2.0\n",
      " |      4    4.0\n",
      " |      5    6.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Difference with following row\n",
      " |      \n",
      " |      >>> s.diff(periods=-1)\n",
      " |      0    0.0\n",
      " |      1   -1.0\n",
      " |      2   -1.0\n",
      " |      3   -2.0\n",
      " |      4   -3.0\n",
      " |      5    NaN\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  div = truediv(self, other, level=None, fill_value=None, axis=0)\n",
      " |  \n",
      " |  divide = truediv(self, other, level=None, fill_value=None, axis=0)\n",
      " |  \n",
      " |  divmod(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Return Integer division and modulo of series and other, element-wise (binary operator `divmod`).\n",
      " |      \n",
      " |      Equivalent to ``series divmod other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.rdivmod\n",
      " |  \n",
      " |  dot(self, other)\n",
      " |      Compute the dot product between the Series and the columns of other.\n",
      " |      \n",
      " |      This method computes the dot product between the Series and another\n",
      " |      one, or the Series and each columns of a DataFrame, or the Series and\n",
      " |      each columns of an array.\n",
      " |      \n",
      " |      It can also be called using `self @ other` in Python >= 3.5.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame or array-like\n",
      " |          The other object to compute the dot product with its columns.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar, Series or numpy.ndarray\n",
      " |          Return the dot product of the Series and other if other is a\n",
      " |          Series, the Series of the dot product of Series and each rows of\n",
      " |          other if other is a DataFrame or a numpy.ndarray between the Series\n",
      " |          and each columns of the numpy array.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.dot: Compute the matrix product with the DataFrame.\n",
      " |      Series.mul: Multiplication of series and other, element-wise.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The Series and other has to share the same index if other is a Series\n",
      " |      or a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([0, 1, 2, 3])\n",
      " |      >>> other = pd.Series([-1, 2, -3, 4])\n",
      " |      >>> s.dot(other)\n",
      " |      8\n",
      " |      >>> s @ other\n",
      " |      8\n",
      " |      >>> df = pd.DataFrame([[0, 1], [-2, 3], [4, -5], [6, 7]])\n",
      " |      >>> s.dot(df)\n",
      " |      0    24\n",
      " |      1    14\n",
      " |      dtype: int64\n",
      " |      >>> arr = np.array([[0, 1], [-2, 3], [4, -5], [6, 7]])\n",
      " |      >>> s.dot(arr)\n",
      " |      array([24, 14])\n",
      " |  \n",
      " |  drop(self, labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')\n",
      " |      Return Series with specified index labels removed.\n",
      " |      \n",
      " |      Remove elements of a Series based on specifying the index labels.\n",
      " |      When using a multi-index, labels on different levels can be removed\n",
      " |      by specifying the level.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      labels : single label or list-like\n",
      " |          Index labels to drop.\n",
      " |      axis : 0, default 0\n",
      " |          Redundant for application on Series.\n",
      " |      index : single label or list-like\n",
      " |          Redundant for application on Series, but 'index' can be used instead\n",
      " |          of 'labels'.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0\n",
      " |      columns : single label or list-like\n",
      " |          No change is made to the Series; use 'index' or 'labels' instead.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0\n",
      " |      level : int or level name, optional\n",
      " |          For MultiIndex, level for which the labels will be removed.\n",
      " |      inplace : bool, default False\n",
      " |          If True, do operation inplace and return None.\n",
      " |      errors : {'ignore', 'raise'}, default 'raise'\n",
      " |          If 'ignore', suppress error and only existing labels are dropped.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Series with specified index labels removed.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError\n",
      " |          If none of the labels are found in the index.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.reindex : Return only specified index labels of Series.\n",
      " |      Series.dropna : Return series without null values.\n",
      " |      Series.drop_duplicates : Return Series with duplicate values removed.\n",
      " |      DataFrame.drop : Drop specified labels from rows or columns.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(data=np.arange(3), index=['A', 'B', 'C'])\n",
      " |      >>> s\n",
      " |      A  0\n",
      " |      B  1\n",
      " |      C  2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Drop labels B en C\n",
      " |      \n",
      " |      >>> s.drop(labels=['B', 'C'])\n",
      " |      A  0\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Drop 2nd level label in MultiIndex Series\n",
      " |      \n",
      " |      >>> midx = pd.MultiIndex(levels=[['lama', 'cow', 'falcon'],\n",
      " |      ...                              ['speed', 'weight', 'length']],\n",
      " |      ...                      codes=[[0, 0, 0, 1, 1, 1, 2, 2, 2],\n",
      " |      ...                             [0, 1, 2, 0, 1, 2, 0, 1, 2]])\n",
      " |      >>> s = pd.Series([45, 200, 1.2, 30, 250, 1.5, 320, 1, 0.3],\n",
      " |      ...               index=midx)\n",
      " |      >>> s\n",
      " |      lama    speed      45.0\n",
      " |              weight    200.0\n",
      " |              length      1.2\n",
      " |      cow     speed      30.0\n",
      " |              weight    250.0\n",
      " |              length      1.5\n",
      " |      falcon  speed     320.0\n",
      " |              weight      1.0\n",
      " |              length      0.3\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.drop(labels='weight', level=1)\n",
      " |      lama    speed      45.0\n",
      " |              length      1.2\n",
      " |      cow     speed      30.0\n",
      " |              length      1.5\n",
      " |      falcon  speed     320.0\n",
      " |              length      0.3\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  drop_duplicates(self, keep='first', inplace=False)\n",
      " |      Return Series with duplicate values removed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      keep : {'first', 'last', ``False``}, default 'first'\n",
      " |          Method to handle dropping duplicates:\n",
      " |      \n",
      " |          - 'first' : Drop duplicates except for the first occurrence.\n",
      " |          - 'last' : Drop duplicates except for the last occurrence.\n",
      " |          - ``False`` : Drop all duplicates.\n",
      " |      \n",
      " |      inplace : bool, default ``False``\n",
      " |          If ``True``, performs operation inplace and returns None.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Series with duplicates dropped.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.drop_duplicates : Equivalent method on Index.\n",
      " |      DataFrame.drop_duplicates : Equivalent method on DataFrame.\n",
      " |      Series.duplicated : Related method on Series, indicating duplicate\n",
      " |          Series values.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Generate a Series with duplicated entries.\n",
      " |      \n",
      " |      >>> s = pd.Series(['lama', 'cow', 'lama', 'beetle', 'lama', 'hippo'],\n",
      " |      ...               name='animal')\n",
      " |      >>> s\n",
      " |      0      lama\n",
      " |      1       cow\n",
      " |      2      lama\n",
      " |      3    beetle\n",
      " |      4      lama\n",
      " |      5     hippo\n",
      " |      Name: animal, dtype: object\n",
      " |      \n",
      " |      With the 'keep' parameter, the selection behaviour of duplicated values\n",
      " |      can be changed. The value 'first' keeps the first occurrence for each\n",
      " |      set of duplicated entries. The default value of keep is 'first'.\n",
      " |      \n",
      " |      >>> s.drop_duplicates()\n",
      " |      0      lama\n",
      " |      1       cow\n",
      " |      3    beetle\n",
      " |      5     hippo\n",
      " |      Name: animal, dtype: object\n",
      " |      \n",
      " |      The value 'last' for parameter 'keep' keeps the last occurrence for\n",
      " |      each set of duplicated entries.\n",
      " |      \n",
      " |      >>> s.drop_duplicates(keep='last')\n",
      " |      1       cow\n",
      " |      3    beetle\n",
      " |      4      lama\n",
      " |      5     hippo\n",
      " |      Name: animal, dtype: object\n",
      " |      \n",
      " |      The value ``False`` for parameter 'keep' discards all sets of\n",
      " |      duplicated entries. Setting the value of 'inplace' to ``True`` performs\n",
      " |      the operation inplace and returns ``None``.\n",
      " |      \n",
      " |      >>> s.drop_duplicates(keep=False, inplace=True)\n",
      " |      >>> s\n",
      " |      1       cow\n",
      " |      3    beetle\n",
      " |      5     hippo\n",
      " |      Name: animal, dtype: object\n",
      " |  \n",
      " |  dropna(self, axis=0, inplace=False, how=None)\n",
      " |      Return a new Series with missing values removed.\n",
      " |      \n",
      " |      See the :ref:`User Guide <missing_data>` for more on which values are\n",
      " |      considered missing, and how to work with missing data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index'}, default 0\n",
      " |          There is only one axis to drop values from.\n",
      " |      inplace : bool, default False\n",
      " |          If True, do operation inplace and return None.\n",
      " |      how : str, optional\n",
      " |          Not in use. Kept for compatibility.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Series with NA entries dropped from it.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.isna: Indicate missing values.\n",
      " |      Series.notna : Indicate existing (non-missing) values.\n",
      " |      Series.fillna : Replace missing values.\n",
      " |      DataFrame.dropna : Drop rows or columns which contain NA values.\n",
      " |      Index.dropna : Drop missing indices.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> ser = pd.Series([1., 2., np.nan])\n",
      " |      >>> ser\n",
      " |      0    1.0\n",
      " |      1    2.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Drop NA values from a Series.\n",
      " |      \n",
      " |      >>> ser.dropna()\n",
      " |      0    1.0\n",
      " |      1    2.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Keep the Series with valid entries in the same variable.\n",
      " |      \n",
      " |      >>> ser.dropna(inplace=True)\n",
      " |      >>> ser\n",
      " |      0    1.0\n",
      " |      1    2.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Empty strings are not considered NA values. ``None`` is considered an\n",
      " |      NA value.\n",
      " |      \n",
      " |      >>> ser = pd.Series([np.NaN, 2, pd.NaT, '', None, 'I stay'])\n",
      " |      >>> ser\n",
      " |      0       NaN\n",
      " |      1         2\n",
      " |      2       NaT\n",
      " |      3\n",
      " |      4      None\n",
      " |      5    I stay\n",
      " |      dtype: object\n",
      " |      >>> ser.dropna()\n",
      " |      1         2\n",
      " |      3\n",
      " |      5    I stay\n",
      " |      dtype: object\n",
      " |  \n",
      " |  duplicated(self, keep='first')\n",
      " |      Indicate duplicate Series values.\n",
      " |      \n",
      " |      Duplicated values are indicated as ``True`` values in the resulting\n",
      " |      Series. Either all duplicates, all except the first or all except the\n",
      " |      last occurrence of duplicates can be indicated.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      keep : {'first', 'last', False}, default 'first'\n",
      " |          Method to handle dropping duplicates:\n",
      " |      \n",
      " |          - 'first' : Mark duplicates as ``True`` except for the first\n",
      " |            occurrence.\n",
      " |          - 'last' : Mark duplicates as ``True`` except for the last\n",
      " |            occurrence.\n",
      " |          - ``False`` : Mark all duplicates as ``True``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Series indicating whether each value has occurred in the\n",
      " |          preceding values.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.duplicated : Equivalent method on pandas.Index.\n",
      " |      DataFrame.duplicated : Equivalent method on pandas.DataFrame.\n",
      " |      Series.drop_duplicates : Remove duplicate values from Series.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      By default, for each set of duplicated values, the first occurrence is\n",
      " |      set on False and all others on True:\n",
      " |      \n",
      " |      >>> animals = pd.Series(['lama', 'cow', 'lama', 'beetle', 'lama'])\n",
      " |      >>> animals.duplicated()\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      4     True\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      which is equivalent to\n",
      " |      \n",
      " |      >>> animals.duplicated(keep='first')\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      4     True\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      By using 'last', the last occurrence of each set of duplicated values\n",
      " |      is set on False and all others on True:\n",
      " |      \n",
      " |      >>> animals.duplicated(keep='last')\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      4    False\n",
      " |      dtype: bool\n",
      " |      \n",
      " |      By setting keep on ``False``, all duplicates are True:\n",
      " |      \n",
      " |      >>> animals.duplicated(keep=False)\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      4     True\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  eq(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Return Equal to of series and other, element-wise (binary operator `eq`).\n",
      " |      \n",
      " |      Equivalent to ``series == other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.None\n",
      " |  \n",
      " |  ewm(self, com=None, span=None, halflife=None, alpha=None, min_periods=0, adjust=True, ignore_na=False, axis=0)\n",
      " |      Provide exponential weighted functions.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      com : float, optional\n",
      " |          Specify decay in terms of center of mass,\n",
      " |          :math:`\\alpha = 1 / (1 + com),\\text{ for } com \\geq 0`.\n",
      " |      span : float, optional\n",
      " |          Specify decay in terms of span,\n",
      " |          :math:`\\alpha = 2 / (span + 1),\\text{ for } span \\geq 1`.\n",
      " |      halflife : float, optional\n",
      " |          Specify decay in terms of half-life,\n",
      " |          :math:`\\alpha = 1 - exp(log(0.5) / halflife),\\text{for} halflife > 0`.\n",
      " |      alpha : float, optional\n",
      " |          Specify smoothing factor :math:`\\alpha` directly,\n",
      " |          :math:`0 < \\alpha \\leq 1`.\n",
      " |      min_periods : int, default 0\n",
      " |          Minimum number of observations in window required to have a value\n",
      " |          (otherwise result is NA).\n",
      " |      adjust : bool, default True\n",
      " |          Divide by decaying adjustment factor in beginning periods to account\n",
      " |          for imbalance in relative weightings\n",
      " |          (viewing EWMA as a moving average).\n",
      " |      ignore_na : bool, default False\n",
      " |          Ignore missing values when calculating weights;\n",
      " |          specify True to reproduce pre-0.15.0 behavior.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to use. The value 0 identifies the rows, and 1\n",
      " |          identifies the columns.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          A Window sub-classed for the particular operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      rolling : Provides rolling window calculations.\n",
      " |      expanding : Provides expanding transformations.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Exactly one of center of mass, span, half-life, and alpha must be provided.\n",
      " |      Allowed values and relationship between the parameters are specified in the\n",
      " |      parameter descriptions above; see the link at the end of this section for\n",
      " |      a detailed explanation.\n",
      " |      \n",
      " |      When adjust is True (default), weighted averages are calculated using\n",
      " |      weights (1-alpha)**(n-1), (1-alpha)**(n-2), ..., 1-alpha, 1.\n",
      " |      \n",
      " |      When adjust is False, weighted averages are calculated recursively as:\n",
      " |         weighted_average[0] = arg[0];\n",
      " |         weighted_average[i] = (1-alpha)*weighted_average[i-1] + alpha*arg[i].\n",
      " |      \n",
      " |      When ignore_na is False (default), weights are based on absolute positions.\n",
      " |      For example, the weights of x and y used in calculating the final weighted\n",
      " |      average of [x, None, y] are (1-alpha)**2 and 1 (if adjust is True), and\n",
      " |      (1-alpha)**2 and alpha (if adjust is False).\n",
      " |      \n",
      " |      When ignore_na is True (reproducing pre-0.15.0 behavior), weights are based\n",
      " |      on relative positions. For example, the weights of x and y used in\n",
      " |      calculating the final weighted average of [x, None, y] are 1-alpha and 1\n",
      " |      (if adjust is True), and 1-alpha and alpha (if adjust is False).\n",
      " |      \n",
      " |      More details can be found at\n",
      " |      https://pandas.pydata.org/pandas-docs/stable/user_guide/computation.html#exponentially-weighted-windows\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      " |      >>> df\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |      \n",
      " |      >>> df.ewm(com=0.5).mean()\n",
      " |                B\n",
      " |      0  0.000000\n",
      " |      1  0.750000\n",
      " |      2  1.615385\n",
      " |      3  1.615385\n",
      " |      4  3.670213\n",
      " |  \n",
      " |  expanding(self, min_periods=1, center=False, axis=0)\n",
      " |      Provide expanding transformations.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      min_periods : int, default 1\n",
      " |          Minimum number of observations in window required to have a value\n",
      " |          (otherwise result is NA).\n",
      " |      center : bool, default False\n",
      " |          Set the labels at the center of the window.\n",
      " |      axis : int or str, default 0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      a Window sub-classed for the particular operation\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      rolling : Provides rolling window calculations.\n",
      " |      ewm : Provides exponential weighted functions.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      By default, the result is set to the right edge of the window. This can be\n",
      " |      changed to the center of the window by setting ``center=True``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |      \n",
      " |      >>> df.expanding(2).sum()\n",
      " |           B\n",
      " |      0  NaN\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  3.0\n",
      " |      4  7.0\n",
      " |  \n",
      " |  explode(self) -> 'Series'\n",
      " |      Transform each element of a list-like to a row, replicating the\n",
      " |      index values.\n",
      " |      \n",
      " |      .. versionadded:: 0.25.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Exploded lists to rows; index will be duplicated for these rows.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.str.split : Split string values on specified separator.\n",
      " |      Series.unstack : Unstack, a.k.a. pivot, Series with MultiIndex\n",
      " |          to produce DataFrame.\n",
      " |      DataFrame.melt : Unpivot a DataFrame from wide format to long format.\n",
      " |      DataFrame.explode : Explode a DataFrame from list-like\n",
      " |          columns to long format.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This routine will explode list-likes including lists, tuples,\n",
      " |      Series, and np.ndarray. The result dtype of the subset rows will\n",
      " |      be object. Scalars will be returned unchanged. Empty list-likes will\n",
      " |      result in a np.nan for that row.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([[1, 2, 3], 'foo', [], [3, 4]])\n",
      " |      >>> s\n",
      " |      0    [1, 2, 3]\n",
      " |      1          foo\n",
      " |      2           []\n",
      " |      3       [3, 4]\n",
      " |      dtype: object\n",
      " |      \n",
      " |      >>> s.explode()\n",
      " |      0      1\n",
      " |      0      2\n",
      " |      0      3\n",
      " |      1    foo\n",
      " |      2    NaN\n",
      " |      3      3\n",
      " |      3      4\n",
      " |      dtype: object\n",
      " |  \n",
      " |  fillna(self, value=None, method=None, axis=None, inplace=False, limit=None, downcast=None) -> Union[ForwardRef('Series'), NoneType]\n",
      " |      Fill NA/NaN values using the specified method.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      value : scalar, dict, Series, or DataFrame\n",
      " |          Value to use to fill holes (e.g. 0), alternately a\n",
      " |          dict/Series/DataFrame of values specifying which value to use for\n",
      " |          each index (for a Series) or column (for a DataFrame).  Values not\n",
      " |          in the dict/Series/DataFrame will not be filled. This value cannot\n",
      " |          be a list.\n",
      " |      method : {'backfill', 'bfill', 'pad', 'ffill', None}, default None\n",
      " |          Method to use for filling holes in reindexed Series\n",
      " |          pad / ffill: propagate last valid observation forward to next valid\n",
      " |          backfill / bfill: use next valid observation to fill gap.\n",
      " |      axis : {0 or 'index'}\n",
      " |          Axis along which to fill missing values.\n",
      " |      inplace : bool, default False\n",
      " |          If True, fill in-place. Note: this will modify any\n",
      " |          other views on this object (e.g., a no-copy slice for a column in a\n",
      " |          DataFrame).\n",
      " |      limit : int, default None\n",
      " |          If method is specified, this is the maximum number of consecutive\n",
      " |          NaN values to forward/backward fill. In other words, if there is\n",
      " |          a gap with more than this number of consecutive NaNs, it will only\n",
      " |          be partially filled. If method is not specified, this is the\n",
      " |          maximum number of entries along the entire axis where NaNs will be\n",
      " |          filled. Must be greater than 0 if not None.\n",
      " |      downcast : dict, default is None\n",
      " |          A dict of item->dtype of what to downcast if possible,\n",
      " |          or the string 'infer' which will try to downcast to an appropriate\n",
      " |          equal type (e.g. float64 to int64 if possible).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or None\n",
      " |          Object with missing values filled or None if ``inplace=True``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      interpolate : Fill NaN values using interpolation.\n",
      " |      reindex : Conform object to new index.\n",
      " |      asfreq : Convert TimeSeries to specified frequency.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[np.nan, 2, np.nan, 0],\n",
      " |      ...                    [3, 4, np.nan, 1],\n",
      " |      ...                    [np.nan, np.nan, np.nan, 5],\n",
      " |      ...                    [np.nan, 3, np.nan, 4]],\n",
      " |      ...                   columns=list('ABCD'))\n",
      " |      >>> df\n",
      " |           A    B   C  D\n",
      " |      0  NaN  2.0 NaN  0\n",
      " |      1  3.0  4.0 NaN  1\n",
      " |      2  NaN  NaN NaN  5\n",
      " |      3  NaN  3.0 NaN  4\n",
      " |      \n",
      " |      Replace all NaN elements with 0s.\n",
      " |      \n",
      " |      >>> df.fillna(0)\n",
      " |          A   B   C   D\n",
      " |      0   0.0 2.0 0.0 0\n",
      " |      1   3.0 4.0 0.0 1\n",
      " |      2   0.0 0.0 0.0 5\n",
      " |      3   0.0 3.0 0.0 4\n",
      " |      \n",
      " |      We can also propagate non-null values forward or backward.\n",
      " |      \n",
      " |      >>> df.fillna(method='ffill')\n",
      " |          A   B   C   D\n",
      " |      0   NaN 2.0 NaN 0\n",
      " |      1   3.0 4.0 NaN 1\n",
      " |      2   3.0 4.0 NaN 5\n",
      " |      3   3.0 3.0 NaN 4\n",
      " |      \n",
      " |      Replace all NaN elements in column 'A', 'B', 'C', and 'D', with 0, 1,\n",
      " |      2, and 3 respectively.\n",
      " |      \n",
      " |      >>> values = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n",
      " |      >>> df.fillna(value=values)\n",
      " |          A   B   C   D\n",
      " |      0   0.0 2.0 2.0 0\n",
      " |      1   3.0 4.0 2.0 1\n",
      " |      2   0.0 1.0 2.0 5\n",
      " |      3   0.0 3.0 2.0 4\n",
      " |      \n",
      " |      Only replace the first NaN element.\n",
      " |      \n",
      " |      >>> df.fillna(value=values, limit=1)\n",
      " |          A   B   C   D\n",
      " |      0   0.0 2.0 2.0 0\n",
      " |      1   3.0 4.0 NaN 1\n",
      " |      2   NaN 1.0 NaN 5\n",
      " |      3   NaN 3.0 NaN 4\n",
      " |  \n",
      " |  floordiv(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Return Integer division of series and other, element-wise (binary operator `floordiv`).\n",
      " |      \n",
      " |      Equivalent to ``series // other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.rfloordiv\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.floordiv(b, fill_value=0)\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      c    NaN\n",
      " |      d    0.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  ge(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Return Greater than or equal to of series and other, element-wise (binary operator `ge`).\n",
      " |      \n",
      " |      Equivalent to ``series >= other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.None\n",
      " |  \n",
      " |  groupby(self, by=None, axis=0, level=None, as_index: bool = True, sort: bool = True, group_keys: bool = True, squeeze: bool = False, observed: bool = False) -> 'groupby_generic.SeriesGroupBy'\n",
      " |      Group Series using a mapper or by a Series of columns.\n",
      " |      \n",
      " |      A groupby operation involves some combination of splitting the\n",
      " |      object, applying a function, and combining the results. This can be\n",
      " |      used to group large amounts of data and compute operations on these\n",
      " |      groups.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      by : mapping, function, label, or list of labels\n",
      " |          Used to determine the groups for the groupby.\n",
      " |          If ``by`` is a function, it's called on each value of the object's\n",
      " |          index. If a dict or Series is passed, the Series or dict VALUES\n",
      " |          will be used to determine the groups (the Series' values are first\n",
      " |          aligned; see ``.align()`` method). If an ndarray is passed, the\n",
      " |          values are used as-is determine the groups. A label or list of\n",
      " |          labels may be passed to group by the columns in ``self``. Notice\n",
      " |          that a tuple is interpreted as a (single) key.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Split along rows (0) or columns (1).\n",
      " |      level : int, level name, or sequence of such, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), group by a particular\n",
      " |          level or levels.\n",
      " |      as_index : bool, default True\n",
      " |          For aggregated output, return object with group labels as the\n",
      " |          index. Only relevant for DataFrame input. as_index=False is\n",
      " |          effectively \"SQL-style\" grouped output.\n",
      " |      sort : bool, default True\n",
      " |          Sort group keys. Get better performance by turning this off.\n",
      " |          Note this does not influence the order of observations within each\n",
      " |          group. Groupby preserves the order of rows within each group.\n",
      " |      group_keys : bool, default True\n",
      " |          When calling apply, add group keys to index to identify pieces.\n",
      " |      squeeze : bool, default False\n",
      " |          Reduce the dimensionality of the return type if possible,\n",
      " |          otherwise return a consistent type.\n",
      " |      observed : bool, default False\n",
      " |          This only applies if any of the groupers are Categoricals.\n",
      " |          If True: only show observed values for categorical groupers.\n",
      " |          If False: show all values for categorical groupers.\n",
      " |      \n",
      " |          .. versionadded:: 0.23.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      SeriesGroupBy\n",
      " |          Returns a groupby object that contains information about the groups.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      resample : Convenience method for frequency conversion and resampling\n",
      " |          of time series.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the `user guide\n",
      " |      <https://pandas.pydata.org/pandas-docs/stable/groupby.html>`_ for more.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> ser = pd.Series([390., 350., 30., 20.],\n",
      " |      ...                 index=['Falcon', 'Falcon', 'Parrot', 'Parrot'], name=\"Max Speed\")\n",
      " |      >>> ser\n",
      " |      Falcon    390.0\n",
      " |      Falcon    350.0\n",
      " |      Parrot     30.0\n",
      " |      Parrot     20.0\n",
      " |      Name: Max Speed, dtype: float64\n",
      " |      >>> ser.groupby([\"a\", \"b\", \"a\", \"b\"]).mean()\n",
      " |      a    210.0\n",
      " |      b    185.0\n",
      " |      Name: Max Speed, dtype: float64\n",
      " |      >>> ser.groupby(level=0).mean()\n",
      " |      Falcon    370.0\n",
      " |      Parrot     25.0\n",
      " |      Name: Max Speed, dtype: float64\n",
      " |      >>> ser.groupby(ser > 100).mean()\n",
      " |      Max Speed\n",
      " |      False     25.0\n",
      " |      True     370.0\n",
      " |      Name: Max Speed, dtype: float64\n",
      " |      \n",
      " |      **Grouping by Indexes**\n",
      " |      \n",
      " |      We can groupby different levels of a hierarchical index\n",
      " |      using the `level` parameter:\n",
      " |      \n",
      " |      >>> arrays = [['Falcon', 'Falcon', 'Parrot', 'Parrot'],\n",
      " |      ...           ['Captive', 'Wild', 'Captive', 'Wild']]\n",
      " |      >>> index = pd.MultiIndex.from_arrays(arrays, names=('Animal', 'Type'))\n",
      " |      >>> ser = pd.Series([390., 350., 30., 20.], index=index, name=\"Max Speed\")\n",
      " |      >>> ser\n",
      " |      Animal  Type\n",
      " |      Falcon  Captive    390.0\n",
      " |              Wild       350.0\n",
      " |      Parrot  Captive     30.0\n",
      " |              Wild        20.0\n",
      " |      Name: Max Speed, dtype: float64\n",
      " |      >>> ser.groupby(level=0).mean()\n",
      " |      Animal\n",
      " |      Falcon    370.0\n",
      " |      Parrot     25.0\n",
      " |      Name: Max Speed, dtype: float64\n",
      " |      >>> ser.groupby(level=\"Type\").mean()\n",
      " |      Type\n",
      " |      Captive    210.0\n",
      " |      Wild       185.0\n",
      " |      Name: Max Speed, dtype: float64\n",
      " |  \n",
      " |  gt(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Return Greater than of series and other, element-wise (binary operator `gt`).\n",
      " |      \n",
      " |      Equivalent to ``series > other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.None\n",
      " |  \n",
      " |  hist = hist_series(self, by=None, ax=None, grid=True, xlabelsize=None, xrot=None, ylabelsize=None, yrot=None, figsize=None, bins=10, backend=None, **kwargs)\n",
      " |      Draw histogram of the input series using matplotlib.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      by : object, optional\n",
      " |          If passed, then used to form histograms for separate groups.\n",
      " |      ax : matplotlib axis object\n",
      " |          If not passed, uses gca().\n",
      " |      grid : bool, default True\n",
      " |          Whether to show axis grid lines.\n",
      " |      xlabelsize : int, default None\n",
      " |          If specified changes the x-axis label size.\n",
      " |      xrot : float, default None\n",
      " |          Rotation of x axis labels.\n",
      " |      ylabelsize : int, default None\n",
      " |          If specified changes the y-axis label size.\n",
      " |      yrot : float, default None\n",
      " |          Rotation of y axis labels.\n",
      " |      figsize : tuple, default None\n",
      " |          Figure size in inches by default.\n",
      " |      bins : int or sequence, default 10\n",
      " |          Number of histogram bins to be used. If an integer is given, bins + 1\n",
      " |          bin edges are calculated and returned. If bins is a sequence, gives\n",
      " |          bin edges, including left edge of first bin and right edge of last\n",
      " |          bin. In this case, bins is returned unmodified.\n",
      " |      backend : str, default None\n",
      " |          Backend to use instead of the backend specified in the option\n",
      " |          ``plotting.backend``. For instance, 'matplotlib'. Alternatively, to\n",
      " |          specify the ``plotting.backend`` for the whole session, set\n",
      " |          ``pd.options.plotting.backend``.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      **kwargs\n",
      " |          To be passed to the actual plotting function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      matplotlib.AxesSubplot\n",
      " |          A histogram plot.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      matplotlib.axes.Axes.hist : Plot a histogram using matplotlib.\n",
      " |  \n",
      " |  idxmax(self, axis=0, skipna=True, *args, **kwargs)\n",
      " |      Return the row label of the maximum value.\n",
      " |      \n",
      " |      If multiple values equal the maximum, the first row label with that\n",
      " |      value is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : int, default 0\n",
      " |          For compatibility with DataFrame.idxmax. Redundant for application\n",
      " |          on Series.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If the entire Series is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs\n",
      " |          Additional arguments and keywords have no effect but might be\n",
      " |          accepted for compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index\n",
      " |          Label of the maximum value.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          If the Series is empty.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.argmax : Return indices of the maximum values\n",
      " |          along the given axis.\n",
      " |      DataFrame.idxmax : Return index of first occurrence of maximum\n",
      " |          over requested axis.\n",
      " |      Series.idxmin : Return index *label* of the first occurrence\n",
      " |          of minimum of values.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the Series version of ``ndarray.argmax``. This method\n",
      " |      returns the label of the maximum, while ``ndarray.argmax`` returns\n",
      " |      the position. To get the position, use ``series.values.argmax()``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(data=[1, None, 4, 3, 4],\n",
      " |      ...               index=['A', 'B', 'C', 'D', 'E'])\n",
      " |      >>> s\n",
      " |      A    1.0\n",
      " |      B    NaN\n",
      " |      C    4.0\n",
      " |      D    3.0\n",
      " |      E    4.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.idxmax()\n",
      " |      'C'\n",
      " |      \n",
      " |      If `skipna` is False and there is an NA value in the data,\n",
      " |      the function returns ``nan``.\n",
      " |      \n",
      " |      >>> s.idxmax(skipna=False)\n",
      " |      nan\n",
      " |  \n",
      " |  idxmin(self, axis=0, skipna=True, *args, **kwargs)\n",
      " |      Return the row label of the minimum value.\n",
      " |      \n",
      " |      If multiple values equal the minimum, the first row label with that\n",
      " |      value is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : int, default 0\n",
      " |          For compatibility with DataFrame.idxmin. Redundant for application\n",
      " |          on Series.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If the entire Series is NA, the result\n",
      " |          will be NA.\n",
      " |      *args, **kwargs\n",
      " |          Additional arguments and keywords have no effect but might be\n",
      " |          accepted for compatibility with NumPy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index\n",
      " |          Label of the minimum value.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          If the Series is empty.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.argmin : Return indices of the minimum values\n",
      " |          along the given axis.\n",
      " |      DataFrame.idxmin : Return index of first occurrence of minimum\n",
      " |          over requested axis.\n",
      " |      Series.idxmax : Return index *label* of the first occurrence\n",
      " |          of maximum of values.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the Series version of ``ndarray.argmin``. This method\n",
      " |      returns the label of the minimum, while ``ndarray.argmin`` returns\n",
      " |      the position. To get the position, use ``series.values.argmin()``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(data=[1, None, 4, 1],\n",
      " |      ...               index=['A', 'B', 'C', 'D'])\n",
      " |      >>> s\n",
      " |      A    1.0\n",
      " |      B    NaN\n",
      " |      C    4.0\n",
      " |      D    1.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.idxmin()\n",
      " |      'A'\n",
      " |      \n",
      " |      If `skipna` is False and there is an NA value in the data,\n",
      " |      the function returns ``nan``.\n",
      " |      \n",
      " |      >>> s.idxmin(skipna=False)\n",
      " |      nan\n",
      " |  \n",
      " |  isin(self, values)\n",
      " |      Check whether `values` are contained in Series.\n",
      " |      \n",
      " |      Return a boolean Series showing whether each element in the Series\n",
      " |      matches an element in the passed sequence of `values` exactly.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      values : set or list-like\n",
      " |          The sequence of values to test. Passing in a single string will\n",
      " |          raise a ``TypeError``. Instead, turn a single string into a\n",
      " |          list of one element.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Series of booleans indicating if each element is in values.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |        * If `values` is a string\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.isin : Equivalent method on DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(['lama', 'cow', 'lama', 'beetle', 'lama',\n",
      " |      ...                'hippo'], name='animal')\n",
      " |      >>> s.isin(['cow', 'lama'])\n",
      " |      0     True\n",
      " |      1     True\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      4     True\n",
      " |      5    False\n",
      " |      Name: animal, dtype: bool\n",
      " |      \n",
      " |      Passing a single string as ``s.isin('lama')`` will raise an error. Use\n",
      " |      a list of one element instead:\n",
      " |      \n",
      " |      >>> s.isin(['lama'])\n",
      " |      0     True\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      3    False\n",
      " |      4     True\n",
      " |      5    False\n",
      " |      Name: animal, dtype: bool\n",
      " |  \n",
      " |  isna(self)\n",
      " |      Detect missing values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are NA.\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, gets mapped to True\n",
      " |      values.\n",
      " |      Everything else gets mapped to False values. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Mask of bool values for each element in Series that\n",
      " |          indicates whether an element is not an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.isnull : Alias of isna.\n",
      " |      Series.notna : Boolean inverse of isna.\n",
      " |      Series.dropna : Omit axes labels with missing values.\n",
      " |      isna : Top-level isna.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'age': [5, 6, np.NaN],\n",
      " |      ...                    'born': [pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                             pd.Timestamp('1940-04-25')],\n",
      " |      ...                    'name': ['Alfred', 'Batman', ''],\n",
      " |      ...                    'toy': [None, 'Batmobile', 'Joker']})\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.isna()\n",
      " |           age   born   name    toy\n",
      " |      0  False   True  False   True\n",
      " |      1  False  False  False  False\n",
      " |      2   True  False  False  False\n",
      " |      \n",
      " |      Show which entries in a Series are NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.isna()\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  isnull(self)\n",
      " |      Detect missing values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are NA.\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, gets mapped to True\n",
      " |      values.\n",
      " |      Everything else gets mapped to False values. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Mask of bool values for each element in Series that\n",
      " |          indicates whether an element is not an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.isnull : Alias of isna.\n",
      " |      Series.notna : Boolean inverse of isna.\n",
      " |      Series.dropna : Omit axes labels with missing values.\n",
      " |      isna : Top-level isna.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'age': [5, 6, np.NaN],\n",
      " |      ...                    'born': [pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                             pd.Timestamp('1940-04-25')],\n",
      " |      ...                    'name': ['Alfred', 'Batman', ''],\n",
      " |      ...                    'toy': [None, 'Batmobile', 'Joker']})\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.isna()\n",
      " |           age   born   name    toy\n",
      " |      0  False   True  False   True\n",
      " |      1  False  False  False  False\n",
      " |      2   True  False  False  False\n",
      " |      \n",
      " |      Show which entries in a Series are NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.isna()\n",
      " |      0    False\n",
      " |      1    False\n",
      " |      2     True\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  items(self)\n",
      " |      Lazily iterate over (index, value) tuples.\n",
      " |      \n",
      " |      This method returns an iterable tuple (index, value). This is\n",
      " |      convenient if you want to create a lazy iterator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      iterable\n",
      " |          Iterable of tuples containing the (index, value) pairs from a\n",
      " |          Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.items : Iterate over (column name, Series) pairs.\n",
      " |      DataFrame.iterrows : Iterate over DataFrame rows as (index, Series) pairs.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(['A', 'B', 'C'])\n",
      " |      >>> for index, value in s.items():\n",
      " |      ...     print(f\"Index : {index}, Value : {value}\")\n",
      " |      Index : 0, Value : A\n",
      " |      Index : 1, Value : B\n",
      " |      Index : 2, Value : C\n",
      " |  \n",
      " |  iteritems(self)\n",
      " |      Lazily iterate over (index, value) tuples.\n",
      " |      \n",
      " |      This method returns an iterable tuple (index, value). This is\n",
      " |      convenient if you want to create a lazy iterator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      iterable\n",
      " |          Iterable of tuples containing the (index, value) pairs from a\n",
      " |          Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.items : Iterate over (column name, Series) pairs.\n",
      " |      DataFrame.iterrows : Iterate over DataFrame rows as (index, Series) pairs.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(['A', 'B', 'C'])\n",
      " |      >>> for index, value in s.items():\n",
      " |      ...     print(f\"Index : {index}, Value : {value}\")\n",
      " |      Index : 0, Value : A\n",
      " |      Index : 1, Value : B\n",
      " |      Index : 2, Value : C\n",
      " |  \n",
      " |  keys(self)\n",
      " |      Return alias for index.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index\n",
      " |          Index of the Series.\n",
      " |  \n",
      " |  kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return unbiased kurtosis over requested axis.\n",
      " |      \n",
      " |      Kurtosis obtained using Fisher's definition of\n",
      " |      kurtosis (kurtosis of normal == 0.0). Normalized by N-1.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series (if level specified)\n",
      " |  \n",
      " |  kurtosis = kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |  \n",
      " |  le(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Return Less than or equal to of series and other, element-wise (binary operator `le`).\n",
      " |      \n",
      " |      Equivalent to ``series <= other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.None\n",
      " |  \n",
      " |  lt(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Return Less than of series and other, element-wise (binary operator `lt`).\n",
      " |      \n",
      " |      Equivalent to ``series < other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.None\n",
      " |  \n",
      " |  mad(self, axis=None, skipna=None, level=None)\n",
      " |      Return the mean absolute deviation of the values for the requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series (if level specified)\n",
      " |  \n",
      " |  map(self, arg, na_action=None)\n",
      " |      Map values of Series according to input correspondence.\n",
      " |      \n",
      " |      Used for substituting each value in a Series with another value,\n",
      " |      that may be derived from a function, a ``dict`` or\n",
      " |      a :class:`Series`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      arg : function, collections.abc.Mapping subclass or Series\n",
      " |          Mapping correspondence.\n",
      " |      na_action : {None, 'ignore'}, default None\n",
      " |          If 'ignore', propagate NaN values, without passing them to the\n",
      " |          mapping correspondence.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Same index as caller.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.apply : For applying more complex functions on a Series.\n",
      " |      DataFrame.apply : Apply a function row-/column-wise.\n",
      " |      DataFrame.applymap : Apply a function elementwise on a whole DataFrame.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      When ``arg`` is a dictionary, values in Series that are not in the\n",
      " |      dictionary (as keys) are converted to ``NaN``. However, if the\n",
      " |      dictionary is a ``dict`` subclass that defines ``__missing__`` (i.e.\n",
      " |      provides a method for default values), then this default is used\n",
      " |      rather than ``NaN``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(['cat', 'dog', np.nan, 'rabbit'])\n",
      " |      >>> s\n",
      " |      0      cat\n",
      " |      1      dog\n",
      " |      2      NaN\n",
      " |      3   rabbit\n",
      " |      dtype: object\n",
      " |      \n",
      " |      ``map`` accepts a ``dict`` or a ``Series``. Values that are not found\n",
      " |      in the ``dict`` are converted to ``NaN``, unless the dict has a default\n",
      " |      value (e.g. ``defaultdict``):\n",
      " |      \n",
      " |      >>> s.map({'cat': 'kitten', 'dog': 'puppy'})\n",
      " |      0   kitten\n",
      " |      1    puppy\n",
      " |      2      NaN\n",
      " |      3      NaN\n",
      " |      dtype: object\n",
      " |      \n",
      " |      It also accepts a function:\n",
      " |      \n",
      " |      >>> s.map('I am a {}'.format)\n",
      " |      0       I am a cat\n",
      " |      1       I am a dog\n",
      " |      2       I am a nan\n",
      " |      3    I am a rabbit\n",
      " |      dtype: object\n",
      " |      \n",
      " |      To avoid applying the function to missing values (and keep them as\n",
      " |      ``NaN``) ``na_action='ignore'`` can be used:\n",
      " |      \n",
      " |      >>> s.map('I am a {}'.format, na_action='ignore')\n",
      " |      0     I am a cat\n",
      " |      1     I am a dog\n",
      " |      2            NaN\n",
      " |      3  I am a rabbit\n",
      " |      dtype: object\n",
      " |  \n",
      " |  max(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the maximum of the values for the requested axis.\n",
      " |      \n",
      " |                  If you want the *index* of the maximum, use ``idxmax``. This is\n",
      " |                  the equivalent of the ``numpy.ndarray`` method ``argmax``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series (if level specified)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sum : Return the sum.\n",
      " |      Series.min : Return the minimum.\n",
      " |      Series.max : Return the maximum.\n",
      " |      Series.idxmin : Return the index of the minimum.\n",
      " |      Series.idxmax : Return the index of the maximum.\n",
      " |      DataFrame.sum : Return the sum over the requested axis.\n",
      " |      DataFrame.min : Return the minimum over the requested axis.\n",
      " |      DataFrame.max : Return the maximum over the requested axis.\n",
      " |      DataFrame.idxmin : Return the index of the minimum over the requested axis.\n",
      " |      DataFrame.idxmax : Return the index of the maximum over the requested axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.MultiIndex.from_arrays([\n",
      " |      ...     ['warm', 'warm', 'cold', 'cold'],\n",
      " |      ...     ['dog', 'falcon', 'fish', 'spider']],\n",
      " |      ...     names=['blooded', 'animal'])\n",
      " |      >>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n",
      " |      >>> s\n",
      " |      blooded  animal\n",
      " |      warm     dog       4\n",
      " |               falcon    2\n",
      " |      cold     fish      0\n",
      " |               spider    8\n",
      " |      Name: legs, dtype: int64\n",
      " |      \n",
      " |      >>> s.max()\n",
      " |      8\n",
      " |      \n",
      " |      Max using level names, as well as indices.\n",
      " |      \n",
      " |      >>> s.max(level='blooded')\n",
      " |      blooded\n",
      " |      warm    4\n",
      " |      cold    8\n",
      " |      Name: legs, dtype: int64\n",
      " |      \n",
      " |      >>> s.max(level=0)\n",
      " |      blooded\n",
      " |      warm    4\n",
      " |      cold    8\n",
      " |      Name: legs, dtype: int64\n",
      " |  \n",
      " |  mean(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the mean of the values for the requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series (if level specified)\n",
      " |  \n",
      " |  median(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the median of the values for the requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series (if level specified)\n",
      " |  \n",
      " |  memory_usage(self, index=True, deep=False)\n",
      " |      Return the memory usage of the Series.\n",
      " |      \n",
      " |      The memory usage can optionally include the contribution of\n",
      " |      the index and of elements of `object` dtype.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : bool, default True\n",
      " |          Specifies whether to include the memory usage of the Series index.\n",
      " |      deep : bool, default False\n",
      " |          If True, introspect the data deeply by interrogating\n",
      " |          `object` dtypes for system-level memory consumption, and include\n",
      " |          it in the returned value.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      int\n",
      " |          Bytes of memory consumed.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.nbytes : Total bytes consumed by the elements of the\n",
      " |          array.\n",
      " |      DataFrame.memory_usage : Bytes consumed by a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(range(3))\n",
      " |      >>> s.memory_usage()\n",
      " |      152\n",
      " |      \n",
      " |      Not including the index gives the size of the rest of the data, which\n",
      " |      is necessarily smaller:\n",
      " |      \n",
      " |      >>> s.memory_usage(index=False)\n",
      " |      24\n",
      " |      \n",
      " |      The memory footprint of `object` values is ignored by default:\n",
      " |      \n",
      " |      >>> s = pd.Series([\"a\", \"b\"])\n",
      " |      >>> s.values\n",
      " |      array(['a', 'b'], dtype=object)\n",
      " |      >>> s.memory_usage()\n",
      " |      144\n",
      " |      >>> s.memory_usage(deep=True)\n",
      " |      260\n",
      " |  \n",
      " |  min(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the minimum of the values for the requested axis.\n",
      " |      \n",
      " |                  If you want the *index* of the minimum, use ``idxmin``. This is\n",
      " |                  the equivalent of the ``numpy.ndarray`` method ``argmin``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series (if level specified)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sum : Return the sum.\n",
      " |      Series.min : Return the minimum.\n",
      " |      Series.max : Return the maximum.\n",
      " |      Series.idxmin : Return the index of the minimum.\n",
      " |      Series.idxmax : Return the index of the maximum.\n",
      " |      DataFrame.sum : Return the sum over the requested axis.\n",
      " |      DataFrame.min : Return the minimum over the requested axis.\n",
      " |      DataFrame.max : Return the maximum over the requested axis.\n",
      " |      DataFrame.idxmin : Return the index of the minimum over the requested axis.\n",
      " |      DataFrame.idxmax : Return the index of the maximum over the requested axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.MultiIndex.from_arrays([\n",
      " |      ...     ['warm', 'warm', 'cold', 'cold'],\n",
      " |      ...     ['dog', 'falcon', 'fish', 'spider']],\n",
      " |      ...     names=['blooded', 'animal'])\n",
      " |      >>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n",
      " |      >>> s\n",
      " |      blooded  animal\n",
      " |      warm     dog       4\n",
      " |               falcon    2\n",
      " |      cold     fish      0\n",
      " |               spider    8\n",
      " |      Name: legs, dtype: int64\n",
      " |      \n",
      " |      >>> s.min()\n",
      " |      0\n",
      " |      \n",
      " |      Min using level names, as well as indices.\n",
      " |      \n",
      " |      >>> s.min(level='blooded')\n",
      " |      blooded\n",
      " |      warm    2\n",
      " |      cold    0\n",
      " |      Name: legs, dtype: int64\n",
      " |      \n",
      " |      >>> s.min(level=0)\n",
      " |      blooded\n",
      " |      warm    2\n",
      " |      cold    0\n",
      " |      Name: legs, dtype: int64\n",
      " |  \n",
      " |  mod(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Return Modulo of series and other, element-wise (binary operator `mod`).\n",
      " |      \n",
      " |      Equivalent to ``series % other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.rmod\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.mod(b, fill_value=0)\n",
      " |      a    0.0\n",
      " |      b    NaN\n",
      " |      c    NaN\n",
      " |      d    0.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  mode(self, dropna=True)\n",
      " |      Return the mode(s) of the dataset.\n",
      " |      \n",
      " |      Always returns Series even if only one value is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dropna : bool, default True\n",
      " |          Don't consider counts of NaN/NaT.\n",
      " |      \n",
      " |          .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Modes of the Series in sorted order.\n",
      " |  \n",
      " |  mul(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Return Multiplication of series and other, element-wise (binary operator `mul`).\n",
      " |      \n",
      " |      Equivalent to ``series * other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.rmul\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.multiply(b, fill_value=0)\n",
      " |      a    1.0\n",
      " |      b    0.0\n",
      " |      c    0.0\n",
      " |      d    0.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  multiply = mul(self, other, level=None, fill_value=None, axis=0)\n",
      " |  \n",
      " |  ne(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Return Not equal to of series and other, element-wise (binary operator `ne`).\n",
      " |      \n",
      " |      Equivalent to ``series != other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.None\n",
      " |  \n",
      " |  nlargest(self, n=5, keep='first')\n",
      " |      Return the largest `n` elements.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, default 5\n",
      " |          Return this many descending sorted values.\n",
      " |      keep : {'first', 'last', 'all'}, default 'first'\n",
      " |          When there are duplicate values that cannot all fit in a\n",
      " |          Series of `n` elements:\n",
      " |      \n",
      " |          - ``first`` : return the first `n` occurrences in order\n",
      " |              of appearance.\n",
      " |          - ``last`` : return the last `n` occurrences in reverse\n",
      " |              order of appearance.\n",
      " |          - ``all`` : keep all occurrences. This can result in a Series of\n",
      " |              size larger than `n`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The `n` largest values in the Series, sorted in decreasing order.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.nsmallest: Get the `n` smallest elements.\n",
      " |      Series.sort_values: Sort Series by values.\n",
      " |      Series.head: Return the first `n` rows.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Faster than ``.sort_values(ascending=False).head(n)`` for small `n`\n",
      " |      relative to the size of the ``Series`` object.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> countries_population = {\"Italy\": 59000000, \"France\": 65000000,\n",
      " |      ...                         \"Malta\": 434000, \"Maldives\": 434000,\n",
      " |      ...                         \"Brunei\": 434000, \"Iceland\": 337000,\n",
      " |      ...                         \"Nauru\": 11300, \"Tuvalu\": 11300,\n",
      " |      ...                         \"Anguilla\": 11300, \"Monserat\": 5200}\n",
      " |      >>> s = pd.Series(countries_population)\n",
      " |      >>> s\n",
      " |      Italy       59000000\n",
      " |      France      65000000\n",
      " |      Malta         434000\n",
      " |      Maldives      434000\n",
      " |      Brunei        434000\n",
      " |      Iceland       337000\n",
      " |      Nauru          11300\n",
      " |      Tuvalu         11300\n",
      " |      Anguilla       11300\n",
      " |      Monserat        5200\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      The `n` largest elements where ``n=5`` by default.\n",
      " |      \n",
      " |      >>> s.nlargest()\n",
      " |      France      65000000\n",
      " |      Italy       59000000\n",
      " |      Malta         434000\n",
      " |      Maldives      434000\n",
      " |      Brunei        434000\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      The `n` largest elements where ``n=3``. Default `keep` value is 'first'\n",
      " |      so Malta will be kept.\n",
      " |      \n",
      " |      >>> s.nlargest(3)\n",
      " |      France    65000000\n",
      " |      Italy     59000000\n",
      " |      Malta       434000\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      The `n` largest elements where ``n=3`` and keeping the last duplicates.\n",
      " |      Brunei will be kept since it is the last with value 434000 based on\n",
      " |      the index order.\n",
      " |      \n",
      " |      >>> s.nlargest(3, keep='last')\n",
      " |      France      65000000\n",
      " |      Italy       59000000\n",
      " |      Brunei        434000\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      The `n` largest elements where ``n=3`` with all duplicates kept. Note\n",
      " |      that the returned Series has five elements due to the three duplicates.\n",
      " |      \n",
      " |      >>> s.nlargest(3, keep='all')\n",
      " |      France      65000000\n",
      " |      Italy       59000000\n",
      " |      Malta         434000\n",
      " |      Maldives      434000\n",
      " |      Brunei        434000\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  notna(self)\n",
      " |      Detect existing (non-missing) values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are not NA.\n",
      " |      Non-missing values get mapped to True. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, get mapped to False\n",
      " |      values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Mask of bool values for each element in Series that\n",
      " |          indicates whether an element is not an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.notnull : Alias of notna.\n",
      " |      Series.isna : Boolean inverse of notna.\n",
      " |      Series.dropna : Omit axes labels with missing values.\n",
      " |      notna : Top-level notna.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are not NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'age': [5, 6, np.NaN],\n",
      " |      ...                    'born': [pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                             pd.Timestamp('1940-04-25')],\n",
      " |      ...                    'name': ['Alfred', 'Batman', ''],\n",
      " |      ...                    'toy': [None, 'Batmobile', 'Joker']})\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.notna()\n",
      " |           age   born  name    toy\n",
      " |      0   True  False  True  False\n",
      " |      1   True   True  True   True\n",
      " |      2  False   True  True   True\n",
      " |      \n",
      " |      Show which entries in a Series are not NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.notna()\n",
      " |      0     True\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  notnull(self)\n",
      " |      Detect existing (non-missing) values.\n",
      " |      \n",
      " |      Return a boolean same-sized object indicating if the values are not NA.\n",
      " |      Non-missing values get mapped to True. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
      " |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, get mapped to False\n",
      " |      values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Mask of bool values for each element in Series that\n",
      " |          indicates whether an element is not an NA value.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.notnull : Alias of notna.\n",
      " |      Series.isna : Boolean inverse of notna.\n",
      " |      Series.dropna : Omit axes labels with missing values.\n",
      " |      notna : Top-level notna.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a DataFrame are not NA.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'age': [5, 6, np.NaN],\n",
      " |      ...                    'born': [pd.NaT, pd.Timestamp('1939-05-27'),\n",
      " |      ...                             pd.Timestamp('1940-04-25')],\n",
      " |      ...                    'name': ['Alfred', 'Batman', ''],\n",
      " |      ...                    'toy': [None, 'Batmobile', 'Joker']})\n",
      " |      >>> df\n",
      " |         age       born    name        toy\n",
      " |      0  5.0        NaT  Alfred       None\n",
      " |      1  6.0 1939-05-27  Batman  Batmobile\n",
      " |      2  NaN 1940-04-25              Joker\n",
      " |      \n",
      " |      >>> df.notna()\n",
      " |           age   born  name    toy\n",
      " |      0   True  False  True  False\n",
      " |      1   True   True  True   True\n",
      " |      2  False   True  True   True\n",
      " |      \n",
      " |      Show which entries in a Series are not NA.\n",
      " |      \n",
      " |      >>> ser = pd.Series([5, 6, np.NaN])\n",
      " |      >>> ser\n",
      " |      0    5.0\n",
      " |      1    6.0\n",
      " |      2    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> ser.notna()\n",
      " |      0     True\n",
      " |      1     True\n",
      " |      2    False\n",
      " |      dtype: bool\n",
      " |  \n",
      " |  nsmallest(self, n=5, keep='first')\n",
      " |      Return the smallest `n` elements.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, default 5\n",
      " |          Return this many ascending sorted values.\n",
      " |      keep : {'first', 'last', 'all'}, default 'first'\n",
      " |          When there are duplicate values that cannot all fit in a\n",
      " |          Series of `n` elements:\n",
      " |      \n",
      " |          - ``first`` : return the first `n` occurrences in order\n",
      " |              of appearance.\n",
      " |          - ``last`` : return the last `n` occurrences in reverse\n",
      " |              order of appearance.\n",
      " |          - ``all`` : keep all occurrences. This can result in a Series of\n",
      " |              size larger than `n`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The `n` smallest values in the Series, sorted in increasing order.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.nlargest: Get the `n` largest elements.\n",
      " |      Series.sort_values: Sort Series by values.\n",
      " |      Series.head: Return the first `n` rows.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Faster than ``.sort_values().head(n)`` for small `n` relative to\n",
      " |      the size of the ``Series`` object.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> countries_population = {\"Italy\": 59000000, \"France\": 65000000,\n",
      " |      ...                         \"Brunei\": 434000, \"Malta\": 434000,\n",
      " |      ...                         \"Maldives\": 434000, \"Iceland\": 337000,\n",
      " |      ...                         \"Nauru\": 11300, \"Tuvalu\": 11300,\n",
      " |      ...                         \"Anguilla\": 11300, \"Monserat\": 5200}\n",
      " |      >>> s = pd.Series(countries_population)\n",
      " |      >>> s\n",
      " |      Italy       59000000\n",
      " |      France      65000000\n",
      " |      Brunei        434000\n",
      " |      Malta         434000\n",
      " |      Maldives      434000\n",
      " |      Iceland       337000\n",
      " |      Nauru          11300\n",
      " |      Tuvalu         11300\n",
      " |      Anguilla       11300\n",
      " |      Monserat        5200\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      The `n` smallest elements where ``n=5`` by default.\n",
      " |      \n",
      " |      >>> s.nsmallest()\n",
      " |      Monserat      5200\n",
      " |      Nauru        11300\n",
      " |      Tuvalu       11300\n",
      " |      Anguilla     11300\n",
      " |      Iceland     337000\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      The `n` smallest elements where ``n=3``. Default `keep` value is\n",
      " |      'first' so Nauru and Tuvalu will be kept.\n",
      " |      \n",
      " |      >>> s.nsmallest(3)\n",
      " |      Monserat     5200\n",
      " |      Nauru       11300\n",
      " |      Tuvalu      11300\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      The `n` smallest elements where ``n=3`` and keeping the last\n",
      " |      duplicates. Anguilla and Tuvalu will be kept since they are the last\n",
      " |      with value 11300 based on the index order.\n",
      " |      \n",
      " |      >>> s.nsmallest(3, keep='last')\n",
      " |      Monserat     5200\n",
      " |      Anguilla    11300\n",
      " |      Tuvalu      11300\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      The `n` smallest elements where ``n=3`` with all duplicates kept. Note\n",
      " |      that the returned Series has four elements due to the three duplicates.\n",
      " |      \n",
      " |      >>> s.nsmallest(3, keep='all')\n",
      " |      Monserat     5200\n",
      " |      Nauru       11300\n",
      " |      Tuvalu      11300\n",
      " |      Anguilla    11300\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  pow(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Return Exponential power of series and other, element-wise (binary operator `pow`).\n",
      " |      \n",
      " |      Equivalent to ``series ** other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.rpow\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.pow(b, fill_value=0)\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    0.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  prod(self, axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)\n",
      " |      Return the product of the values for the requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      min_count : int, default 0\n",
      " |          The required number of valid values to perform the operation. If fewer than\n",
      " |          ``min_count`` non-NA values are present the result will be NA.\n",
      " |      \n",
      " |          .. versionadded:: 0.22.0\n",
      " |      \n",
      " |             Added with the default being 0. This means the sum of an all-NA\n",
      " |             or empty Series is 0, and the product of an all-NA or empty\n",
      " |             Series is 1.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series (if level specified)\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      By default, the product of an empty or all-NA Series is ``1``\n",
      " |      \n",
      " |      >>> pd.Series([]).prod()\n",
      " |      1.0\n",
      " |      \n",
      " |      This can be controlled with the ``min_count`` parameter\n",
      " |      \n",
      " |      >>> pd.Series([]).prod(min_count=1)\n",
      " |      nan\n",
      " |      \n",
      " |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
      " |      empty series identically.\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).prod()\n",
      " |      1.0\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).prod(min_count=1)\n",
      " |      nan\n",
      " |  \n",
      " |  product = prod(self, axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)\n",
      " |  \n",
      " |  quantile(self, q=0.5, interpolation='linear')\n",
      " |      Return value at the given quantile.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      q : float or array-like, default 0.5 (50% quantile)\n",
      " |          The quantile(s) to compute, which can lie in range: 0 <= q <= 1.\n",
      " |      interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\n",
      " |          This optional parameter specifies the interpolation method to use,\n",
      " |          when the desired quantile lies between two data points `i` and `j`:\n",
      " |      \n",
      " |              * linear: `i + (j - i) * fraction`, where `fraction` is the\n",
      " |                fractional part of the index surrounded by `i` and `j`.\n",
      " |              * lower: `i`.\n",
      " |              * higher: `j`.\n",
      " |              * nearest: `i` or `j` whichever is nearest.\n",
      " |              * midpoint: (`i` + `j`) / 2.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      float or Series\n",
      " |          If ``q`` is an array, a Series will be returned where the\n",
      " |          index is ``q`` and the values are the quantiles, otherwise\n",
      " |          a float will be returned.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.window.Rolling.quantile\n",
      " |      numpy.percentile\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s.quantile(.5)\n",
      " |      2.5\n",
      " |      >>> s.quantile([.25, .5, .75])\n",
      " |      0.25    1.75\n",
      " |      0.50    2.50\n",
      " |      0.75    3.25\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  radd(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Return Addition of series and other, element-wise (binary operator `radd`).\n",
      " |      \n",
      " |      Equivalent to ``other + series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.add\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.add(b, fill_value=0)\n",
      " |      a    2.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  ravel(self, order='C')\n",
      " |      Return the flattened underlying data as an ndarray.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray or ndarray-like\n",
      " |          Flattened data of the Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.ravel\n",
      " |  \n",
      " |  rdiv = rtruediv(self, other, level=None, fill_value=None, axis=0)\n",
      " |  \n",
      " |  rdivmod(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Return Integer division and modulo of series and other, element-wise (binary operator `rdivmod`).\n",
      " |      \n",
      " |      Equivalent to ``other divmod series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.divmod\n",
      " |  \n",
      " |  reindex(self, index=None, **kwargs)\n",
      " |      Conform Series to new index with optional filling logic.\n",
      " |      \n",
      " |      Places NA/NaN in locations having no value in the previous index. A new object\n",
      " |      is produced unless the new index is equivalent to the current one and\n",
      " |      ``copy=False``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      \n",
      " |      index : array-like, optional\n",
      " |          New labels / index to conform to, should be specified using\n",
      " |          keywords. Preferably an Index object to avoid duplicating data.\n",
      " |      \n",
      " |      method : {None, 'backfill'/'bfill', 'pad'/'ffill', 'nearest'}\n",
      " |          Method to use for filling holes in reindexed DataFrame.\n",
      " |          Please note: this is only applicable to DataFrames/Series with a\n",
      " |          monotonically increasing/decreasing index.\n",
      " |      \n",
      " |          * None (default): don't fill gaps\n",
      " |          * pad / ffill: Propagate last valid observation forward to next\n",
      " |            valid.\n",
      " |          * backfill / bfill: Use next valid observation to fill gap.\n",
      " |          * nearest: Use nearest valid observations to fill gap.\n",
      " |      \n",
      " |      copy : bool, default True\n",
      " |          Return a new object, even if the passed indexes are the same.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      fill_value : scalar, default np.NaN\n",
      " |          Value to use for missing values. Defaults to NaN, but can be any\n",
      " |          \"compatible\" value.\n",
      " |      limit : int, default None\n",
      " |          Maximum number of consecutive elements to forward or backward fill.\n",
      " |      tolerance : optional\n",
      " |          Maximum distance between original and new labels for inexact\n",
      " |          matches. The values of the index at the matching locations most\n",
      " |          satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      " |      \n",
      " |          Tolerance may be a scalar value, which applies the same tolerance\n",
      " |          to all values, or list-like, which applies variable tolerance per\n",
      " |          element. List-like includes list, tuple, array, Series, and must be\n",
      " |          the same size as the index and its dtype must exactly match the\n",
      " |          index's type.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0 (list-like tolerance)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series with changed index.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.set_index : Set row labels.\n",
      " |      DataFrame.reset_index : Remove row labels or move them to new columns.\n",
      " |      DataFrame.reindex_like : Change to same indices as other DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      ``DataFrame.reindex`` supports two calling conventions\n",
      " |      \n",
      " |      * ``(index=index_labels, columns=column_labels, ...)``\n",
      " |      * ``(labels, axis={'index', 'columns'}, ...)``\n",
      " |      \n",
      " |      We *highly* recommend using keyword arguments to clarify your\n",
      " |      intent.\n",
      " |      \n",
      " |      Create a dataframe with some fictional data.\n",
      " |      \n",
      " |      >>> index = ['Firefox', 'Chrome', 'Safari', 'IE10', 'Konqueror']\n",
      " |      >>> df = pd.DataFrame({'http_status': [200, 200, 404, 404, 301],\n",
      " |      ...                   'response_time': [0.04, 0.02, 0.07, 0.08, 1.0]},\n",
      " |      ...                   index=index)\n",
      " |      >>> df\n",
      " |                 http_status  response_time\n",
      " |      Firefox            200           0.04\n",
      " |      Chrome             200           0.02\n",
      " |      Safari             404           0.07\n",
      " |      IE10               404           0.08\n",
      " |      Konqueror          301           1.00\n",
      " |      \n",
      " |      Create a new index and reindex the dataframe. By default\n",
      " |      values in the new index that do not have corresponding\n",
      " |      records in the dataframe are assigned ``NaN``.\n",
      " |      \n",
      " |      >>> new_index = ['Safari', 'Iceweasel', 'Comodo Dragon', 'IE10',\n",
      " |      ...              'Chrome']\n",
      " |      >>> df.reindex(new_index)\n",
      " |                     http_status  response_time\n",
      " |      Safari               404.0           0.07\n",
      " |      Iceweasel              NaN            NaN\n",
      " |      Comodo Dragon          NaN            NaN\n",
      " |      IE10                 404.0           0.08\n",
      " |      Chrome               200.0           0.02\n",
      " |      \n",
      " |      We can fill in the missing values by passing a value to\n",
      " |      the keyword ``fill_value``. Because the index is not monotonically\n",
      " |      increasing or decreasing, we cannot use arguments to the keyword\n",
      " |      ``method`` to fill the ``NaN`` values.\n",
      " |      \n",
      " |      >>> df.reindex(new_index, fill_value=0)\n",
      " |                     http_status  response_time\n",
      " |      Safari                 404           0.07\n",
      " |      Iceweasel                0           0.00\n",
      " |      Comodo Dragon            0           0.00\n",
      " |      IE10                   404           0.08\n",
      " |      Chrome                 200           0.02\n",
      " |      \n",
      " |      >>> df.reindex(new_index, fill_value='missing')\n",
      " |                    http_status response_time\n",
      " |      Safari                404          0.07\n",
      " |      Iceweasel         missing       missing\n",
      " |      Comodo Dragon     missing       missing\n",
      " |      IE10                  404          0.08\n",
      " |      Chrome                200          0.02\n",
      " |      \n",
      " |      We can also reindex the columns.\n",
      " |      \n",
      " |      >>> df.reindex(columns=['http_status', 'user_agent'])\n",
      " |                 http_status  user_agent\n",
      " |      Firefox            200         NaN\n",
      " |      Chrome             200         NaN\n",
      " |      Safari             404         NaN\n",
      " |      IE10               404         NaN\n",
      " |      Konqueror          301         NaN\n",
      " |      \n",
      " |      Or we can use \"axis-style\" keyword arguments\n",
      " |      \n",
      " |      >>> df.reindex(['http_status', 'user_agent'], axis=\"columns\")\n",
      " |                 http_status  user_agent\n",
      " |      Firefox            200         NaN\n",
      " |      Chrome             200         NaN\n",
      " |      Safari             404         NaN\n",
      " |      IE10               404         NaN\n",
      " |      Konqueror          301         NaN\n",
      " |      \n",
      " |      To further illustrate the filling functionality in\n",
      " |      ``reindex``, we will create a dataframe with a\n",
      " |      monotonically increasing index (for example, a sequence\n",
      " |      of dates).\n",
      " |      \n",
      " |      >>> date_index = pd.date_range('1/1/2010', periods=6, freq='D')\n",
      " |      >>> df2 = pd.DataFrame({\"prices\": [100, 101, np.nan, 100, 89, 88]},\n",
      " |      ...                    index=date_index)\n",
      " |      >>> df2\n",
      " |                  prices\n",
      " |      2010-01-01   100.0\n",
      " |      2010-01-02   101.0\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04   100.0\n",
      " |      2010-01-05    89.0\n",
      " |      2010-01-06    88.0\n",
      " |      \n",
      " |      Suppose we decide to expand the dataframe to cover a wider\n",
      " |      date range.\n",
      " |      \n",
      " |      >>> date_index2 = pd.date_range('12/29/2009', periods=10, freq='D')\n",
      " |      >>> df2.reindex(date_index2)\n",
      " |                  prices\n",
      " |      2009-12-29     NaN\n",
      " |      2009-12-30     NaN\n",
      " |      2009-12-31     NaN\n",
      " |      2010-01-01   100.0\n",
      " |      2010-01-02   101.0\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04   100.0\n",
      " |      2010-01-05    89.0\n",
      " |      2010-01-06    88.0\n",
      " |      2010-01-07     NaN\n",
      " |      \n",
      " |      The index entries that did not have a value in the original data frame\n",
      " |      (for example, '2009-12-29') are by default filled with ``NaN``.\n",
      " |      If desired, we can fill in the missing values using one of several\n",
      " |      options.\n",
      " |      \n",
      " |      For example, to back-propagate the last valid value to fill the ``NaN``\n",
      " |      values, pass ``bfill`` as an argument to the ``method`` keyword.\n",
      " |      \n",
      " |      >>> df2.reindex(date_index2, method='bfill')\n",
      " |                  prices\n",
      " |      2009-12-29   100.0\n",
      " |      2009-12-30   100.0\n",
      " |      2009-12-31   100.0\n",
      " |      2010-01-01   100.0\n",
      " |      2010-01-02   101.0\n",
      " |      2010-01-03     NaN\n",
      " |      2010-01-04   100.0\n",
      " |      2010-01-05    89.0\n",
      " |      2010-01-06    88.0\n",
      " |      2010-01-07     NaN\n",
      " |      \n",
      " |      Please note that the ``NaN`` value present in the original dataframe\n",
      " |      (at index value 2010-01-03) will not be filled by any of the\n",
      " |      value propagation schemes. This is because filling while reindexing\n",
      " |      does not look at dataframe values, but only compares the original and\n",
      " |      desired indexes. If you do want to fill in the ``NaN`` values present\n",
      " |      in the original dataframe, use the ``fillna()`` method.\n",
      " |      \n",
      " |      See the :ref:`user guide <basics.reindexing>` for more.\n",
      " |  \n",
      " |  rename(self, index=None, *, axis=None, copy=True, inplace=False, level=None, errors='ignore')\n",
      " |      Alter Series index labels or name.\n",
      " |      \n",
      " |      Function / dict values must be unique (1-to-1). Labels not contained in\n",
      " |      a dict / Series will be left as-is. Extra labels listed don't throw an\n",
      " |      error.\n",
      " |      \n",
      " |      Alternatively, change ``Series.name`` with a scalar value.\n",
      " |      \n",
      " |      See the :ref:`user guide <basics.rename>` for more.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or \"index\"}\n",
      " |          Unused. Accepted for compatability with DataFrame method only.\n",
      " |      index : scalar, hashable sequence, dict-like or function, optional\n",
      " |          Functions or dict-like are transformations to apply to\n",
      " |          the index.\n",
      " |          Scalar or hashable sequence-like will alter the ``Series.name``\n",
      " |          attribute.\n",
      " |      \n",
      " |      **kwargs\n",
      " |          Additional keyword arguments passed to the function. Only the\n",
      " |          \"inplace\" keyword is used.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Series with index labels or name altered.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.rename : Corresponding DataFrame method.\n",
      " |      Series.rename_axis : Set the name of the axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |      >>> s.rename(\"my_name\")  # scalar, changes Series.name\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      Name: my_name, dtype: int64\n",
      " |      >>> s.rename(lambda x: x ** 2)  # function, changes labels\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      4    3\n",
      " |      dtype: int64\n",
      " |      >>> s.rename({1: 3, 2: 5})  # mapping, changes labels\n",
      " |      0    1\n",
      " |      3    2\n",
      " |      5    3\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  reorder_levels(self, order)\n",
      " |      Rearrange index levels using input order.\n",
      " |      \n",
      " |      May not drop or duplicate levels.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      order : list of int representing new level order\n",
      " |          Reference level by number or key.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of caller (new object)\n",
      " |  \n",
      " |  repeat(self, repeats, axis=None)\n",
      " |      Repeat elements of a Series.\n",
      " |      \n",
      " |      Returns a new Series where each element of the current Series\n",
      " |      is repeated consecutively a given number of times.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      repeats : int or array of ints\n",
      " |          The number of repetitions for each element. This should be a\n",
      " |          non-negative integer. Repeating 0 times will return an empty\n",
      " |          Series.\n",
      " |      axis : None\n",
      " |          Must be ``None``. Has no effect but is accepted for compatibility\n",
      " |          with numpy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Newly created Series with repeated elements.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.repeat : Equivalent function for Index.\n",
      " |      numpy.repeat : Similar method for :class:`numpy.ndarray`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(['a', 'b', 'c'])\n",
      " |      >>> s\n",
      " |      0    a\n",
      " |      1    b\n",
      " |      2    c\n",
      " |      dtype: object\n",
      " |      >>> s.repeat(2)\n",
      " |      0    a\n",
      " |      0    a\n",
      " |      1    b\n",
      " |      1    b\n",
      " |      2    c\n",
      " |      2    c\n",
      " |      dtype: object\n",
      " |      >>> s.repeat([1, 2, 3])\n",
      " |      0    a\n",
      " |      1    b\n",
      " |      1    b\n",
      " |      2    c\n",
      " |      2    c\n",
      " |      2    c\n",
      " |      dtype: object\n",
      " |  \n",
      " |  replace(self, to_replace=None, value=None, inplace=False, limit=None, regex=False, method='pad')\n",
      " |      Replace values given in `to_replace` with `value`.\n",
      " |      \n",
      " |      Values of the Series are replaced with other values dynamically.\n",
      " |      This differs from updating with ``.loc`` or ``.iloc``, which require\n",
      " |      you to specify a location to update with some value.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      to_replace : str, regex, list, dict, Series, int, float, or None\n",
      " |          How to find the values that will be replaced.\n",
      " |      \n",
      " |          * numeric, str or regex:\n",
      " |      \n",
      " |              - numeric: numeric values equal to `to_replace` will be\n",
      " |                replaced with `value`\n",
      " |              - str: string exactly matching `to_replace` will be replaced\n",
      " |                with `value`\n",
      " |              - regex: regexs matching `to_replace` will be replaced with\n",
      " |                `value`\n",
      " |      \n",
      " |          * list of str, regex, or numeric:\n",
      " |      \n",
      " |              - First, if `to_replace` and `value` are both lists, they\n",
      " |                **must** be the same length.\n",
      " |              - Second, if ``regex=True`` then all of the strings in **both**\n",
      " |                lists will be interpreted as regexs otherwise they will match\n",
      " |                directly. This doesn't matter much for `value` since there\n",
      " |                are only a few possible substitution regexes you can use.\n",
      " |              - str, regex and numeric rules apply as above.\n",
      " |      \n",
      " |          * dict:\n",
      " |      \n",
      " |              - Dicts can be used to specify different replacement values\n",
      " |                for different existing values. For example,\n",
      " |                ``{'a': 'b', 'y': 'z'}`` replaces the value 'a' with 'b' and\n",
      " |                'y' with 'z'. To use a dict in this way the `value`\n",
      " |                parameter should be `None`.\n",
      " |              - For a DataFrame a dict can specify that different values\n",
      " |                should be replaced in different columns. For example,\n",
      " |                ``{'a': 1, 'b': 'z'}`` looks for the value 1 in column 'a'\n",
      " |                and the value 'z' in column 'b' and replaces these values\n",
      " |                with whatever is specified in `value`. The `value` parameter\n",
      " |                should not be ``None`` in this case. You can treat this as a\n",
      " |                special case of passing two lists except that you are\n",
      " |                specifying the column to search in.\n",
      " |              - For a DataFrame nested dictionaries, e.g.,\n",
      " |                ``{'a': {'b': np.nan}}``, are read as follows: look in column\n",
      " |                'a' for the value 'b' and replace it with NaN. The `value`\n",
      " |                parameter should be ``None`` to use a nested dict in this\n",
      " |                way. You can nest regular expressions as well. Note that\n",
      " |                column names (the top-level dictionary keys in a nested\n",
      " |                dictionary) **cannot** be regular expressions.\n",
      " |      \n",
      " |          * None:\n",
      " |      \n",
      " |              - This means that the `regex` argument must be a string,\n",
      " |                compiled regular expression, or list, dict, ndarray or\n",
      " |                Series of such elements. If `value` is also ``None`` then\n",
      " |                this **must** be a nested dictionary or Series.\n",
      " |      \n",
      " |          See the examples section for examples of each of these.\n",
      " |      value : scalar, dict, list, str, regex, default None\n",
      " |          Value to replace any values matching `to_replace` with.\n",
      " |          For a DataFrame a dict of values can be used to specify which\n",
      " |          value to use for each column (columns not in the dict will not be\n",
      " |          filled). Regular expressions, strings and lists or dicts of such\n",
      " |          objects are also allowed.\n",
      " |      inplace : bool, default False\n",
      " |          If True, in place. Note: this will modify any\n",
      " |          other views on this object (e.g. a column from a DataFrame).\n",
      " |          Returns the caller if this is True.\n",
      " |      limit : int, default None\n",
      " |          Maximum size gap to forward or backward fill.\n",
      " |      regex : bool or same types as `to_replace`, default False\n",
      " |          Whether to interpret `to_replace` and/or `value` as regular\n",
      " |          expressions. If this is ``True`` then `to_replace` *must* be a\n",
      " |          string. Alternatively, this could be a regular expression or a\n",
      " |          list, dict, or array of regular expressions in which case\n",
      " |          `to_replace` must be ``None``.\n",
      " |      method : {'pad', 'ffill', 'bfill', `None`}\n",
      " |          The method to use when for replacement, when `to_replace` is a\n",
      " |          scalar, list or tuple and `value` is ``None``.\n",
      " |      \n",
      " |          .. versionchanged:: 0.23.0\n",
      " |              Added to DataFrame.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Object after replacement.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      AssertionError\n",
      " |          * If `regex` is not a ``bool`` and `to_replace` is not\n",
      " |            ``None``.\n",
      " |      TypeError\n",
      " |          * If `to_replace` is a ``dict`` and `value` is not a ``list``,\n",
      " |            ``dict``, ``ndarray``, or ``Series``\n",
      " |          * If `to_replace` is ``None`` and `regex` is not compilable\n",
      " |            into a regular expression or is a list, dict, ndarray, or\n",
      " |            Series.\n",
      " |          * When replacing multiple ``bool`` or ``datetime64`` objects and\n",
      " |            the arguments to `to_replace` does not match the type of the\n",
      " |            value being replaced\n",
      " |      ValueError\n",
      " |          * If a ``list`` or an ``ndarray`` is passed to `to_replace` and\n",
      " |            `value` but they are not the same length.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.fillna : Fill NA values.\n",
      " |      Series.where : Replace values based on boolean condition.\n",
      " |      Series.str.replace : Simple string replacement.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      * Regex substitution is performed under the hood with ``re.sub``. The\n",
      " |        rules for substitution for ``re.sub`` are the same.\n",
      " |      * Regular expressions will only substitute on strings, meaning you\n",
      " |        cannot provide, for example, a regular expression matching floating\n",
      " |        point numbers and expect the columns in your frame that have a\n",
      " |        numeric dtype to be matched. However, if those floating point\n",
      " |        numbers *are* strings, then you can do this.\n",
      " |      * This method has *a lot* of options. You are encouraged to experiment\n",
      " |        and play with this method to gain intuition about how it works.\n",
      " |      * When dict is used as the `to_replace` value, it is like\n",
      " |        key(s) in the dict are the to_replace part and\n",
      " |        value(s) in the dict are the value parameter.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      **Scalar `to_replace` and `value`**\n",
      " |      \n",
      " |      >>> s = pd.Series([0, 1, 2, 3, 4])\n",
      " |      >>> s.replace(0, 5)\n",
      " |      0    5\n",
      " |      1    1\n",
      " |      2    2\n",
      " |      3    3\n",
      " |      4    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [0, 1, 2, 3, 4],\n",
      " |      ...                    'B': [5, 6, 7, 8, 9],\n",
      " |      ...                    'C': ['a', 'b', 'c', 'd', 'e']})\n",
      " |      >>> df.replace(0, 5)\n",
      " |         A  B  C\n",
      " |      0  5  5  a\n",
      " |      1  1  6  b\n",
      " |      2  2  7  c\n",
      " |      3  3  8  d\n",
      " |      4  4  9  e\n",
      " |      \n",
      " |      **List-like `to_replace`**\n",
      " |      \n",
      " |      >>> df.replace([0, 1, 2, 3], 4)\n",
      " |         A  B  C\n",
      " |      0  4  5  a\n",
      " |      1  4  6  b\n",
      " |      2  4  7  c\n",
      " |      3  4  8  d\n",
      " |      4  4  9  e\n",
      " |      \n",
      " |      >>> df.replace([0, 1, 2, 3], [4, 3, 2, 1])\n",
      " |         A  B  C\n",
      " |      0  4  5  a\n",
      " |      1  3  6  b\n",
      " |      2  2  7  c\n",
      " |      3  1  8  d\n",
      " |      4  4  9  e\n",
      " |      \n",
      " |      >>> s.replace([1, 2], method='bfill')\n",
      " |      0    0\n",
      " |      1    3\n",
      " |      2    3\n",
      " |      3    3\n",
      " |      4    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      **dict-like `to_replace`**\n",
      " |      \n",
      " |      >>> df.replace({0: 10, 1: 100})\n",
      " |           A  B  C\n",
      " |      0   10  5  a\n",
      " |      1  100  6  b\n",
      " |      2    2  7  c\n",
      " |      3    3  8  d\n",
      " |      4    4  9  e\n",
      " |      \n",
      " |      >>> df.replace({'A': 0, 'B': 5}, 100)\n",
      " |           A    B  C\n",
      " |      0  100  100  a\n",
      " |      1    1    6  b\n",
      " |      2    2    7  c\n",
      " |      3    3    8  d\n",
      " |      4    4    9  e\n",
      " |      \n",
      " |      >>> df.replace({'A': {0: 100, 4: 400}})\n",
      " |           A  B  C\n",
      " |      0  100  5  a\n",
      " |      1    1  6  b\n",
      " |      2    2  7  c\n",
      " |      3    3  8  d\n",
      " |      4  400  9  e\n",
      " |      \n",
      " |      **Regular expression `to_replace`**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': ['bat', 'foo', 'bait'],\n",
      " |      ...                    'B': ['abc', 'bar', 'xyz']})\n",
      " |      >>> df.replace(to_replace=r'^ba.$', value='new', regex=True)\n",
      " |            A    B\n",
      " |      0   new  abc\n",
      " |      1   foo  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace({'A': r'^ba.$'}, {'A': 'new'}, regex=True)\n",
      " |            A    B\n",
      " |      0   new  abc\n",
      " |      1   foo  bar\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace(regex=r'^ba.$', value='new')\n",
      " |            A    B\n",
      " |      0   new  abc\n",
      " |      1   foo  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace(regex={r'^ba.$': 'new', 'foo': 'xyz'})\n",
      " |            A    B\n",
      " |      0   new  abc\n",
      " |      1   xyz  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      >>> df.replace(regex=[r'^ba.$', 'foo'], value='new')\n",
      " |            A    B\n",
      " |      0   new  abc\n",
      " |      1   new  new\n",
      " |      2  bait  xyz\n",
      " |      \n",
      " |      Note that when replacing multiple ``bool`` or ``datetime64`` objects,\n",
      " |      the data types in the `to_replace` parameter must match the data\n",
      " |      type of the value being replaced:\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [True, False, True],\n",
      " |      ...                    'B': [False, True, False]})\n",
      " |      >>> df.replace({'a string': 'new value', True: False})  # raises\n",
      " |      Traceback (most recent call last):\n",
      " |          ...\n",
      " |      TypeError: Cannot compare types 'ndarray(dtype=bool)' and 'str'\n",
      " |      \n",
      " |      This raises a ``TypeError`` because one of the ``dict`` keys is not of\n",
      " |      the correct type for replacement.\n",
      " |      \n",
      " |      Compare the behavior of ``s.replace({'a': None})`` and\n",
      " |      ``s.replace('a', None)`` to understand the peculiarities\n",
      " |      of the `to_replace` parameter:\n",
      " |      \n",
      " |      >>> s = pd.Series([10, 'a', 'a', 'b', 'a'])\n",
      " |      \n",
      " |      When one uses a dict as the `to_replace` value, it is like the\n",
      " |      value(s) in the dict are equal to the `value` parameter.\n",
      " |      ``s.replace({'a': None})`` is equivalent to\n",
      " |      ``s.replace(to_replace={'a': None}, value=None, method=None)``:\n",
      " |      \n",
      " |      >>> s.replace({'a': None})\n",
      " |      0      10\n",
      " |      1    None\n",
      " |      2    None\n",
      " |      3       b\n",
      " |      4    None\n",
      " |      dtype: object\n",
      " |      \n",
      " |      When ``value=None`` and `to_replace` is a scalar, list or\n",
      " |      tuple, `replace` uses the method parameter (default 'pad') to do the\n",
      " |      replacement. So this is why the 'a' values are being replaced by 10\n",
      " |      in rows 1 and 2 and 'b' in row 4 in this case.\n",
      " |      The command ``s.replace('a', None)`` is actually equivalent to\n",
      " |      ``s.replace(to_replace='a', value=None, method='pad')``:\n",
      " |      \n",
      " |      >>> s.replace('a', None)\n",
      " |      0    10\n",
      " |      1    10\n",
      " |      2    10\n",
      " |      3     b\n",
      " |      4     b\n",
      " |      dtype: object\n",
      " |  \n",
      " |  reset_index(self, level=None, drop=False, name=None, inplace=False)\n",
      " |      Generate a new DataFrame or Series with the index reset.\n",
      " |      \n",
      " |      This is useful when the index needs to be treated as a column, or\n",
      " |      when the index is meaningless and needs to be reset to the default\n",
      " |      before another operation.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, str, tuple, or list, default optional\n",
      " |          For a Series with a MultiIndex, only remove the specified levels\n",
      " |          from the index. Removes all levels by default.\n",
      " |      drop : bool, default False\n",
      " |          Just reset the index, without inserting it as a column in\n",
      " |          the new DataFrame.\n",
      " |      name : object, optional\n",
      " |          The name to use for the column containing the original Series\n",
      " |          values. Uses ``self.name`` by default. This argument is ignored\n",
      " |          when `drop` is True.\n",
      " |      inplace : bool, default False\n",
      " |          Modify the Series in place (do not create a new object).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          When `drop` is False (the default), a DataFrame is returned.\n",
      " |          The newly created columns will come first in the DataFrame,\n",
      " |          followed by the original Series values.\n",
      " |          When `drop` is True, a `Series` is returned.\n",
      " |          In either case, if ``inplace=True``, no value is returned.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.reset_index: Analogous function for DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4], name='foo',\n",
      " |      ...               index=pd.Index(['a', 'b', 'c', 'd'], name='idx'))\n",
      " |      \n",
      " |      Generate a DataFrame with default index.\n",
      " |      \n",
      " |      >>> s.reset_index()\n",
      " |        idx  foo\n",
      " |      0   a    1\n",
      " |      1   b    2\n",
      " |      2   c    3\n",
      " |      3   d    4\n",
      " |      \n",
      " |      To specify the name of the new column use `name`.\n",
      " |      \n",
      " |      >>> s.reset_index(name='values')\n",
      " |        idx  values\n",
      " |      0   a       1\n",
      " |      1   b       2\n",
      " |      2   c       3\n",
      " |      3   d       4\n",
      " |      \n",
      " |      To generate a new Series with the default set `drop` to True.\n",
      " |      \n",
      " |      >>> s.reset_index(drop=True)\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      Name: foo, dtype: int64\n",
      " |      \n",
      " |      To update the Series in place, without generating a new one\n",
      " |      set `inplace` to True. Note that it also requires ``drop=True``.\n",
      " |      \n",
      " |      >>> s.reset_index(inplace=True, drop=True)\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      Name: foo, dtype: int64\n",
      " |      \n",
      " |      The `level` parameter is interesting for Series with a multi-level\n",
      " |      index.\n",
      " |      \n",
      " |      >>> arrays = [np.array(['bar', 'bar', 'baz', 'baz']),\n",
      " |      ...           np.array(['one', 'two', 'one', 'two'])]\n",
      " |      >>> s2 = pd.Series(\n",
      " |      ...     range(4), name='foo',\n",
      " |      ...     index=pd.MultiIndex.from_arrays(arrays,\n",
      " |      ...                                     names=['a', 'b']))\n",
      " |      \n",
      " |      To remove a specific level from the Index, use `level`.\n",
      " |      \n",
      " |      >>> s2.reset_index(level='a')\n",
      " |             a  foo\n",
      " |      b\n",
      " |      one  bar    0\n",
      " |      two  bar    1\n",
      " |      one  baz    2\n",
      " |      two  baz    3\n",
      " |      \n",
      " |      If `level` is not set, all levels are removed from the Index.\n",
      " |      \n",
      " |      >>> s2.reset_index()\n",
      " |           a    b  foo\n",
      " |      0  bar  one    0\n",
      " |      1  bar  two    1\n",
      " |      2  baz  one    2\n",
      " |      3  baz  two    3\n",
      " |  \n",
      " |  rfloordiv(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Return Integer division of series and other, element-wise (binary operator `rfloordiv`).\n",
      " |      \n",
      " |      Equivalent to ``other // series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.floordiv\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.floordiv(b, fill_value=0)\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      c    NaN\n",
      " |      d    0.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  rmod(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Return Modulo of series and other, element-wise (binary operator `rmod`).\n",
      " |      \n",
      " |      Equivalent to ``other % series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.mod\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.mod(b, fill_value=0)\n",
      " |      a    0.0\n",
      " |      b    NaN\n",
      " |      c    NaN\n",
      " |      d    0.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  rmul(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Return Multiplication of series and other, element-wise (binary operator `rmul`).\n",
      " |      \n",
      " |      Equivalent to ``other * series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.mul\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.multiply(b, fill_value=0)\n",
      " |      a    1.0\n",
      " |      b    0.0\n",
      " |      c    0.0\n",
      " |      d    0.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  rolling(self, window, min_periods=None, center=False, win_type=None, on=None, axis=0, closed=None)\n",
      " |      Provide rolling window calculations.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      window : int, offset, or BaseIndexer subclass\n",
      " |          Size of the moving window. This is the number of observations used for\n",
      " |          calculating the statistic. Each window will be a fixed size.\n",
      " |      \n",
      " |          If its an offset then this will be the time period of each window. Each\n",
      " |          window will be a variable sized based on the observations included in\n",
      " |          the time-period. This is only valid for datetimelike indexes.\n",
      " |      \n",
      " |          If a BaseIndexer subclass is passed, calculates the window boundaries\n",
      " |          based on the defined ``get_window_bounds`` method. Additional rolling\n",
      " |          keyword arguments, namely `min_periods`, `center`, and\n",
      " |          `closed` will be passed to `get_window_bounds`.\n",
      " |      min_periods : int, default None\n",
      " |          Minimum number of observations in window required to have a value\n",
      " |          (otherwise result is NA). For a window that is specified by an offset,\n",
      " |          `min_periods` will default to 1. Otherwise, `min_periods` will default\n",
      " |          to the size of the window.\n",
      " |      center : bool, default False\n",
      " |          Set the labels at the center of the window.\n",
      " |      win_type : str, default None\n",
      " |          Provide a window type. If ``None``, all points are evenly weighted.\n",
      " |          See the notes below for further information.\n",
      " |      on : str, optional\n",
      " |          For a DataFrame, a datetime-like column or MultiIndex level on which\n",
      " |          to calculate the rolling window, rather than the DataFrame's index.\n",
      " |          Provided integer column is ignored and excluded from result since\n",
      " |          an integer index is not used to calculate the rolling window.\n",
      " |      axis : int or str, default 0\n",
      " |      closed : str, default None\n",
      " |          Make the interval closed on the 'right', 'left', 'both' or\n",
      " |          'neither' endpoints.\n",
      " |          For offset-based windows, it defaults to 'right'.\n",
      " |          For fixed windows, defaults to 'both'. Remaining cases not implemented\n",
      " |          for fixed windows.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      a Window or Rolling sub-classed for the particular operation\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      expanding : Provides expanding transformations.\n",
      " |      ewm : Provides exponential weighted functions.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      By default, the result is set to the right edge of the window. This can be\n",
      " |      changed to the center of the window by setting ``center=True``.\n",
      " |      \n",
      " |      To learn more about the offsets & frequency strings, please see `this link\n",
      " |      <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\n",
      " |      \n",
      " |      The recognized win_types are:\n",
      " |      \n",
      " |      * ``boxcar``\n",
      " |      * ``triang``\n",
      " |      * ``blackman``\n",
      " |      * ``hamming``\n",
      " |      * ``bartlett``\n",
      " |      * ``parzen``\n",
      " |      * ``bohman``\n",
      " |      * ``blackmanharris``\n",
      " |      * ``nuttall``\n",
      " |      * ``barthann``\n",
      " |      * ``kaiser`` (needs beta)\n",
      " |      * ``gaussian`` (needs std)\n",
      " |      * ``general_gaussian`` (needs power, width)\n",
      " |      * ``slepian`` (needs width)\n",
      " |      * ``exponential`` (needs tau), center is set to None.\n",
      " |      \n",
      " |      If ``win_type=None`` all points are evenly weighted. To learn more about\n",
      " |      different window types see `scipy.signal window functions\n",
      " |      <https://docs.scipy.org/doc/scipy/reference/signal.html#window-functions>`__.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})\n",
      " |      >>> df\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  2.0\n",
      " |      3  NaN\n",
      " |      4  4.0\n",
      " |      \n",
      " |      Rolling sum with a window length of 2, using the 'triang'\n",
      " |      window type.\n",
      " |      \n",
      " |      >>> df.rolling(2, win_type='triang').sum()\n",
      " |           B\n",
      " |      0  NaN\n",
      " |      1  0.5\n",
      " |      2  1.5\n",
      " |      3  NaN\n",
      " |      4  NaN\n",
      " |      \n",
      " |      Rolling sum with a window length of 2, using the 'gaussian'\n",
      " |      window type (note how we need to specify std).\n",
      " |      \n",
      " |      >>> df.rolling(2, win_type='gaussian').sum(std=3)\n",
      " |                B\n",
      " |      0       NaN\n",
      " |      1  0.986207\n",
      " |      2  2.958621\n",
      " |      3       NaN\n",
      " |      4       NaN\n",
      " |      \n",
      " |      Rolling sum with a window length of 2, min_periods defaults\n",
      " |      to the window length.\n",
      " |      \n",
      " |      >>> df.rolling(2).sum()\n",
      " |           B\n",
      " |      0  NaN\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  NaN\n",
      " |      4  NaN\n",
      " |      \n",
      " |      Same as above, but explicitly set the min_periods\n",
      " |      \n",
      " |      >>> df.rolling(2, min_periods=1).sum()\n",
      " |           B\n",
      " |      0  0.0\n",
      " |      1  1.0\n",
      " |      2  3.0\n",
      " |      3  2.0\n",
      " |      4  4.0\n",
      " |      \n",
      " |      A ragged (meaning not-a-regular frequency), time-indexed DataFrame\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]},\n",
      " |      ...                   index = [pd.Timestamp('20130101 09:00:00'),\n",
      " |      ...                            pd.Timestamp('20130101 09:00:02'),\n",
      " |      ...                            pd.Timestamp('20130101 09:00:03'),\n",
      " |      ...                            pd.Timestamp('20130101 09:00:05'),\n",
      " |      ...                            pd.Timestamp('20130101 09:00:06')])\n",
      " |      \n",
      " |      >>> df\n",
      " |                             B\n",
      " |      2013-01-01 09:00:00  0.0\n",
      " |      2013-01-01 09:00:02  1.0\n",
      " |      2013-01-01 09:00:03  2.0\n",
      " |      2013-01-01 09:00:05  NaN\n",
      " |      2013-01-01 09:00:06  4.0\n",
      " |      \n",
      " |      Contrasting to an integer rolling window, this will roll a variable\n",
      " |      length window corresponding to the time period.\n",
      " |      The default for min_periods is 1.\n",
      " |      \n",
      " |      >>> df.rolling('2s').sum()\n",
      " |                             B\n",
      " |      2013-01-01 09:00:00  0.0\n",
      " |      2013-01-01 09:00:02  1.0\n",
      " |      2013-01-01 09:00:03  3.0\n",
      " |      2013-01-01 09:00:05  NaN\n",
      " |      2013-01-01 09:00:06  4.0\n",
      " |  \n",
      " |  round(self, decimals=0, *args, **kwargs)\n",
      " |      Round each value in a Series to the given number of decimals.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      decimals : int, default 0\n",
      " |          Number of decimal places to round to. If decimals is negative,\n",
      " |          it specifies the number of positions to the left of the decimal point.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Rounded values of the Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.around : Round values of an np.array.\n",
      " |      DataFrame.round : Round values of a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([0.1, 1.3, 2.7])\n",
      " |      >>> s.round()\n",
      " |      0    0.0\n",
      " |      1    1.0\n",
      " |      2    3.0\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  rpow(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Return Exponential power of series and other, element-wise (binary operator `rpow`).\n",
      " |      \n",
      " |      Equivalent to ``other ** series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.pow\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.pow(b, fill_value=0)\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    0.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  rsub(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Return Subtraction of series and other, element-wise (binary operator `rsub`).\n",
      " |      \n",
      " |      Equivalent to ``other - series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sub\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.subtract(b, fill_value=0)\n",
      " |      a    0.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d   -1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  rtruediv(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Return Floating division of series and other, element-wise (binary operator `rtruediv`).\n",
      " |      \n",
      " |      Equivalent to ``other / series``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.truediv\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.divide(b, fill_value=0)\n",
      " |      a    1.0\n",
      " |      b    inf\n",
      " |      c    inf\n",
      " |      d    0.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  searchsorted(self, value, side='left', sorter=None)\n",
      " |      Find indices where elements should be inserted to maintain order.\n",
      " |      \n",
      " |      Find the indices into a sorted Series `self` such that, if the\n",
      " |      corresponding elements in `value` were inserted before the indices,\n",
      " |      the order of `self` would be preserved.\n",
      " |      \n",
      " |      .. note::\n",
      " |      \n",
      " |          The Series *must* be monotonically sorted, otherwise\n",
      " |          wrong locations will likely be returned. Pandas does *not*\n",
      " |          check this for you.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      value : array_like\n",
      " |          Values to insert into `self`.\n",
      " |      side : {'left', 'right'}, optional\n",
      " |          If 'left', the index of the first suitable location found is given.\n",
      " |          If 'right', return the last such index.  If there is no suitable\n",
      " |          index, return either 0 or N (where N is the length of `self`).\n",
      " |      sorter : 1-D array_like, optional\n",
      " |          Optional array of integer indices that sort `self` into ascending\n",
      " |          order. They are typically the result of ``np.argsort``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      int or array of int\n",
      " |          A scalar or array of insertion points with the\n",
      " |          same shape as `value`.\n",
      " |      \n",
      " |          .. versionchanged:: 0.24.0\n",
      " |              If `value` is a scalar, an int is now always returned.\n",
      " |              Previously, scalar inputs returned an 1-item array for\n",
      " |              :class:`Series` and :class:`Categorical`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      sort_values\n",
      " |      numpy.searchsorted\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Binary search is used to find the required insertion points.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> x = pd.Series([1, 2, 3])\n",
      " |      >>> x\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> x.searchsorted(4)\n",
      " |      3\n",
      " |      \n",
      " |      >>> x.searchsorted([0, 4])\n",
      " |      array([0, 3])\n",
      " |      \n",
      " |      >>> x.searchsorted([1, 3], side='left')\n",
      " |      array([0, 2])\n",
      " |      \n",
      " |      >>> x.searchsorted([1, 3], side='right')\n",
      " |      array([1, 3])\n",
      " |      \n",
      " |      >>> x = pd.Categorical(['apple', 'bread', 'bread',\n",
      " |                              'cheese', 'milk'], ordered=True)\n",
      " |      [apple, bread, bread, cheese, milk]\n",
      " |      Categories (4, object): [apple < bread < cheese < milk]\n",
      " |      \n",
      " |      >>> x.searchsorted('bread')\n",
      " |      1\n",
      " |      \n",
      " |      >>> x.searchsorted(['bread'], side='right')\n",
      " |      array([3])\n",
      " |      \n",
      " |      If the values are not monotonically sorted, wrong locations\n",
      " |      may be returned:\n",
      " |      \n",
      " |      >>> x = pd.Series([2, 1, 3])\n",
      " |      >>> x.searchsorted(1)\n",
      " |      0  # wrong result, correct would be 1\n",
      " |  \n",
      " |  sem(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      " |      Return unbiased standard error of the mean over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar.\n",
      " |      ddof : int, default 1\n",
      " |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\n",
      " |          where N represents the number of elements.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series (if level specified)\n",
      " |  \n",
      " |  shift(self, periods=1, freq=None, axis=0, fill_value=None)\n",
      " |      Shift index by desired number of periods with an optional time `freq`.\n",
      " |      \n",
      " |      When `freq` is not passed, shift the index without realigning the data.\n",
      " |      If `freq` is passed (in this case, the index must be date or datetime,\n",
      " |      or it will raise a `NotImplementedError`), the index will be\n",
      " |      increased using the periods and the `freq`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to shift. Can be positive or negative.\n",
      " |      freq : DateOffset, tseries.offsets, timedelta, or str, optional\n",
      " |          Offset to use from the tseries module or time rule (e.g. 'EOM').\n",
      " |          If `freq` is specified then the index values are shifted but the\n",
      " |          data is not realigned. That is, use `freq` if you would like to\n",
      " |          extend the index when shifting and preserve the original data.\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default None\n",
      " |          Shift direction.\n",
      " |      fill_value : object, optional\n",
      " |          The scalar value to use for newly introduced missing values.\n",
      " |          the default depends on the dtype of `self`.\n",
      " |          For numeric data, ``np.nan`` is used.\n",
      " |          For datetime, timedelta, or period data, etc. :attr:`NaT` is used.\n",
      " |          For extension dtypes, ``self.dtype.na_value`` is used.\n",
      " |      \n",
      " |          .. versionchanged:: 0.24.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Copy of input object, shifted.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.shift : Shift values of Index.\n",
      " |      DatetimeIndex.shift : Shift values of DatetimeIndex.\n",
      " |      PeriodIndex.shift : Shift values of PeriodIndex.\n",
      " |      tshift : Shift the time index, using the index's frequency if\n",
      " |          available.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'Col1': [10, 20, 15, 30, 45],\n",
      " |      ...                    'Col2': [13, 23, 18, 33, 48],\n",
      " |      ...                    'Col3': [17, 27, 22, 37, 52]})\n",
      " |      \n",
      " |      >>> df.shift(periods=3)\n",
      " |         Col1  Col2  Col3\n",
      " |      0   NaN   NaN   NaN\n",
      " |      1   NaN   NaN   NaN\n",
      " |      2   NaN   NaN   NaN\n",
      " |      3  10.0  13.0  17.0\n",
      " |      4  20.0  23.0  27.0\n",
      " |      \n",
      " |      >>> df.shift(periods=1, axis='columns')\n",
      " |         Col1  Col2  Col3\n",
      " |      0   NaN  10.0  13.0\n",
      " |      1   NaN  20.0  23.0\n",
      " |      2   NaN  15.0  18.0\n",
      " |      3   NaN  30.0  33.0\n",
      " |      4   NaN  45.0  48.0\n",
      " |      \n",
      " |      >>> df.shift(periods=3, fill_value=0)\n",
      " |         Col1  Col2  Col3\n",
      " |      0     0     0     0\n",
      " |      1     0     0     0\n",
      " |      2     0     0     0\n",
      " |      3    10    13    17\n",
      " |      4    20    23    27\n",
      " |  \n",
      " |  skew(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return unbiased skew over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series (if level specified)\n",
      " |  \n",
      " |  sort_index(self, axis=0, level=None, ascending=True, inplace=False, kind='quicksort', na_position='last', sort_remaining=True, ignore_index: bool = False)\n",
      " |      Sort Series by index labels.\n",
      " |      \n",
      " |      Returns a new Series sorted by label if `inplace` argument is\n",
      " |      ``False``, otherwise updates the original series and returns None.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : int, default 0\n",
      " |          Axis to direct sorting. This can only be 0 for Series.\n",
      " |      level : int, optional\n",
      " |          If not None, sort on values in specified index level(s).\n",
      " |      ascending : bool, default true\n",
      " |          Sort ascending vs. descending.\n",
      " |      inplace : bool, default False\n",
      " |          If True, perform operation in-place.\n",
      " |      kind : {'quicksort', 'mergesort', 'heapsort'}, default 'quicksort'\n",
      " |          Choice of sorting algorithm. See also :func:`numpy.sort` for more\n",
      " |          information.  'mergesort' is the only stable algorithm. For\n",
      " |          DataFrames, this option is only applied when sorting on a single\n",
      " |          column or label.\n",
      " |      na_position : {'first', 'last'}, default 'last'\n",
      " |          If 'first' puts NaNs at the beginning, 'last' puts NaNs at the end.\n",
      " |          Not implemented for MultiIndex.\n",
      " |      sort_remaining : bool, default True\n",
      " |          If True and sorting by level and index is multilevel, sort by other\n",
      " |          levels too (in order) after sorting by specified level.\n",
      " |      ignore_index : bool, default False\n",
      " |          If True, the resulting axis will be labeled 0, 1, …, n - 1.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The original Series sorted by the labels.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.sort_index: Sort DataFrame by the index.\n",
      " |      DataFrame.sort_values: Sort DataFrame by the value.\n",
      " |      Series.sort_values : Sort Series by the value.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(['a', 'b', 'c', 'd'], index=[3, 2, 1, 4])\n",
      " |      >>> s.sort_index()\n",
      " |      1    c\n",
      " |      2    b\n",
      " |      3    a\n",
      " |      4    d\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Sort Descending\n",
      " |      \n",
      " |      >>> s.sort_index(ascending=False)\n",
      " |      4    d\n",
      " |      3    a\n",
      " |      2    b\n",
      " |      1    c\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Sort Inplace\n",
      " |      \n",
      " |      >>> s.sort_index(inplace=True)\n",
      " |      >>> s\n",
      " |      1    c\n",
      " |      2    b\n",
      " |      3    a\n",
      " |      4    d\n",
      " |      dtype: object\n",
      " |      \n",
      " |      By default NaNs are put at the end, but use `na_position` to place\n",
      " |      them at the beginning\n",
      " |      \n",
      " |      >>> s = pd.Series(['a', 'b', 'c', 'd'], index=[3, 2, 1, np.nan])\n",
      " |      >>> s.sort_index(na_position='first')\n",
      " |      NaN     d\n",
      " |       1.0    c\n",
      " |       2.0    b\n",
      " |       3.0    a\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Specify index level to sort\n",
      " |      \n",
      " |      >>> arrays = [np.array(['qux', 'qux', 'foo', 'foo',\n",
      " |      ...                     'baz', 'baz', 'bar', 'bar']),\n",
      " |      ...           np.array(['two', 'one', 'two', 'one',\n",
      " |      ...                     'two', 'one', 'two', 'one'])]\n",
      " |      >>> s = pd.Series([1, 2, 3, 4, 5, 6, 7, 8], index=arrays)\n",
      " |      >>> s.sort_index(level=1)\n",
      " |      bar  one    8\n",
      " |      baz  one    6\n",
      " |      foo  one    4\n",
      " |      qux  one    2\n",
      " |      bar  two    7\n",
      " |      baz  two    5\n",
      " |      foo  two    3\n",
      " |      qux  two    1\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Does not sort by remaining levels when sorting by levels\n",
      " |      \n",
      " |      >>> s.sort_index(level=1, sort_remaining=False)\n",
      " |      qux  one    2\n",
      " |      foo  one    4\n",
      " |      baz  one    6\n",
      " |      bar  one    8\n",
      " |      qux  two    1\n",
      " |      foo  two    3\n",
      " |      baz  two    5\n",
      " |      bar  two    7\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  sort_values(self, axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last', ignore_index=False)\n",
      " |      Sort by the values.\n",
      " |      \n",
      " |      Sort a Series in ascending or descending order by some\n",
      " |      criterion.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index'}, default 0\n",
      " |          Axis to direct sorting. The value 'index' is accepted for\n",
      " |          compatibility with DataFrame.sort_values.\n",
      " |      ascending : bool, default True\n",
      " |          If True, sort values in ascending order, otherwise descending.\n",
      " |      inplace : bool, default False\n",
      " |          If True, perform operation in-place.\n",
      " |      kind : {'quicksort', 'mergesort' or 'heapsort'}, default 'quicksort'\n",
      " |          Choice of sorting algorithm. See also :func:`numpy.sort` for more\n",
      " |          information. 'mergesort' is the only stable  algorithm.\n",
      " |      na_position : {'first' or 'last'}, default 'last'\n",
      " |          Argument 'first' puts NaNs at the beginning, 'last' puts NaNs at\n",
      " |          the end.\n",
      " |      ignore_index : bool, default False\n",
      " |           If True, the resulting axis will be labeled 0, 1, …, n - 1.\n",
      " |      \n",
      " |           .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Series ordered by values.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sort_index : Sort by the Series indices.\n",
      " |      DataFrame.sort_values : Sort DataFrame by the values along either axis.\n",
      " |      DataFrame.sort_index : Sort DataFrame by indices.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([np.nan, 1, 3, 10, 5])\n",
      " |      >>> s\n",
      " |      0     NaN\n",
      " |      1     1.0\n",
      " |      2     3.0\n",
      " |      3     10.0\n",
      " |      4     5.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Sort values ascending order (default behaviour)\n",
      " |      \n",
      " |      >>> s.sort_values(ascending=True)\n",
      " |      1     1.0\n",
      " |      2     3.0\n",
      " |      4     5.0\n",
      " |      3    10.0\n",
      " |      0     NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Sort values descending order\n",
      " |      \n",
      " |      >>> s.sort_values(ascending=False)\n",
      " |      3    10.0\n",
      " |      4     5.0\n",
      " |      2     3.0\n",
      " |      1     1.0\n",
      " |      0     NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Sort values inplace\n",
      " |      \n",
      " |      >>> s.sort_values(ascending=False, inplace=True)\n",
      " |      >>> s\n",
      " |      3    10.0\n",
      " |      4     5.0\n",
      " |      2     3.0\n",
      " |      1     1.0\n",
      " |      0     NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Sort values putting NAs first\n",
      " |      \n",
      " |      >>> s.sort_values(na_position='first')\n",
      " |      0     NaN\n",
      " |      1     1.0\n",
      " |      2     3.0\n",
      " |      4     5.0\n",
      " |      3    10.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Sort a series of strings\n",
      " |      \n",
      " |      >>> s = pd.Series(['z', 'b', 'd', 'a', 'c'])\n",
      " |      >>> s\n",
      " |      0    z\n",
      " |      1    b\n",
      " |      2    d\n",
      " |      3    a\n",
      " |      4    c\n",
      " |      dtype: object\n",
      " |      \n",
      " |      >>> s.sort_values()\n",
      " |      3    a\n",
      " |      1    b\n",
      " |      4    c\n",
      " |      2    d\n",
      " |      0    z\n",
      " |      dtype: object\n",
      " |  \n",
      " |  std(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      " |      Return sample standard deviation over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar.\n",
      " |      ddof : int, default 1\n",
      " |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\n",
      " |          where N represents the number of elements.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series (if level specified)\n",
      " |  \n",
      " |  sub(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Return Subtraction of series and other, element-wise (binary operator `sub`).\n",
      " |      \n",
      " |      Equivalent to ``series - other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.rsub\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.subtract(b, fill_value=0)\n",
      " |      a    0.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d   -1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  subtract = sub(self, other, level=None, fill_value=None, axis=0)\n",
      " |  \n",
      " |  sum(self, axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)\n",
      " |      Return the sum of the values for the requested axis.\n",
      " |      \n",
      " |                  This is equivalent to the method ``numpy.sum``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |          Axis for the function to be applied on.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when computing the result.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      min_count : int, default 0\n",
      " |          The required number of valid values to perform the operation. If fewer than\n",
      " |          ``min_count`` non-NA values are present the result will be NA.\n",
      " |      \n",
      " |          .. versionadded:: 0.22.0\n",
      " |      \n",
      " |             Added with the default being 0. This means the sum of an all-NA\n",
      " |             or empty Series is 0, and the product of an all-NA or empty\n",
      " |             Series is 1.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments to be passed to the function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series (if level specified)\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sum : Return the sum.\n",
      " |      Series.min : Return the minimum.\n",
      " |      Series.max : Return the maximum.\n",
      " |      Series.idxmin : Return the index of the minimum.\n",
      " |      Series.idxmax : Return the index of the maximum.\n",
      " |      DataFrame.sum : Return the sum over the requested axis.\n",
      " |      DataFrame.min : Return the minimum over the requested axis.\n",
      " |      DataFrame.max : Return the maximum over the requested axis.\n",
      " |      DataFrame.idxmin : Return the index of the minimum over the requested axis.\n",
      " |      DataFrame.idxmax : Return the index of the maximum over the requested axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.MultiIndex.from_arrays([\n",
      " |      ...     ['warm', 'warm', 'cold', 'cold'],\n",
      " |      ...     ['dog', 'falcon', 'fish', 'spider']],\n",
      " |      ...     names=['blooded', 'animal'])\n",
      " |      >>> s = pd.Series([4, 2, 0, 8], name='legs', index=idx)\n",
      " |      >>> s\n",
      " |      blooded  animal\n",
      " |      warm     dog       4\n",
      " |               falcon    2\n",
      " |      cold     fish      0\n",
      " |               spider    8\n",
      " |      Name: legs, dtype: int64\n",
      " |      \n",
      " |      >>> s.sum()\n",
      " |      14\n",
      " |      \n",
      " |      Sum using level names, as well as indices.\n",
      " |      \n",
      " |      >>> s.sum(level='blooded')\n",
      " |      blooded\n",
      " |      warm    6\n",
      " |      cold    8\n",
      " |      Name: legs, dtype: int64\n",
      " |      \n",
      " |      >>> s.sum(level=0)\n",
      " |      blooded\n",
      " |      warm    6\n",
      " |      cold    8\n",
      " |      Name: legs, dtype: int64\n",
      " |      \n",
      " |      By default, the sum of an empty or all-NA Series is ``0``.\n",
      " |      \n",
      " |      >>> pd.Series([]).sum()  # min_count=0 is the default\n",
      " |      0.0\n",
      " |      \n",
      " |      This can be controlled with the ``min_count`` parameter. For example, if\n",
      " |      you'd like the sum of an empty series to be NaN, pass ``min_count=1``.\n",
      " |      \n",
      " |      >>> pd.Series([]).sum(min_count=1)\n",
      " |      nan\n",
      " |      \n",
      " |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and\n",
      " |      empty series identically.\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).sum()\n",
      " |      0.0\n",
      " |      \n",
      " |      >>> pd.Series([np.nan]).sum(min_count=1)\n",
      " |      nan\n",
      " |  \n",
      " |  swaplevel(self, i=-2, j=-1, copy=True)\n",
      " |      Swap levels i and j in a :class:`MultiIndex`.\n",
      " |      \n",
      " |      Default is to swap the two innermost levels of the index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      i, j : int, str\n",
      " |          Level of the indices to be swapped. Can pass level name as string.\n",
      " |      copy : bool, default True\n",
      " |          Whether to copy underlying data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Series with levels swapped in MultiIndex.\n",
      " |  \n",
      " |  take(self, indices, axis=0, is_copy=None, **kwargs) -> 'Series'\n",
      " |      Return the elements in the given *positional* indices along an axis.\n",
      " |      \n",
      " |      This means that we are not indexing according to actual values in\n",
      " |      the index attribute of the object. We are indexing according to the\n",
      " |      actual position of the element in the object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      indices : array-like\n",
      " |          An array of ints indicating which positions to take.\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default 0\n",
      " |          The axis on which to select elements. ``0`` means that we are\n",
      " |          selecting rows, ``1`` means that we are selecting columns.\n",
      " |      is_copy : bool\n",
      " |          Before pandas 1.0, ``is_copy=False`` can be specified to ensure\n",
      " |          that the return value is an actual copy. Starting with pandas 1.0,\n",
      " |          ``take`` always returns a copy, and the keyword is therefore\n",
      " |          deprecated.\n",
      " |      \n",
      " |          .. deprecated:: 1.0.0\n",
      " |      **kwargs\n",
      " |          For compatibility with :meth:`numpy.take`. Has no effect on the\n",
      " |          output.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      taken : same type as caller\n",
      " |          An array-like containing the elements taken from the object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Select a subset of a DataFrame by labels.\n",
      " |      DataFrame.iloc : Select a subset of a DataFrame by positions.\n",
      " |      numpy.take : Take elements from an array along an axis.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('falcon', 'bird', 389.0),\n",
      " |      ...                    ('parrot', 'bird', 24.0),\n",
      " |      ...                    ('lion', 'mammal', 80.5),\n",
      " |      ...                    ('monkey', 'mammal', np.nan)],\n",
      " |      ...                   columns=['name', 'class', 'max_speed'],\n",
      " |      ...                   index=[0, 2, 3, 1])\n",
      " |      >>> df\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      2  parrot    bird       24.0\n",
      " |      3    lion  mammal       80.5\n",
      " |      1  monkey  mammal        NaN\n",
      " |      \n",
      " |      Take elements at positions 0 and 3 along the axis 0 (default).\n",
      " |      \n",
      " |      Note how the actual indices selected (0 and 1) do not correspond to\n",
      " |      our selected indices 0 and 3. That's because we are selecting the 0th\n",
      " |      and 3rd rows, not rows whose indices equal 0 and 3.\n",
      " |      \n",
      " |      >>> df.take([0, 3])\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      1  monkey  mammal        NaN\n",
      " |      \n",
      " |      Take elements at indices 1 and 2 along the axis 1 (column selection).\n",
      " |      \n",
      " |      >>> df.take([1, 2], axis=1)\n",
      " |          class  max_speed\n",
      " |      0    bird      389.0\n",
      " |      2    bird       24.0\n",
      " |      3  mammal       80.5\n",
      " |      1  mammal        NaN\n",
      " |      \n",
      " |      We may take elements using negative integers for positive indices,\n",
      " |      starting from the end of the object, just like with Python lists.\n",
      " |      \n",
      " |      >>> df.take([-1, -2])\n",
      " |           name   class  max_speed\n",
      " |      1  monkey  mammal        NaN\n",
      " |      3    lion  mammal       80.5\n",
      " |  \n",
      " |  to_dict(self, into=<class 'dict'>)\n",
      " |      Convert Series to {label -> value} dict or dict-like object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      into : class, default dict\n",
      " |          The collections.abc.Mapping subclass to use as the return\n",
      " |          object. Can be the actual class or an empty\n",
      " |          instance of the mapping type you want.  If you want a\n",
      " |          collections.defaultdict, you must pass it initialized.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      collections.abc.Mapping\n",
      " |          Key-value representation of Series.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s.to_dict()\n",
      " |      {0: 1, 1: 2, 2: 3, 3: 4}\n",
      " |      >>> from collections import OrderedDict, defaultdict\n",
      " |      >>> s.to_dict(OrderedDict)\n",
      " |      OrderedDict([(0, 1), (1, 2), (2, 3), (3, 4)])\n",
      " |      >>> dd = defaultdict(list)\n",
      " |      >>> s.to_dict(dd)\n",
      " |      defaultdict(<class 'list'>, {0: 1, 1: 2, 2: 3, 3: 4})\n",
      " |  \n",
      " |  to_frame(self, name=None)\n",
      " |      Convert Series to DataFrame.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : object, default None\n",
      " |          The passed name should substitute for the series name (if it has\n",
      " |          one).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          DataFrame representation of Series.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([\"a\", \"b\", \"c\"],\n",
      " |      ...               name=\"vals\")\n",
      " |      >>> s.to_frame()\n",
      " |        vals\n",
      " |      0    a\n",
      " |      1    b\n",
      " |      2    c\n",
      " |  \n",
      " |  to_markdown(self, buf: Union[IO[str], NoneType] = None, mode: Union[str, NoneType] = None, **kwargs) -> Union[str, NoneType]\n",
      " |      Print Series in Markdown-friendly format.\n",
      " |      \n",
      " |      .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      buf : writable buffer, defaults to sys.stdout\n",
      " |          Where to send the output. By default, the output is printed to\n",
      " |          sys.stdout. Pass a writable buffer if you need to further process\n",
      " |          the output.\n",
      " |      mode : str, optional\n",
      " |          Mode in which file is opened.\n",
      " |      **kwargs\n",
      " |          These parameters will be passed to `tabulate`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |          Series in Markdown-friendly format.\n",
      " |      \n",
      " |              Examples\n",
      " |              --------\n",
      " |              >>> s = pd.Series([\"elk\", \"pig\", \"dog\", \"quetzal\"], name=\"animal\")\n",
      " |              >>> print(s.to_markdown())\n",
      " |              |    | animal   |\n",
      " |              |---:|:---------|\n",
      " |              |  0 | elk      |\n",
      " |              |  1 | pig      |\n",
      " |              |  2 | dog      |\n",
      " |              |  3 | quetzal  |\n",
      " |  \n",
      " |  to_period(self, freq=None, copy=True)\n",
      " |      Convert Series from DatetimeIndex to PeriodIndex with desired\n",
      " |      frequency (inferred from index if not passed).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : str, default None\n",
      " |          Frequency associated with the PeriodIndex.\n",
      " |      copy : bool, default True\n",
      " |          Whether or not to return a copy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          Series with index converted to PeriodIndex.\n",
      " |  \n",
      " |  to_string(self, buf=None, na_rep='NaN', float_format=None, header=True, index=True, length=False, dtype=False, name=False, max_rows=None, min_rows=None)\n",
      " |      Render a string representation of the Series.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      buf : StringIO-like, optional\n",
      " |          Buffer to write to.\n",
      " |      na_rep : str, optional\n",
      " |          String representation of NaN to use, default 'NaN'.\n",
      " |      float_format : one-parameter function, optional\n",
      " |          Formatter function to apply to columns' elements if they are\n",
      " |          floats, default None.\n",
      " |      header : bool, default True\n",
      " |          Add the Series header (index name).\n",
      " |      index : bool, optional\n",
      " |          Add index (row) labels, default True.\n",
      " |      length : bool, default False\n",
      " |          Add the Series length.\n",
      " |      dtype : bool, default False\n",
      " |          Add the Series dtype.\n",
      " |      name : bool, default False\n",
      " |          Add the Series name if not None.\n",
      " |      max_rows : int, optional\n",
      " |          Maximum number of rows to show before truncating. If None, show\n",
      " |          all.\n",
      " |      min_rows : int, optional\n",
      " |          The number of rows to display in a truncated repr (when number\n",
      " |          of rows is above `max_rows`).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str or None\n",
      " |          String representation of Series if ``buf=None``, otherwise None.\n",
      " |  \n",
      " |  to_timestamp(self, freq=None, how='start', copy=True)\n",
      " |      Cast to DatetimeIndex of Timestamps, at *beginning* of period.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : str, default frequency of PeriodIndex\n",
      " |          Desired frequency.\n",
      " |      how : {'s', 'e', 'start', 'end'}\n",
      " |          Convention for converting period to timestamp; start of period\n",
      " |          vs. end.\n",
      " |      copy : bool, default True\n",
      " |          Whether or not to return a copy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series with DatetimeIndex\n",
      " |  \n",
      " |  transform(self, func, axis=0, *args, **kwargs)\n",
      " |      Call ``func`` on self producing a Series with transformed values.\n",
      " |      \n",
      " |      Produced Series will have same axis length as self.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function, str, list or dict\n",
      " |          Function to use for transforming the data. If a function, must either\n",
      " |          work when passed a Series or when passed to Series.apply.\n",
      " |      \n",
      " |          Accepted combinations are:\n",
      " |      \n",
      " |          - function\n",
      " |          - string function name\n",
      " |          - list of functions and/or function names, e.g. ``[np.exp. 'sqrt']``\n",
      " |          - dict of axis labels -> functions, function names or list of such.\n",
      " |      axis : {0 or 'index'}\n",
      " |          Parameter needed for compatibility with DataFrame.\n",
      " |      *args\n",
      " |          Positional arguments to pass to `func`.\n",
      " |      **kwargs\n",
      " |          Keyword arguments to pass to `func`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          A Series that must have the same length as self.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError : If the returned Series has a different length than self.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.agg : Only perform aggregating type operations.\n",
      " |      Series.apply : Invoke function on a Series.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': range(3), 'B': range(1, 4)})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  0  1\n",
      " |      1  1  2\n",
      " |      2  2  3\n",
      " |      >>> df.transform(lambda x: x + 1)\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      1  2  3\n",
      " |      2  3  4\n",
      " |      \n",
      " |      Even though the resulting Series must have the same length as the\n",
      " |      input Series, it is possible to provide several input functions:\n",
      " |      \n",
      " |      >>> s = pd.Series(range(3))\n",
      " |      >>> s\n",
      " |      0    0\n",
      " |      1    1\n",
      " |      2    2\n",
      " |      dtype: int64\n",
      " |      >>> s.transform([np.sqrt, np.exp])\n",
      " |             sqrt        exp\n",
      " |      0  0.000000   1.000000\n",
      " |      1  1.000000   2.718282\n",
      " |      2  1.414214   7.389056\n",
      " |  \n",
      " |  truediv(self, other, level=None, fill_value=None, axis=0)\n",
      " |      Return Floating division of series and other, element-wise (binary operator `truediv`).\n",
      " |      \n",
      " |      Equivalent to ``series / other``, but with support to substitute a fill_value for\n",
      " |      missing data in one of the inputs.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or scalar value\n",
      " |      fill_value : None or float value, default None (NaN)\n",
      " |          Fill existing missing (NaN) values, and any new element needed for\n",
      " |          successful Series alignment, with this value before computation.\n",
      " |          If data in both corresponding Series locations is missing\n",
      " |          the result will be missing.\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The result of the operation.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.rtruediv\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> a = pd.Series([1, 1, 1, np.nan], index=['a', 'b', 'c', 'd'])\n",
      " |      >>> a\n",
      " |      a    1.0\n",
      " |      b    1.0\n",
      " |      c    1.0\n",
      " |      d    NaN\n",
      " |      dtype: float64\n",
      " |      >>> b = pd.Series([1, np.nan, 1, np.nan], index=['a', 'b', 'd', 'e'])\n",
      " |      >>> b\n",
      " |      a    1.0\n",
      " |      b    NaN\n",
      " |      d    1.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |      >>> a.divide(b, fill_value=0)\n",
      " |      a    1.0\n",
      " |      b    inf\n",
      " |      c    inf\n",
      " |      d    0.0\n",
      " |      e    NaN\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  unique(self)\n",
      " |      Return unique values of Series object.\n",
      " |      \n",
      " |      Uniques are returned in order of appearance. Hash table-based unique,\n",
      " |      therefore does NOT sort.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray or ExtensionArray\n",
      " |          The unique values returned as a NumPy array. See Notes.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      unique : Top-level unique method for any 1-d array-like object.\n",
      " |      Index.unique : Return Index with unique values from an Index object.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Returns the unique values as a NumPy array. In case of an\n",
      " |      extension-array backed Series, a new\n",
      " |      :class:`~api.extensions.ExtensionArray` of that type with just\n",
      " |      the unique values is returned. This includes\n",
      " |      \n",
      " |          * Categorical\n",
      " |          * Period\n",
      " |          * Datetime with Timezone\n",
      " |          * Interval\n",
      " |          * Sparse\n",
      " |          * IntegerNA\n",
      " |      \n",
      " |      See Examples section.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> pd.Series([2, 1, 3, 3], name='A').unique()\n",
      " |      array([2, 1, 3])\n",
      " |      \n",
      " |      >>> pd.Series([pd.Timestamp('2016-01-01') for _ in range(3)]).unique()\n",
      " |      array(['2016-01-01T00:00:00.000000000'], dtype='datetime64[ns]')\n",
      " |      \n",
      " |      >>> pd.Series([pd.Timestamp('2016-01-01', tz='US/Eastern')\n",
      " |      ...            for _ in range(3)]).unique()\n",
      " |      <DatetimeArray>\n",
      " |      ['2016-01-01 00:00:00-05:00']\n",
      " |      Length: 1, dtype: datetime64[ns, US/Eastern]\n",
      " |      \n",
      " |      An unordered Categorical will return categories in the order of\n",
      " |      appearance.\n",
      " |      \n",
      " |      >>> pd.Series(pd.Categorical(list('baabc'))).unique()\n",
      " |      [b, a, c]\n",
      " |      Categories (3, object): [b, a, c]\n",
      " |      \n",
      " |      An ordered Categorical preserves the category ordering.\n",
      " |      \n",
      " |      >>> pd.Series(pd.Categorical(list('baabc'), categories=list('abc'),\n",
      " |      ...                          ordered=True)).unique()\n",
      " |      [b, a, c]\n",
      " |      Categories (3, object): [a < b < c]\n",
      " |  \n",
      " |  unstack(self, level=-1, fill_value=None)\n",
      " |      Unstack, a.k.a. pivot, Series with MultiIndex to produce DataFrame.\n",
      " |      The level involved will automatically get sorted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, str, or list of these, default last level\n",
      " |          Level(s) to unstack, can pass level name.\n",
      " |      fill_value : scalar value, default None\n",
      " |          Value to use when replacing NaN values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          Unstacked Series.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4],\n",
      " |      ...               index=pd.MultiIndex.from_product([['one', 'two'],\n",
      " |      ...                                                 ['a', 'b']]))\n",
      " |      >>> s\n",
      " |      one  a    1\n",
      " |           b    2\n",
      " |      two  a    3\n",
      " |           b    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.unstack(level=-1)\n",
      " |           a  b\n",
      " |      one  1  2\n",
      " |      two  3  4\n",
      " |      \n",
      " |      >>> s.unstack(level=0)\n",
      " |         one  two\n",
      " |      a    1    3\n",
      " |      b    2    4\n",
      " |  \n",
      " |  update(self, other)\n",
      " |      Modify Series in place using non-NA values from passed\n",
      " |      Series. Aligns on index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.update(pd.Series([4, 5, 6]))\n",
      " |      >>> s\n",
      " |      0    4\n",
      " |      1    5\n",
      " |      2    6\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s = pd.Series(['a', 'b', 'c'])\n",
      " |      >>> s.update(pd.Series(['d', 'e'], index=[0, 2]))\n",
      " |      >>> s\n",
      " |      0    d\n",
      " |      1    b\n",
      " |      2    e\n",
      " |      dtype: object\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.update(pd.Series([4, 5, 6, 7, 8]))\n",
      " |      >>> s\n",
      " |      0    4\n",
      " |      1    5\n",
      " |      2    6\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      If ``other`` contains NaNs the corresponding values are not updated\n",
      " |      in the original Series.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.update(pd.Series([4, np.nan, 6]))\n",
      " |      >>> s\n",
      " |      0    4\n",
      " |      1    2\n",
      " |      2    6\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  var(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      " |      Return unbiased variance over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0)}\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA.\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a scalar.\n",
      " |      ddof : int, default 1\n",
      " |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,\n",
      " |          where N represents the number of elements.\n",
      " |      numeric_only : bool, default None\n",
      " |          Include only float, int, boolean columns. If None, will attempt to use\n",
      " |          everything, then use only numeric data. Not implemented for Series.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar or Series (if level specified)\n",
      " |  \n",
      " |  view(self, dtype=None)\n",
      " |      Create a new view of the Series.\n",
      " |      \n",
      " |      This function will return a new Series with a view of the same\n",
      " |      underlying values in memory, optionally reinterpreted with a new data\n",
      " |      type. The new data type must preserve the same size in bytes as to not\n",
      " |      cause index misalignment.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : data type\n",
      " |          Data type object or one of their string representations.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          A new Series object as a view of the same data in memory.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.view : Equivalent numpy function to create a new view of\n",
      " |          the same data in memory.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Series are instantiated with ``dtype=float64`` by default. While\n",
      " |      ``numpy.ndarray.view()`` will return a view with the same data type as\n",
      " |      the original array, ``Series.view()`` (without specified dtype)\n",
      " |      will try using ``float64`` and may fail if the original data type size\n",
      " |      in bytes is not the same.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([-2, -1, 0, 1, 2], dtype='int8')\n",
      " |      >>> s\n",
      " |      0   -2\n",
      " |      1   -1\n",
      " |      2    0\n",
      " |      3    1\n",
      " |      4    2\n",
      " |      dtype: int8\n",
      " |      \n",
      " |      The 8 bit signed integer representation of `-1` is `0b11111111`, but\n",
      " |      the same bytes represent 255 if read as an 8 bit unsigned integer:\n",
      " |      \n",
      " |      >>> us = s.view('uint8')\n",
      " |      >>> us\n",
      " |      0    254\n",
      " |      1    255\n",
      " |      2      0\n",
      " |      3      1\n",
      " |      4      2\n",
      " |      dtype: uint8\n",
      " |      \n",
      " |      The views share the same underlying values:\n",
      " |      \n",
      " |      >>> us[0] = 128\n",
      " |      >>> s\n",
      " |      0   -128\n",
      " |      1     -1\n",
      " |      2      0\n",
      " |      3      1\n",
      " |      4      2\n",
      " |      dtype: int8\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  array\n",
      " |      The ExtensionArray of the data backing this Series or Index.\n",
      " |      \n",
      " |      .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ExtensionArray\n",
      " |          An ExtensionArray of the values stored within. For extension\n",
      " |          types, this is the actual array. For NumPy native types, this\n",
      " |          is a thin (no copy) wrapper around :class:`numpy.ndarray`.\n",
      " |      \n",
      " |          ``.array`` differs ``.values`` which may require converting the\n",
      " |          data to a different form.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.to_numpy : Similar method that always returns a NumPy array.\n",
      " |      Series.to_numpy : Similar method that always returns a NumPy array.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This table lays out the different array types for each extension\n",
      " |      dtype within pandas.\n",
      " |      \n",
      " |      ================== =============================\n",
      " |      dtype              array type\n",
      " |      ================== =============================\n",
      " |      category           Categorical\n",
      " |      period             PeriodArray\n",
      " |      interval           IntervalArray\n",
      " |      IntegerNA          IntegerArray\n",
      " |      string             StringArray\n",
      " |      boolean            BooleanArray\n",
      " |      datetime64[ns, tz] DatetimeArray\n",
      " |      ================== =============================\n",
      " |      \n",
      " |      For any 3rd-party extension types, the array type will be an\n",
      " |      ExtensionArray.\n",
      " |      \n",
      " |      For all remaining dtypes ``.array`` will be a\n",
      " |      :class:`arrays.NumpyExtensionArray` wrapping the actual ndarray\n",
      " |      stored within. If you absolutely need a NumPy array (possibly with\n",
      " |      copying / coercing data), then use :meth:`Series.to_numpy` instead.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      For regular NumPy types like int, and float, a PandasArray\n",
      " |      is returned.\n",
      " |      \n",
      " |      >>> pd.Series([1, 2, 3]).array\n",
      " |      <PandasArray>\n",
      " |      [1, 2, 3]\n",
      " |      Length: 3, dtype: int64\n",
      " |      \n",
      " |      For extension types, like Categorical, the actual ExtensionArray\n",
      " |      is returned\n",
      " |      \n",
      " |      >>> ser = pd.Series(pd.Categorical(['a', 'b', 'a']))\n",
      " |      >>> ser.array\n",
      " |      [a, b, a]\n",
      " |      Categories (2, object): [a, b]\n",
      " |  \n",
      " |  axes\n",
      " |      Return a list of the row axis labels.\n",
      " |  \n",
      " |  dtype\n",
      " |      Return the dtype object of the underlying data.\n",
      " |  \n",
      " |  dtypes\n",
      " |      Return the dtype object of the underlying data.\n",
      " |  \n",
      " |  hasnans\n",
      " |      Return if I have any nans; enables various perf speedups.\n",
      " |  \n",
      " |  values\n",
      " |      Return Series as ndarray or ndarray-like depending on the dtype.\n",
      " |      \n",
      " |      .. warning::\n",
      " |      \n",
      " |         We recommend using :attr:`Series.array` or\n",
      " |         :meth:`Series.to_numpy`, depending on whether you need\n",
      " |         a reference to the underlying data or a NumPy array.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray or ndarray-like\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.array : Reference to the underlying data.\n",
      " |      Series.to_numpy : A NumPy array representing the underlying data.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> pd.Series([1, 2, 3]).values\n",
      " |      array([1, 2, 3])\n",
      " |      \n",
      " |      >>> pd.Series(list('aabc')).values\n",
      " |      array(['a', 'a', 'b', 'c'], dtype=object)\n",
      " |      \n",
      " |      >>> pd.Series(list('aabc')).astype('category').values\n",
      " |      [a, a, b, c]\n",
      " |      Categories (3, object): [a, b, c]\n",
      " |      \n",
      " |      Timezone aware datetime data is converted to UTC:\n",
      " |      \n",
      " |      >>> pd.Series(pd.date_range('20130101', periods=3,\n",
      " |      ...                         tz='US/Eastern')).values\n",
      " |      array(['2013-01-01T05:00:00.000000000',\n",
      " |             '2013-01-02T05:00:00.000000000',\n",
      " |             '2013-01-03T05:00:00.000000000'], dtype='datetime64[ns]')\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  index\n",
      " |      The index (axis labels) of the Series.\n",
      " |  \n",
      " |  name\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {'_data': <class 'pandas.core.internals.managers.Sin...\n",
      " |  \n",
      " |  cat = <class 'pandas.core.arrays.categorical.CategoricalAccessor'>\n",
      " |      Accessor object for categorical properties of the Series values.\n",
      " |      \n",
      " |      Be aware that assigning to `categories` is a inplace operation, while all\n",
      " |      methods return new categorical data per default (but can be called with\n",
      " |      `inplace=True`).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : Series or CategoricalIndex\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s.cat.categories\n",
      " |      >>> s.cat.categories = list('abc')\n",
      " |      >>> s.cat.rename_categories(list('cab'))\n",
      " |      >>> s.cat.reorder_categories(list('cab'))\n",
      " |      >>> s.cat.add_categories(['d','e'])\n",
      " |      >>> s.cat.remove_categories(['d'])\n",
      " |      >>> s.cat.remove_unused_categories()\n",
      " |      >>> s.cat.set_categories(list('abcde'))\n",
      " |      >>> s.cat.as_ordered()\n",
      " |      >>> s.cat.as_unordered()\n",
      " |  \n",
      " |  dt = <class 'pandas.core.indexes.accessors.CombinedDatetimelikePropert...\n",
      " |      Accessor object for datetimelike properties of the Series values.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s.dt.hour\n",
      " |      >>> s.dt.second\n",
      " |      >>> s.dt.quarter\n",
      " |      \n",
      " |      Returns a Series indexed like the original Series.\n",
      " |      Raises TypeError if the Series does not contain datetimelike values.\n",
      " |  \n",
      " |  plot = <class 'pandas.plotting._core.PlotAccessor'>\n",
      " |      Make plots of Series or DataFrame.\n",
      " |      \n",
      " |      Uses the backend specified by the\n",
      " |      option ``plotting.backend``. By default, matplotlib is used.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : Series or DataFrame\n",
      " |          The object for which the method is called.\n",
      " |      x : label or position, default None\n",
      " |          Only used if data is a DataFrame.\n",
      " |      y : label, position or list of label, positions, default None\n",
      " |          Allows plotting of one column versus another. Only used if data is a\n",
      " |          DataFrame.\n",
      " |      kind : str\n",
      " |          The kind of plot to produce:\n",
      " |      \n",
      " |          - 'line' : line plot (default)\n",
      " |          - 'bar' : vertical bar plot\n",
      " |          - 'barh' : horizontal bar plot\n",
      " |          - 'hist' : histogram\n",
      " |          - 'box' : boxplot\n",
      " |          - 'kde' : Kernel Density Estimation plot\n",
      " |          - 'density' : same as 'kde'\n",
      " |          - 'area' : area plot\n",
      " |          - 'pie' : pie plot\n",
      " |          - 'scatter' : scatter plot\n",
      " |          - 'hexbin' : hexbin plot.\n",
      " |      \n",
      " |      figsize : a tuple (width, height) in inches\n",
      " |      use_index : bool, default True\n",
      " |          Use index as ticks for x axis.\n",
      " |      title : str or list\n",
      " |          Title to use for the plot. If a string is passed, print the string\n",
      " |          at the top of the figure. If a list is passed and `subplots` is\n",
      " |          True, print each item in the list above the corresponding subplot.\n",
      " |      grid : bool, default None (matlab style default)\n",
      " |          Axis grid lines.\n",
      " |      legend : bool or {'reverse'}\n",
      " |          Place legend on axis subplots.\n",
      " |      style : list or dict\n",
      " |          The matplotlib line style per column.\n",
      " |      logx : bool or 'sym', default False\n",
      " |          Use log scaling or symlog scaling on x axis.\n",
      " |          .. versionchanged:: 0.25.0\n",
      " |      \n",
      " |      logy : bool or 'sym' default False\n",
      " |          Use log scaling or symlog scaling on y axis.\n",
      " |          .. versionchanged:: 0.25.0\n",
      " |      \n",
      " |      loglog : bool or 'sym', default False\n",
      " |          Use log scaling or symlog scaling on both x and y axes.\n",
      " |          .. versionchanged:: 0.25.0\n",
      " |      \n",
      " |      xticks : sequence\n",
      " |          Values to use for the xticks.\n",
      " |      yticks : sequence\n",
      " |          Values to use for the yticks.\n",
      " |      xlim : 2-tuple/list\n",
      " |      ylim : 2-tuple/list\n",
      " |      rot : int, default None\n",
      " |          Rotation for ticks (xticks for vertical, yticks for horizontal\n",
      " |          plots).\n",
      " |      fontsize : int, default None\n",
      " |          Font size for xticks and yticks.\n",
      " |      colormap : str or matplotlib colormap object, default None\n",
      " |          Colormap to select colors from. If string, load colormap with that\n",
      " |          name from matplotlib.\n",
      " |      colorbar : bool, optional\n",
      " |          If True, plot colorbar (only relevant for 'scatter' and 'hexbin'\n",
      " |          plots).\n",
      " |      position : float\n",
      " |          Specify relative alignments for bar plot layout.\n",
      " |          From 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5\n",
      " |          (center).\n",
      " |      table : bool, Series or DataFrame, default False\n",
      " |          If True, draw a table using the data in the DataFrame and the data\n",
      " |          will be transposed to meet matplotlib's default layout.\n",
      " |          If a Series or DataFrame is passed, use passed data to draw a\n",
      " |          table.\n",
      " |      yerr : DataFrame, Series, array-like, dict and str\n",
      " |          See :ref:`Plotting with Error Bars <visualization.errorbars>` for\n",
      " |          detail.\n",
      " |      xerr : DataFrame, Series, array-like, dict and str\n",
      " |          Equivalent to yerr.\n",
      " |      mark_right : bool, default True\n",
      " |          When using a secondary_y axis, automatically mark the column\n",
      " |          labels with \"(right)\" in the legend.\n",
      " |      include_bool : bool, default is False\n",
      " |          If True, boolean values can be plotted.\n",
      " |      backend : str, default None\n",
      " |          Backend to use instead of the backend specified in the option\n",
      " |          ``plotting.backend``. For instance, 'matplotlib'. Alternatively, to\n",
      " |          specify the ``plotting.backend`` for the whole session, set\n",
      " |          ``pd.options.plotting.backend``.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      **kwargs\n",
      " |          Options to pass to matplotlib plotting method.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      :class:`matplotlib.axes.Axes` or numpy.ndarray of them\n",
      " |          If the backend is not the default matplotlib one, the return value\n",
      " |          will be the object returned by the backend.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      - See matplotlib documentation online for more on this subject\n",
      " |      - If `kind` = 'bar' or 'barh', you can specify relative alignments\n",
      " |        for bar plot layout by `position` keyword.\n",
      " |        From 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5\n",
      " |        (center)\n",
      " |  \n",
      " |  sparse = <class 'pandas.core.arrays.sparse.accessor.SparseAccessor'>\n",
      " |      Accessor for SparseSparse from other sparse matrix data types.\n",
      " |  \n",
      " |  str = <class 'pandas.core.strings.StringMethods'>\n",
      " |      Vectorized string functions for Series and Index. NAs stay NA unless\n",
      " |      handled otherwise by a particular method. Patterned after Python's string\n",
      " |      methods, with some inspiration from R's stringr package.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s.str.split('_')\n",
      " |      >>> s.str.replace('_', '')\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.IndexOpsMixin:\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Return an iterator of the values.\n",
      " |      \n",
      " |      These are each a scalar type, which is a Python scalar\n",
      " |      (for str, int, float) or a pandas scalar\n",
      " |      (for Timestamp/Timedelta/Interval/Period)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      iterator\n",
      " |  \n",
      " |  argmax(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return an ndarray of the maximum argument indexer.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {None}\n",
      " |          Dummy argument for consistency with Series.\n",
      " |      skipna : bool, default True\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray\n",
      " |          Indices of the maximum values.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.argmax\n",
      " |  \n",
      " |  argmin(self, axis=None, skipna=True, *args, **kwargs)\n",
      " |      Return a ndarray of the minimum argument indexer.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {None}\n",
      " |          Dummy argument for consistency with Series.\n",
      " |      skipna : bool, default True\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.argmin\n",
      " |  \n",
      " |  factorize(self, sort=False, na_sentinel=-1)\n",
      " |      Encode the object as an enumerated type or categorical variable.\n",
      " |      \n",
      " |      This method is useful for obtaining a numeric representation of an\n",
      " |      array when all that matters is identifying distinct values. `factorize`\n",
      " |      is available as both a top-level function :func:`pandas.factorize`,\n",
      " |      and as a method :meth:`Series.factorize` and :meth:`Index.factorize`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sort : bool, default False\n",
      " |          Sort `uniques` and shuffle `codes` to maintain the\n",
      " |          relationship.\n",
      " |      \n",
      " |      na_sentinel : int, default -1\n",
      " |          Value to mark \"not found\".\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      codes : ndarray\n",
      " |          An integer ndarray that's an indexer into `uniques`.\n",
      " |          ``uniques.take(codes)`` will have the same values as `values`.\n",
      " |      uniques : ndarray, Index, or Categorical\n",
      " |          The unique valid values. When `values` is Categorical, `uniques`\n",
      " |          is a Categorical. When `values` is some other pandas object, an\n",
      " |          `Index` is returned. Otherwise, a 1-D ndarray is returned.\n",
      " |      \n",
      " |          .. note ::\n",
      " |      \n",
      " |             Even if there's a missing value in `values`, `uniques` will\n",
      " |             *not* contain an entry for it.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      cut : Discretize continuous-valued array.\n",
      " |      unique : Find the unique value in an array.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      These examples all show factorize as a top-level method like\n",
      " |      ``pd.factorize(values)``. The results are identical for methods like\n",
      " |      :meth:`Series.factorize`.\n",
      " |      \n",
      " |      >>> codes, uniques = pd.factorize(['b', 'b', 'a', 'c', 'b'])\n",
      " |      >>> codes\n",
      " |      array([0, 0, 1, 2, 0])\n",
      " |      >>> uniques\n",
      " |      array(['b', 'a', 'c'], dtype=object)\n",
      " |      \n",
      " |      With ``sort=True``, the `uniques` will be sorted, and `codes` will be\n",
      " |      shuffled so that the relationship is the maintained.\n",
      " |      \n",
      " |      >>> codes, uniques = pd.factorize(['b', 'b', 'a', 'c', 'b'], sort=True)\n",
      " |      >>> codes\n",
      " |      array([1, 1, 0, 2, 1])\n",
      " |      >>> uniques\n",
      " |      array(['a', 'b', 'c'], dtype=object)\n",
      " |      \n",
      " |      Missing values are indicated in `codes` with `na_sentinel`\n",
      " |      (``-1`` by default). Note that missing values are never\n",
      " |      included in `uniques`.\n",
      " |      \n",
      " |      >>> codes, uniques = pd.factorize(['b', None, 'a', 'c', 'b'])\n",
      " |      >>> codes\n",
      " |      array([ 0, -1,  1,  2,  0])\n",
      " |      >>> uniques\n",
      " |      array(['b', 'a', 'c'], dtype=object)\n",
      " |      \n",
      " |      Thus far, we've only factorized lists (which are internally coerced to\n",
      " |      NumPy arrays). When factorizing pandas objects, the type of `uniques`\n",
      " |      will differ. For Categoricals, a `Categorical` is returned.\n",
      " |      \n",
      " |      >>> cat = pd.Categorical(['a', 'a', 'c'], categories=['a', 'b', 'c'])\n",
      " |      >>> codes, uniques = pd.factorize(cat)\n",
      " |      >>> codes\n",
      " |      array([0, 0, 1])\n",
      " |      >>> uniques\n",
      " |      [a, c]\n",
      " |      Categories (3, object): [a, b, c]\n",
      " |      \n",
      " |      Notice that ``'b'`` is in ``uniques.categories``, despite not being\n",
      " |      present in ``cat.values``.\n",
      " |      \n",
      " |      For all other pandas objects, an Index of the appropriate type is\n",
      " |      returned.\n",
      " |      \n",
      " |      >>> cat = pd.Series(['a', 'a', 'c'])\n",
      " |      >>> codes, uniques = pd.factorize(cat)\n",
      " |      >>> codes\n",
      " |      array([0, 0, 1])\n",
      " |      >>> uniques\n",
      " |      Index(['a', 'c'], dtype='object')\n",
      " |  \n",
      " |  item(self)\n",
      " |      Return the first element of the underlying data as a python scalar.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar\n",
      " |          The first element of %(klass)s.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          If the data is not length-1.\n",
      " |  \n",
      " |  nunique(self, dropna=True)\n",
      " |      Return number of unique elements in the object.\n",
      " |      \n",
      " |      Excludes NA values by default.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dropna : bool, default True\n",
      " |          Don't include NaN in the count.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      int\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.nunique: Method nunique for DataFrame.\n",
      " |      Series.count: Count non-NA/null observations in the Series.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 3, 5, 7, 7])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    3\n",
      " |      2    5\n",
      " |      3    7\n",
      " |      4    7\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.nunique()\n",
      " |      4\n",
      " |  \n",
      " |  to_list = tolist(self)\n",
      " |  \n",
      " |  to_numpy(self, dtype=None, copy=False, na_value=<object object at 0x034928B8>, **kwargs)\n",
      " |      A NumPy ndarray representing the values in this Series or Index.\n",
      " |      \n",
      " |      .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : str or numpy.dtype, optional\n",
      " |          The dtype to pass to :meth:`numpy.asarray`.\n",
      " |      copy : bool, default False\n",
      " |          Whether to ensure that the returned value is a not a view on\n",
      " |          another array. Note that ``copy=False`` does not *ensure* that\n",
      " |          ``to_numpy()`` is no-copy. Rather, ``copy=True`` ensure that\n",
      " |          a copy is made, even if not strictly necessary.\n",
      " |      na_value : Any, optional\n",
      " |          The value to use for missing values. The default value depends\n",
      " |          on `dtype` and the type of the array.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      **kwargs\n",
      " |          Additional keywords passed through to the ``to_numpy`` method\n",
      " |          of the underlying array (for extension arrays).\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.array : Get the actual data stored within.\n",
      " |      Index.array : Get the actual data stored within.\n",
      " |      DataFrame.to_numpy : Similar method for DataFrame.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The returned array will be the same up to equality (values equal\n",
      " |      in `self` will be equal in the returned array; likewise for values\n",
      " |      that are not equal). When `self` contains an ExtensionArray, the\n",
      " |      dtype may be different. For example, for a category-dtype Series,\n",
      " |      ``to_numpy()`` will return a NumPy array and the categorical dtype\n",
      " |      will be lost.\n",
      " |      \n",
      " |      For NumPy dtypes, this will be a reference to the actual data stored\n",
      " |      in this Series or Index (assuming ``copy=False``). Modifying the result\n",
      " |      in place will modify the data stored in the Series or Index (not that\n",
      " |      we recommend doing that).\n",
      " |      \n",
      " |      For extension types, ``to_numpy()`` *may* require copying data and\n",
      " |      coercing the result to a NumPy type (possibly object), which may be\n",
      " |      expensive. When you need a no-copy reference to the underlying data,\n",
      " |      :attr:`Series.array` should be used instead.\n",
      " |      \n",
      " |      This table lays out the different dtypes and default return types of\n",
      " |      ``to_numpy()`` for various dtypes within pandas.\n",
      " |      \n",
      " |      ================== ================================\n",
      " |      dtype              array type\n",
      " |      ================== ================================\n",
      " |      category[T]        ndarray[T] (same dtype as input)\n",
      " |      period             ndarray[object] (Periods)\n",
      " |      interval           ndarray[object] (Intervals)\n",
      " |      IntegerNA          ndarray[object]\n",
      " |      datetime64[ns]     datetime64[ns]\n",
      " |      datetime64[ns, tz] ndarray[object] (Timestamps)\n",
      " |      ================== ================================\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> ser = pd.Series(pd.Categorical(['a', 'b', 'a']))\n",
      " |      >>> ser.to_numpy()\n",
      " |      array(['a', 'b', 'a'], dtype=object)\n",
      " |      \n",
      " |      Specify the `dtype` to control how datetime-aware data is represented.\n",
      " |      Use ``dtype=object`` to return an ndarray of pandas :class:`Timestamp`\n",
      " |      objects, each with the correct ``tz``.\n",
      " |      \n",
      " |      >>> ser = pd.Series(pd.date_range('2000', periods=2, tz=\"CET\"))\n",
      " |      >>> ser.to_numpy(dtype=object)\n",
      " |      array([Timestamp('2000-01-01 00:00:00+0100', tz='CET', freq='D'),\n",
      " |             Timestamp('2000-01-02 00:00:00+0100', tz='CET', freq='D')],\n",
      " |            dtype=object)\n",
      " |      \n",
      " |      Or ``dtype='datetime64[ns]'`` to return an ndarray of native\n",
      " |      datetime64 values. The values are converted to UTC and the timezone\n",
      " |      info is dropped.\n",
      " |      \n",
      " |      >>> ser.to_numpy(dtype=\"datetime64[ns]\")\n",
      " |      ... # doctest: +ELLIPSIS\n",
      " |      array(['1999-12-31T23:00:00.000000000', '2000-01-01T23:00:00...'],\n",
      " |            dtype='datetime64[ns]')\n",
      " |  \n",
      " |  tolist(self)\n",
      " |      Return a list of the values.\n",
      " |      \n",
      " |      These are each a scalar type, which is a Python scalar\n",
      " |      (for str, int, float) or a pandas scalar\n",
      " |      (for Timestamp/Timedelta/Interval/Period)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.tolist\n",
      " |  \n",
      " |  transpose(self, *args, **kwargs)\n",
      " |      Return the transpose, which is by definition self.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      %(klass)s\n",
      " |  \n",
      " |  value_counts(self, normalize=False, sort=True, ascending=False, bins=None, dropna=True)\n",
      " |      Return a Series containing counts of unique values.\n",
      " |      \n",
      " |      The resulting object will be in descending order so that the\n",
      " |      first element is the most frequently-occurring element.\n",
      " |      Excludes NA values by default.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      normalize : bool, default False\n",
      " |          If True then the object returned will contain the relative\n",
      " |          frequencies of the unique values.\n",
      " |      sort : bool, default True\n",
      " |          Sort by frequencies.\n",
      " |      ascending : bool, default False\n",
      " |          Sort in ascending order.\n",
      " |      bins : int, optional\n",
      " |          Rather than count values, group them into half-open bins,\n",
      " |          a convenience for ``pd.cut``, only works with numeric data.\n",
      " |      dropna : bool, default True\n",
      " |          Don't include counts of NaN.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.count: Number of non-NA elements in a Series.\n",
      " |      DataFrame.count: Number of non-NA elements in a DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> index = pd.Index([3, 1, 2, 3, 4, np.nan])\n",
      " |      >>> index.value_counts()\n",
      " |      3.0    2\n",
      " |      4.0    1\n",
      " |      2.0    1\n",
      " |      1.0    1\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      With `normalize` set to `True`, returns the relative frequency by\n",
      " |      dividing all values by the sum of values.\n",
      " |      \n",
      " |      >>> s = pd.Series([3, 1, 2, 3, 4, np.nan])\n",
      " |      >>> s.value_counts(normalize=True)\n",
      " |      3.0    0.4\n",
      " |      4.0    0.2\n",
      " |      2.0    0.2\n",
      " |      1.0    0.2\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **bins**\n",
      " |      \n",
      " |      Bins can be useful for going from a continuous variable to a\n",
      " |      categorical variable; instead of counting unique\n",
      " |      apparitions of values, divide the index in the specified\n",
      " |      number of half-open bins.\n",
      " |      \n",
      " |      >>> s.value_counts(bins=3)\n",
      " |      (2.0, 3.0]      2\n",
      " |      (0.996, 2.0]    2\n",
      " |      (3.0, 4.0]      1\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      **dropna**\n",
      " |      \n",
      " |      With `dropna` set to `False` we can also see NaN index values.\n",
      " |      \n",
      " |      >>> s.value_counts(dropna=False)\n",
      " |      3.0    2\n",
      " |      NaN    1\n",
      " |      4.0    1\n",
      " |      2.0    1\n",
      " |      1.0    1\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from pandas.core.base.IndexOpsMixin:\n",
      " |  \n",
      " |  T\n",
      " |      Return the transpose, which is by definition self.\n",
      " |  \n",
      " |  empty\n",
      " |  \n",
      " |  is_monotonic\n",
      " |      Return boolean if values in the object are\n",
      " |      monotonic_increasing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |  \n",
      " |  is_monotonic_decreasing\n",
      " |      Return boolean if values in the object are\n",
      " |      monotonic_decreasing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |  \n",
      " |  is_monotonic_increasing\n",
      " |      Return boolean if values in the object are\n",
      " |      monotonic_increasing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |  \n",
      " |  is_unique\n",
      " |      Return boolean if values in the object are unique.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |  \n",
      " |  nbytes\n",
      " |      Return the number of bytes in the underlying data.\n",
      " |  \n",
      " |  ndim\n",
      " |      Number of dimensions of the underlying data, by definition 1.\n",
      " |  \n",
      " |  shape\n",
      " |      Return a tuple of the shape of the underlying data.\n",
      " |  \n",
      " |  size\n",
      " |      Return the number of elements in the underlying data.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.base.IndexOpsMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pandas.core.base.IndexOpsMixin:\n",
      " |  \n",
      " |  __array_priority__ = 1000\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  __abs__(self: ~FrameOrSeries) -> ~FrameOrSeries\n",
      " |  \n",
      " |  __array_wrap__(self, result, context=None)\n",
      " |  \n",
      " |  __bool__ = __nonzero__(self)\n",
      " |  \n",
      " |  __contains__(self, key) -> bool\n",
      " |      True if the key is in the info axis\n",
      " |  \n",
      " |  __copy__(self: ~FrameOrSeries, deep: bool = True) -> ~FrameOrSeries\n",
      " |  \n",
      " |  __deepcopy__(self: ~FrameOrSeries, memo=None) -> ~FrameOrSeries\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      memo, default None\n",
      " |          Standard signature. Unused\n",
      " |  \n",
      " |  __delitem__(self, key) -> None\n",
      " |      Delete item\n",
      " |  \n",
      " |  __finalize__(self: ~FrameOrSeries, other, method=None, **kwargs) -> ~FrameOrSeries\n",
      " |      Propagate metadata from other to self.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : the object from which to get the attributes that we are going\n",
      " |          to propagate\n",
      " |      method : optional, a passed method name ; possibly to take different\n",
      " |          types of propagation actions based on this\n",
      " |  \n",
      " |  __getattr__(self, name: str)\n",
      " |      After regular attribute access, try looking up the name\n",
      " |      This allows simpler access to columns for interactive use.\n",
      " |  \n",
      " |  __getstate__(self) -> Dict[str, Any]\n",
      " |  \n",
      " |  __hash__(self)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __invert__(self)\n",
      " |  \n",
      " |  __neg__(self)\n",
      " |  \n",
      " |  __nonzero__(self)\n",
      " |  \n",
      " |  __pos__(self)\n",
      " |  \n",
      " |  __round__(self: ~FrameOrSeries, decimals: int = 0) -> ~FrameOrSeries\n",
      " |  \n",
      " |  __setattr__(self, name: str, value) -> None\n",
      " |      After regular attribute access, try setting the name\n",
      " |      This allows simpler access to columns for interactive use.\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  abs(self: ~FrameOrSeries) -> ~FrameOrSeries\n",
      " |      Return a Series/DataFrame with absolute numeric value of each element.\n",
      " |      \n",
      " |      This function only applies to elements that are all numeric.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      abs\n",
      " |          Series/DataFrame containing the absolute value of each element.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.absolute : Calculate the absolute value element-wise.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For ``complex`` inputs, ``1.2 + 1j``, the absolute value is\n",
      " |      :math:`\\sqrt{ a^2 + b^2 }`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Absolute numeric values in a Series.\n",
      " |      \n",
      " |      >>> s = pd.Series([-1.10, 2, -3.33, 4])\n",
      " |      >>> s.abs()\n",
      " |      0    1.10\n",
      " |      1    2.00\n",
      " |      2    3.33\n",
      " |      3    4.00\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Absolute numeric values in a Series with complex numbers.\n",
      " |      \n",
      " |      >>> s = pd.Series([1.2 + 1j])\n",
      " |      >>> s.abs()\n",
      " |      0    1.56205\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Absolute numeric values in a Series with a Timedelta element.\n",
      " |      \n",
      " |      >>> s = pd.Series([pd.Timedelta('1 days')])\n",
      " |      >>> s.abs()\n",
      " |      0   1 days\n",
      " |      dtype: timedelta64[ns]\n",
      " |      \n",
      " |      Select rows with data closest to certain value using argsort (from\n",
      " |      `StackOverflow <https://stackoverflow.com/a/17758115>`__).\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'a': [4, 5, 6, 7],\n",
      " |      ...     'b': [10, 20, 30, 40],\n",
      " |      ...     'c': [100, 50, -30, -50]\n",
      " |      ... })\n",
      " |      >>> df\n",
      " |           a    b    c\n",
      " |      0    4   10  100\n",
      " |      1    5   20   50\n",
      " |      2    6   30  -30\n",
      " |      3    7   40  -50\n",
      " |      >>> df.loc[(df.c - 43).abs().argsort()]\n",
      " |           a    b    c\n",
      " |      1    5   20   50\n",
      " |      0    4   10  100\n",
      " |      2    6   30  -30\n",
      " |      3    7   40  -50\n",
      " |  \n",
      " |  add_prefix(self: ~FrameOrSeries, prefix: str) -> ~FrameOrSeries\n",
      " |      Prefix labels with string `prefix`.\n",
      " |      \n",
      " |      For Series, the row labels are prefixed.\n",
      " |      For DataFrame, the column labels are prefixed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      prefix : str\n",
      " |          The string to add before each label.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          New Series or DataFrame with updated labels.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.add_suffix: Suffix row labels with string `suffix`.\n",
      " |      DataFrame.add_suffix: Suffix column labels with string `suffix`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.add_prefix('item_')\n",
      " |      item_0    1\n",
      " |      item_1    2\n",
      " |      item_2    3\n",
      " |      item_3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3, 4], 'B': [3, 4, 5, 6]})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  1  3\n",
      " |      1  2  4\n",
      " |      2  3  5\n",
      " |      3  4  6\n",
      " |      \n",
      " |      >>> df.add_prefix('col_')\n",
      " |           col_A  col_B\n",
      " |      0       1       3\n",
      " |      1       2       4\n",
      " |      2       3       5\n",
      " |      3       4       6\n",
      " |  \n",
      " |  add_suffix(self: ~FrameOrSeries, suffix: str) -> ~FrameOrSeries\n",
      " |      Suffix labels with string `suffix`.\n",
      " |      \n",
      " |      For Series, the row labels are suffixed.\n",
      " |      For DataFrame, the column labels are suffixed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      suffix : str\n",
      " |          The string to add after each label.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          New Series or DataFrame with updated labels.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.add_prefix: Prefix row labels with string `prefix`.\n",
      " |      DataFrame.add_prefix: Prefix column labels with string `prefix`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.add_suffix('_item')\n",
      " |      0_item    1\n",
      " |      1_item    2\n",
      " |      2_item    3\n",
      " |      3_item    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3, 4], 'B': [3, 4, 5, 6]})\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  1  3\n",
      " |      1  2  4\n",
      " |      2  3  5\n",
      " |      3  4  6\n",
      " |      \n",
      " |      >>> df.add_suffix('_col')\n",
      " |           A_col  B_col\n",
      " |      0       1       3\n",
      " |      1       2       4\n",
      " |      2       3       5\n",
      " |      3       4       6\n",
      " |  \n",
      " |  asfreq(self: ~FrameOrSeries, freq, method=None, how: Union[str, NoneType] = None, normalize: bool = False, fill_value=None) -> ~FrameOrSeries\n",
      " |      Convert TimeSeries to specified frequency.\n",
      " |      \n",
      " |      Optionally provide filling method to pad/backfill missing values.\n",
      " |      \n",
      " |      Returns the original data conformed to a new index with the specified\n",
      " |      frequency. ``resample`` is more appropriate if an operation, such as\n",
      " |      summarization, is necessary to represent the data at the new frequency.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : DateOffset or str\n",
      " |      method : {'backfill'/'bfill', 'pad'/'ffill'}, default None\n",
      " |          Method to use for filling holes in reindexed Series (note this\n",
      " |          does not fill NaNs that already were present):\n",
      " |      \n",
      " |          * 'pad' / 'ffill': propagate last valid observation forward to next\n",
      " |            valid\n",
      " |          * 'backfill' / 'bfill': use NEXT valid observation to fill.\n",
      " |      how : {'start', 'end'}, default end\n",
      " |          For PeriodIndex only (see PeriodIndex.asfreq).\n",
      " |      normalize : bool, default False\n",
      " |          Whether to reset output index to midnight.\n",
      " |      fill_value : scalar, optional\n",
      " |          Value to use for missing values, applied during upsampling (note\n",
      " |          this does not fill NaNs that already were present).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      converted : same type as caller\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      reindex\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      To learn more about the frequency strings, please see `this link\n",
      " |      <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases>`__.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Start by creating a series with 4 one minute timestamps.\n",
      " |      \n",
      " |      >>> index = pd.date_range('1/1/2000', periods=4, freq='T')\n",
      " |      >>> series = pd.Series([0.0, None, 2.0, 3.0], index=index)\n",
      " |      >>> df = pd.DataFrame({'s':series})\n",
      " |      >>> df\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      Upsample the series into 30 second bins.\n",
      " |      \n",
      " |      >>> df.asfreq(freq='30S')\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    NaN\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    NaN\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    NaN\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      Upsample again, providing a ``fill value``.\n",
      " |      \n",
      " |      >>> df.asfreq(freq='30S', fill_value=9.0)\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    9.0\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    9.0\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    9.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |      \n",
      " |      Upsample again, providing a ``method``.\n",
      " |      \n",
      " |      >>> df.asfreq(freq='30S', method='bfill')\n",
      " |                             s\n",
      " |      2000-01-01 00:00:00    0.0\n",
      " |      2000-01-01 00:00:30    NaN\n",
      " |      2000-01-01 00:01:00    NaN\n",
      " |      2000-01-01 00:01:30    2.0\n",
      " |      2000-01-01 00:02:00    2.0\n",
      " |      2000-01-01 00:02:30    3.0\n",
      " |      2000-01-01 00:03:00    3.0\n",
      " |  \n",
      " |  asof(self, where, subset=None)\n",
      " |      Return the last row(s) without any NaNs before `where`.\n",
      " |      \n",
      " |      The last row (for each element in `where`, if list) without any\n",
      " |      NaN is taken.\n",
      " |      In case of a :class:`~pandas.DataFrame`, the last row without NaN\n",
      " |      considering only the subset of columns (if not `None`)\n",
      " |      \n",
      " |      If there is no good value, NaN is returned for a Series or\n",
      " |      a Series of NaN values for a DataFrame\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      where : date or array-like of dates\n",
      " |          Date(s) before which the last row(s) are returned.\n",
      " |      subset : str or array-like of str, default `None`\n",
      " |          For DataFrame, if not `None`, only use these columns to\n",
      " |          check for NaNs.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar, Series, or DataFrame\n",
      " |      \n",
      " |          The return can be:\n",
      " |      \n",
      " |          * scalar : when `self` is a Series and `where` is a scalar\n",
      " |          * Series: when `self` is a Series and `where` is an array-like,\n",
      " |            or when `self` is a DataFrame and `where` is a scalar\n",
      " |          * DataFrame : when `self` is a DataFrame and `where` is an\n",
      " |            array-like\n",
      " |      \n",
      " |          Return scalar, Series, or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      merge_asof : Perform an asof merge. Similar to left join.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Dates are assumed to be sorted. Raises if this is not the case.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      A Series and a scalar `where`.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, np.nan, 4], index=[10, 20, 30, 40])\n",
      " |      >>> s\n",
      " |      10    1.0\n",
      " |      20    2.0\n",
      " |      30    NaN\n",
      " |      40    4.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.asof(20)\n",
      " |      2.0\n",
      " |      \n",
      " |      For a sequence `where`, a Series is returned. The first value is\n",
      " |      NaN, because the first element of `where` is before the first\n",
      " |      index value.\n",
      " |      \n",
      " |      >>> s.asof([5, 20])\n",
      " |      5     NaN\n",
      " |      20    2.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Missing values are not considered. The following is ``2.0``, not\n",
      " |      NaN, even though NaN is at the index location for ``30``.\n",
      " |      \n",
      " |      >>> s.asof(30)\n",
      " |      2.0\n",
      " |      \n",
      " |      Take all columns into consideration\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'a': [10, 20, 30, 40, 50],\n",
      " |      ...                    'b': [None, None, None, None, 500]},\n",
      " |      ...                   index=pd.DatetimeIndex(['2018-02-27 09:01:00',\n",
      " |      ...                                           '2018-02-27 09:02:00',\n",
      " |      ...                                           '2018-02-27 09:03:00',\n",
      " |      ...                                           '2018-02-27 09:04:00',\n",
      " |      ...                                           '2018-02-27 09:05:00']))\n",
      " |      >>> df.asof(pd.DatetimeIndex(['2018-02-27 09:03:30',\n",
      " |      ...                           '2018-02-27 09:04:30']))\n",
      " |                            a   b\n",
      " |      2018-02-27 09:03:30 NaN NaN\n",
      " |      2018-02-27 09:04:30 NaN NaN\n",
      " |      \n",
      " |      Take a single column into consideration\n",
      " |      \n",
      " |      >>> df.asof(pd.DatetimeIndex(['2018-02-27 09:03:30',\n",
      " |      ...                           '2018-02-27 09:04:30']),\n",
      " |      ...         subset=['a'])\n",
      " |                               a   b\n",
      " |      2018-02-27 09:03:30   30.0 NaN\n",
      " |      2018-02-27 09:04:30   40.0 NaN\n",
      " |  \n",
      " |  astype(self: ~FrameOrSeries, dtype, copy: bool = True, errors: str = 'raise') -> ~FrameOrSeries\n",
      " |      Cast a pandas object to a specified dtype ``dtype``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : data type, or dict of column name -> data type\n",
      " |          Use a numpy.dtype or Python type to cast entire pandas object to\n",
      " |          the same type. Alternatively, use {col: dtype, ...}, where col is a\n",
      " |          column label and dtype is a numpy.dtype or Python type to cast one\n",
      " |          or more of the DataFrame's columns to column-specific types.\n",
      " |      copy : bool, default True\n",
      " |          Return a copy when ``copy=True`` (be very careful setting\n",
      " |          ``copy=False`` as changes to values then may propagate to other\n",
      " |          pandas objects).\n",
      " |      errors : {'raise', 'ignore'}, default 'raise'\n",
      " |          Control raising of exceptions on invalid data for provided dtype.\n",
      " |      \n",
      " |          - ``raise`` : allow exceptions to be raised\n",
      " |          - ``ignore`` : suppress exceptions. On error return original object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      casted : same type as caller\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_datetime : Convert argument to datetime.\n",
      " |      to_timedelta : Convert argument to timedelta.\n",
      " |      to_numeric : Convert argument to a numeric type.\n",
      " |      numpy.ndarray.astype : Cast a numpy array to a specified type.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Create a DataFrame:\n",
      " |      \n",
      " |      >>> d = {'col1': [1, 2], 'col2': [3, 4]}\n",
      " |      >>> df = pd.DataFrame(data=d)\n",
      " |      >>> df.dtypes\n",
      " |      col1    int64\n",
      " |      col2    int64\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Cast all columns to int32:\n",
      " |      \n",
      " |      >>> df.astype('int32').dtypes\n",
      " |      col1    int32\n",
      " |      col2    int32\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Cast col1 to int32 using a dictionary:\n",
      " |      \n",
      " |      >>> df.astype({'col1': 'int32'}).dtypes\n",
      " |      col1    int32\n",
      " |      col2    int64\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Create a series:\n",
      " |      \n",
      " |      >>> ser = pd.Series([1, 2], dtype='int32')\n",
      " |      >>> ser\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: int32\n",
      " |      >>> ser.astype('int64')\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Convert to categorical type:\n",
      " |      \n",
      " |      >>> ser.astype('category')\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: category\n",
      " |      Categories (2, int64): [1, 2]\n",
      " |      \n",
      " |      Convert to ordered categorical type with custom ordering:\n",
      " |      \n",
      " |      >>> cat_dtype = pd.api.types.CategoricalDtype(\n",
      " |      ...     categories=[2, 1], ordered=True)\n",
      " |      >>> ser.astype(cat_dtype)\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      dtype: category\n",
      " |      Categories (2, int64): [2 < 1]\n",
      " |      \n",
      " |      Note that using ``copy=False`` and changing data on a new\n",
      " |      pandas object may propagate changes:\n",
      " |      \n",
      " |      >>> s1 = pd.Series([1, 2])\n",
      " |      >>> s2 = s1.astype('int64', copy=False)\n",
      " |      >>> s2[0] = 10\n",
      " |      >>> s1  # note that s1[0] has changed too\n",
      " |      0    10\n",
      " |      1     2\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  at_time(self: ~FrameOrSeries, time, asof: bool = False, axis=None) -> ~FrameOrSeries\n",
      " |      Select values at particular time of day (e.g. 9:30AM).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      time : datetime.time or str\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |      \n",
      " |          .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      between_time : Select values between particular times of the day.\n",
      " |      first : Select initial periods of time series based on a date offset.\n",
      " |      last : Select final periods of time series based on a date offset.\n",
      " |      DatetimeIndex.indexer_at_time : Get just the index locations for\n",
      " |          values at particular time of the day.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='12H')\n",
      " |      >>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n",
      " |      >>> ts\n",
      " |                           A\n",
      " |      2018-04-09 00:00:00  1\n",
      " |      2018-04-09 12:00:00  2\n",
      " |      2018-04-10 00:00:00  3\n",
      " |      2018-04-10 12:00:00  4\n",
      " |      \n",
      " |      >>> ts.at_time('12:00')\n",
      " |                           A\n",
      " |      2018-04-09 12:00:00  2\n",
      " |      2018-04-10 12:00:00  4\n",
      " |  \n",
      " |  between_time(self: ~FrameOrSeries, start_time, end_time, include_start: bool = True, include_end: bool = True, axis=None) -> ~FrameOrSeries\n",
      " |      Select values between particular times of the day (e.g., 9:00-9:30 AM).\n",
      " |      \n",
      " |      By setting ``start_time`` to be later than ``end_time``,\n",
      " |      you can get the times that are *not* between the two times.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      start_time : datetime.time or str\n",
      " |      end_time : datetime.time or str\n",
      " |      include_start : bool, default True\n",
      " |      include_end : bool, default True\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |      \n",
      " |          .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      at_time : Select values at a particular time of the day.\n",
      " |      first : Select initial periods of time series based on a date offset.\n",
      " |      last : Select final periods of time series based on a date offset.\n",
      " |      DatetimeIndex.indexer_between_time : Get just the index locations for\n",
      " |          values between particular times of the day.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='1D20min')\n",
      " |      >>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n",
      " |      >>> ts\n",
      " |                           A\n",
      " |      2018-04-09 00:00:00  1\n",
      " |      2018-04-10 00:20:00  2\n",
      " |      2018-04-11 00:40:00  3\n",
      " |      2018-04-12 01:00:00  4\n",
      " |      \n",
      " |      >>> ts.between_time('0:15', '0:45')\n",
      " |                           A\n",
      " |      2018-04-10 00:20:00  2\n",
      " |      2018-04-11 00:40:00  3\n",
      " |      \n",
      " |      You get the times that are *not* between two times by setting\n",
      " |      ``start_time`` later than ``end_time``:\n",
      " |      \n",
      " |      >>> ts.between_time('0:45', '0:15')\n",
      " |                           A\n",
      " |      2018-04-09 00:00:00  1\n",
      " |      2018-04-12 01:00:00  4\n",
      " |  \n",
      " |  bfill(self: ~FrameOrSeries, axis=None, inplace: bool = False, limit=None, downcast=None) -> Union[~FrameOrSeries, NoneType]\n",
      " |      Synonym for :meth:`DataFrame.fillna` with ``method='bfill'``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      %(klass)s or None\n",
      " |          Object with missing values filled or None if ``inplace=True``.\n",
      " |  \n",
      " |  bool(self)\n",
      " |      Return the bool of a single element PandasObject.\n",
      " |      \n",
      " |      This must be a boolean scalar value, either True or False.  Raise a\n",
      " |      ValueError if the PandasObject does not have exactly 1 element, or that\n",
      " |      element is not boolean\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          Same single boolean value converted to bool type.\n",
      " |  \n",
      " |  clip(self: ~FrameOrSeries, lower=None, upper=None, axis=None, inplace: bool = False, *args, **kwargs) -> ~FrameOrSeries\n",
      " |      Trim values at input threshold(s).\n",
      " |      \n",
      " |      Assigns values outside boundary to boundary values. Thresholds\n",
      " |      can be singular values or array like, and in the latter case\n",
      " |      the clipping is performed element-wise in the specified axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      lower : float or array_like, default None\n",
      " |          Minimum threshold value. All values below this\n",
      " |          threshold will be set to it.\n",
      " |      upper : float or array_like, default None\n",
      " |          Maximum threshold value. All values above this\n",
      " |          threshold will be set to it.\n",
      " |      axis : int or str axis name, optional\n",
      " |          Align object with lower and upper along the given axis.\n",
      " |      inplace : bool, default False\n",
      " |          Whether to perform the operation in place on the data.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0\n",
      " |      *args, **kwargs\n",
      " |          Additional keywords have no effect but might be accepted\n",
      " |          for compatibility with numpy.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Same type as calling object with the values outside the\n",
      " |          clip boundaries replaced.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> data = {'col_0': [9, -3, 0, -1, 5], 'col_1': [-2, -7, 6, 8, -5]}\n",
      " |      >>> df = pd.DataFrame(data)\n",
      " |      >>> df\n",
      " |         col_0  col_1\n",
      " |      0      9     -2\n",
      " |      1     -3     -7\n",
      " |      2      0      6\n",
      " |      3     -1      8\n",
      " |      4      5     -5\n",
      " |      \n",
      " |      Clips per column using lower and upper thresholds:\n",
      " |      \n",
      " |      >>> df.clip(-4, 6)\n",
      " |         col_0  col_1\n",
      " |      0      6     -2\n",
      " |      1     -3     -4\n",
      " |      2      0      6\n",
      " |      3     -1      6\n",
      " |      4      5     -4\n",
      " |      \n",
      " |      Clips using specific lower and upper thresholds per column element:\n",
      " |      \n",
      " |      >>> t = pd.Series([2, -4, -1, 6, 3])\n",
      " |      >>> t\n",
      " |      0    2\n",
      " |      1   -4\n",
      " |      2   -1\n",
      " |      3    6\n",
      " |      4    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df.clip(t, t + 4, axis=0)\n",
      " |         col_0  col_1\n",
      " |      0      6      2\n",
      " |      1     -3     -4\n",
      " |      2      0      3\n",
      " |      3      6      8\n",
      " |      4      5      3\n",
      " |  \n",
      " |  convert_dtypes(self: ~FrameOrSeries, infer_objects: bool = True, convert_string: bool = True, convert_integer: bool = True, convert_boolean: bool = True) -> ~FrameOrSeries\n",
      " |      Convert columns to best possible dtypes using dtypes supporting ``pd.NA``.\n",
      " |      \n",
      " |      .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      infer_objects : bool, default True\n",
      " |          Whether object dtypes should be converted to the best possible types.\n",
      " |      convert_string : bool, default True\n",
      " |          Whether object dtypes should be converted to ``StringDtype()``.\n",
      " |      convert_integer : bool, default True\n",
      " |          Whether, if possible, conversion can be done to integer extension types.\n",
      " |      convert_boolean : bool, defaults True\n",
      " |          Whether object dtypes should be converted to ``BooleanDtypes()``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Copy of input object with new dtype.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      infer_objects : Infer dtypes of objects.\n",
      " |      to_datetime : Convert argument to datetime.\n",
      " |      to_timedelta : Convert argument to timedelta.\n",
      " |      to_numeric : Convert argument to a numeric type.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      \n",
      " |      By default, ``convert_dtypes`` will attempt to convert a Series (or each\n",
      " |      Series in a DataFrame) to dtypes that support ``pd.NA``. By using the options\n",
      " |      ``convert_string``, ``convert_integer``, and ``convert_boolean``, it is\n",
      " |      possible to turn off individual conversions to ``StringDtype``, the integer\n",
      " |      extension types or ``BooleanDtype``, respectively.\n",
      " |      \n",
      " |      For object-dtyped columns, if ``infer_objects`` is ``True``, use the inference\n",
      " |      rules as during normal Series/DataFrame construction.  Then, if possible,\n",
      " |      convert to ``StringDtype``, ``BooleanDtype`` or an appropriate integer extension\n",
      " |      type, otherwise leave as ``object``.\n",
      " |      \n",
      " |      If the dtype is integer, convert to an appropriate integer extension type.\n",
      " |      \n",
      " |      If the dtype is numeric, and consists of all integers, convert to an\n",
      " |      appropriate integer extension type.\n",
      " |      \n",
      " |      In the future, as new dtypes are added that support ``pd.NA``, the results\n",
      " |      of this method will change to support those new dtypes.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(\n",
      " |      ...     {\n",
      " |      ...         \"a\": pd.Series([1, 2, 3], dtype=np.dtype(\"int32\")),\n",
      " |      ...         \"b\": pd.Series([\"x\", \"y\", \"z\"], dtype=np.dtype(\"O\")),\n",
      " |      ...         \"c\": pd.Series([True, False, np.nan], dtype=np.dtype(\"O\")),\n",
      " |      ...         \"d\": pd.Series([\"h\", \"i\", np.nan], dtype=np.dtype(\"O\")),\n",
      " |      ...         \"e\": pd.Series([10, np.nan, 20], dtype=np.dtype(\"float\")),\n",
      " |      ...         \"f\": pd.Series([np.nan, 100.5, 200], dtype=np.dtype(\"float\")),\n",
      " |      ...     }\n",
      " |      ... )\n",
      " |      \n",
      " |      Start with a DataFrame with default dtypes.\n",
      " |      \n",
      " |      >>> df\n",
      " |         a  b      c    d     e      f\n",
      " |      0  1  x   True    h  10.0    NaN\n",
      " |      1  2  y  False    i   NaN  100.5\n",
      " |      2  3  z    NaN  NaN  20.0  200.0\n",
      " |      \n",
      " |      >>> df.dtypes\n",
      " |      a      int32\n",
      " |      b     object\n",
      " |      c     object\n",
      " |      d     object\n",
      " |      e    float64\n",
      " |      f    float64\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Convert the DataFrame to use best possible dtypes.\n",
      " |      \n",
      " |      >>> dfn = df.convert_dtypes()\n",
      " |      >>> dfn\n",
      " |         a  b      c     d     e      f\n",
      " |      0  1  x   True     h    10    NaN\n",
      " |      1  2  y  False     i  <NA>  100.5\n",
      " |      2  3  z   <NA>  <NA>    20  200.0\n",
      " |      \n",
      " |      >>> dfn.dtypes\n",
      " |      a      Int32\n",
      " |      b     string\n",
      " |      c    boolean\n",
      " |      d     string\n",
      " |      e      Int64\n",
      " |      f    float64\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Start with a Series of strings and missing data represented by ``np.nan``.\n",
      " |      \n",
      " |      >>> s = pd.Series([\"a\", \"b\", np.nan])\n",
      " |      >>> s\n",
      " |      0      a\n",
      " |      1      b\n",
      " |      2    NaN\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Obtain a Series with dtype ``StringDtype``.\n",
      " |      \n",
      " |      >>> s.convert_dtypes()\n",
      " |      0       a\n",
      " |      1       b\n",
      " |      2    <NA>\n",
      " |      dtype: string\n",
      " |  \n",
      " |  copy(self: ~FrameOrSeries, deep: bool = True) -> ~FrameOrSeries\n",
      " |      Make a copy of this object's indices and data.\n",
      " |      \n",
      " |      When ``deep=True`` (default), a new object will be created with a\n",
      " |      copy of the calling object's data and indices. Modifications to\n",
      " |      the data or indices of the copy will not be reflected in the\n",
      " |      original object (see notes below).\n",
      " |      \n",
      " |      When ``deep=False``, a new object will be created without copying\n",
      " |      the calling object's data or index (only references to the data\n",
      " |      and index are copied). Any changes to the data of the original\n",
      " |      will be reflected in the shallow copy (and vice versa).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default True\n",
      " |          Make a deep copy, including a copy of the data and the indices.\n",
      " |          With ``deep=False`` neither the indices nor the data are copied.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      copy : Series or DataFrame\n",
      " |          Object type matches caller.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      When ``deep=True``, data is copied but actual Python objects\n",
      " |      will not be copied recursively, only the reference to the object.\n",
      " |      This is in contrast to `copy.deepcopy` in the Standard Library,\n",
      " |      which recursively copies object data (see examples below).\n",
      " |      \n",
      " |      While ``Index`` objects are copied when ``deep=True``, the underlying\n",
      " |      numpy array is not copied for performance reasons. Since ``Index`` is\n",
      " |      immutable, the underlying data can be safely shared and a copy\n",
      " |      is not needed.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2], index=[\"a\", \"b\"])\n",
      " |      >>> s\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s_copy = s.copy()\n",
      " |      >>> s_copy\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      **Shallow copy versus default (deep) copy:**\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2], index=[\"a\", \"b\"])\n",
      " |      >>> deep = s.copy()\n",
      " |      >>> shallow = s.copy(deep=False)\n",
      " |      \n",
      " |      Shallow copy shares data and index with original.\n",
      " |      \n",
      " |      >>> s is shallow\n",
      " |      False\n",
      " |      >>> s.values is shallow.values and s.index is shallow.index\n",
      " |      True\n",
      " |      \n",
      " |      Deep copy has own copy of data and index.\n",
      " |      \n",
      " |      >>> s is deep\n",
      " |      False\n",
      " |      >>> s.values is deep.values or s.index is deep.index\n",
      " |      False\n",
      " |      \n",
      " |      Updates to the data shared by shallow copy and original is reflected\n",
      " |      in both; deep copy remains unchanged.\n",
      " |      \n",
      " |      >>> s[0] = 3\n",
      " |      >>> shallow[1] = 4\n",
      " |      >>> s\n",
      " |      a    3\n",
      " |      b    4\n",
      " |      dtype: int64\n",
      " |      >>> shallow\n",
      " |      a    3\n",
      " |      b    4\n",
      " |      dtype: int64\n",
      " |      >>> deep\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Note that when copying an object containing Python objects, a deep copy\n",
      " |      will copy the data, but will not do so recursively. Updating a nested\n",
      " |      data object will be reflected in the deep copy.\n",
      " |      \n",
      " |      >>> s = pd.Series([[1, 2], [3, 4]])\n",
      " |      >>> deep = s.copy()\n",
      " |      >>> s[0][0] = 10\n",
      " |      >>> s\n",
      " |      0    [10, 2]\n",
      " |      1     [3, 4]\n",
      " |      dtype: object\n",
      " |      >>> deep\n",
      " |      0    [10, 2]\n",
      " |      1     [3, 4]\n",
      " |      dtype: object\n",
      " |  \n",
      " |  describe(self: ~FrameOrSeries, percentiles=None, include=None, exclude=None) -> ~FrameOrSeries\n",
      " |      Generate descriptive statistics.\n",
      " |      \n",
      " |      Descriptive statistics include those that summarize the central\n",
      " |      tendency, dispersion and shape of a\n",
      " |      dataset's distribution, excluding ``NaN`` values.\n",
      " |      \n",
      " |      Analyzes both numeric and object series, as well\n",
      " |      as ``DataFrame`` column sets of mixed data types. The output\n",
      " |      will vary depending on what is provided. Refer to the notes\n",
      " |      below for more detail.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      percentiles : list-like of numbers, optional\n",
      " |          The percentiles to include in the output. All should\n",
      " |          fall between 0 and 1. The default is\n",
      " |          ``[.25, .5, .75]``, which returns the 25th, 50th, and\n",
      " |          75th percentiles.\n",
      " |      include : 'all', list-like of dtypes or None (default), optional\n",
      " |          A white list of data types to include in the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |      \n",
      " |          - 'all' : All columns of the input will be included in the output.\n",
      " |          - A list-like of dtypes : Limits the results to the\n",
      " |            provided data types.\n",
      " |            To limit the result to numeric types submit\n",
      " |            ``numpy.number``. To limit it instead to object columns submit\n",
      " |            the ``numpy.object`` data type. Strings\n",
      " |            can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      " |            select pandas categorical columns, use ``'category'``\n",
      " |          - None (default) : The result will include all numeric columns.\n",
      " |      exclude : list-like of dtypes or None (default), optional,\n",
      " |          A black list of data types to omit from the result. Ignored\n",
      " |          for ``Series``. Here are the options:\n",
      " |      \n",
      " |          - A list-like of dtypes : Excludes the provided data types\n",
      " |            from the result. To exclude numeric types submit\n",
      " |            ``numpy.number``. To exclude object columns submit the data\n",
      " |            type ``numpy.object``. Strings can also be used in the style of\n",
      " |            ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
      " |            exclude pandas categorical columns, use ``'category'``\n",
      " |          - None (default) : The result will exclude nothing.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Summary statistics of the Series or Dataframe provided.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.count: Count number of non-NA/null observations.\n",
      " |      DataFrame.max: Maximum of the values in the object.\n",
      " |      DataFrame.min: Minimum of the values in the object.\n",
      " |      DataFrame.mean: Mean of the values.\n",
      " |      DataFrame.std: Standard deviation of the observations.\n",
      " |      DataFrame.select_dtypes: Subset of a DataFrame including/excluding\n",
      " |          columns based on their dtype.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For numeric data, the result's index will include ``count``,\n",
      " |      ``mean``, ``std``, ``min``, ``max`` as well as lower, ``50`` and\n",
      " |      upper percentiles. By default the lower percentile is ``25`` and the\n",
      " |      upper percentile is ``75``. The ``50`` percentile is the\n",
      " |      same as the median.\n",
      " |      \n",
      " |      For object data (e.g. strings or timestamps), the result's index\n",
      " |      will include ``count``, ``unique``, ``top``, and ``freq``. The ``top``\n",
      " |      is the most common value. The ``freq`` is the most common value's\n",
      " |      frequency. Timestamps also include the ``first`` and ``last`` items.\n",
      " |      \n",
      " |      If multiple object values have the highest count, then the\n",
      " |      ``count`` and ``top`` results will be arbitrarily chosen from\n",
      " |      among those with the highest count.\n",
      " |      \n",
      " |      For mixed data types provided via a ``DataFrame``, the default is to\n",
      " |      return only an analysis of numeric columns. If the dataframe consists\n",
      " |      only of object and categorical data without any numeric columns, the\n",
      " |      default is to return an analysis of both the object and categorical\n",
      " |      columns. If ``include='all'`` is provided as an option, the result\n",
      " |      will include a union of attributes of each type.\n",
      " |      \n",
      " |      The `include` and `exclude` parameters can be used to limit\n",
      " |      which columns in a ``DataFrame`` are analyzed for the output.\n",
      " |      The parameters are ignored when analyzing a ``Series``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Describing a numeric ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Describing a categorical ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series(['a', 'a', 'b', 'c'])\n",
      " |      >>> s.describe()\n",
      " |      count     4\n",
      " |      unique    3\n",
      " |      top       a\n",
      " |      freq      2\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Describing a timestamp ``Series``.\n",
      " |      \n",
      " |      >>> s = pd.Series([\n",
      " |      ...   np.datetime64(\"2000-01-01\"),\n",
      " |      ...   np.datetime64(\"2010-01-01\"),\n",
      " |      ...   np.datetime64(\"2010-01-01\")\n",
      " |      ... ])\n",
      " |      >>> s.describe()\n",
      " |      count                       3\n",
      " |      unique                      2\n",
      " |      top       2010-01-01 00:00:00\n",
      " |      freq                        2\n",
      " |      first     2000-01-01 00:00:00\n",
      " |      last      2010-01-01 00:00:00\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Describing a ``DataFrame``. By default only numeric fields\n",
      " |      are returned.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'categorical': pd.Categorical(['d','e','f']),\n",
      " |      ...                    'numeric': [1, 2, 3],\n",
      " |      ...                    'object': ['a', 'b', 'c']\n",
      " |      ...                   })\n",
      " |      >>> df.describe()\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |      \n",
      " |      Describing all columns of a ``DataFrame`` regardless of data type.\n",
      " |      \n",
      " |      >>> df.describe(include='all')\n",
      " |              categorical  numeric object\n",
      " |      count            3      3.0      3\n",
      " |      unique           3      NaN      3\n",
      " |      top              f      NaN      c\n",
      " |      freq             1      NaN      1\n",
      " |      mean           NaN      2.0    NaN\n",
      " |      std            NaN      1.0    NaN\n",
      " |      min            NaN      1.0    NaN\n",
      " |      25%            NaN      1.5    NaN\n",
      " |      50%            NaN      2.0    NaN\n",
      " |      75%            NaN      2.5    NaN\n",
      " |      max            NaN      3.0    NaN\n",
      " |      \n",
      " |      Describing a column from a ``DataFrame`` by accessing it as\n",
      " |      an attribute.\n",
      " |      \n",
      " |      >>> df.numeric.describe()\n",
      " |      count    3.0\n",
      " |      mean     2.0\n",
      " |      std      1.0\n",
      " |      min      1.0\n",
      " |      25%      1.5\n",
      " |      50%      2.0\n",
      " |      75%      2.5\n",
      " |      max      3.0\n",
      " |      Name: numeric, dtype: float64\n",
      " |      \n",
      " |      Including only numeric columns in a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=[np.number])\n",
      " |             numeric\n",
      " |      count      3.0\n",
      " |      mean       2.0\n",
      " |      std        1.0\n",
      " |      min        1.0\n",
      " |      25%        1.5\n",
      " |      50%        2.0\n",
      " |      75%        2.5\n",
      " |      max        3.0\n",
      " |      \n",
      " |      Including only string columns in a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=[np.object])\n",
      " |             object\n",
      " |      count       3\n",
      " |      unique      3\n",
      " |      top         c\n",
      " |      freq        1\n",
      " |      \n",
      " |      Including only categorical columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(include=['category'])\n",
      " |             categorical\n",
      " |      count            3\n",
      " |      unique           3\n",
      " |      top              f\n",
      " |      freq             1\n",
      " |      \n",
      " |      Excluding numeric columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(exclude=[np.number])\n",
      " |             categorical object\n",
      " |      count            3      3\n",
      " |      unique           3      3\n",
      " |      top              f      c\n",
      " |      freq             1      1\n",
      " |      \n",
      " |      Excluding object columns from a ``DataFrame`` description.\n",
      " |      \n",
      " |      >>> df.describe(exclude=[np.object])\n",
      " |             categorical  numeric\n",
      " |      count            3      3.0\n",
      " |      unique           3      NaN\n",
      " |      top              f      NaN\n",
      " |      freq             1      NaN\n",
      " |      mean           NaN      2.0\n",
      " |      std            NaN      1.0\n",
      " |      min            NaN      1.0\n",
      " |      25%            NaN      1.5\n",
      " |      50%            NaN      2.0\n",
      " |      75%            NaN      2.5\n",
      " |      max            NaN      3.0\n",
      " |  \n",
      " |  droplevel(self: ~FrameOrSeries, level, axis=0) -> ~FrameOrSeries\n",
      " |      Return DataFrame with requested index / column level(s) removed.\n",
      " |      \n",
      " |      .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, str, or list-like\n",
      " |          If a string is given, must be the name of a level\n",
      " |          If list-like, elements must be names or positional indexes\n",
      " |          of levels.\n",
      " |      \n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          DataFrame with requested index / column level(s) removed.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([\n",
      " |      ...     [1, 2, 3, 4],\n",
      " |      ...     [5, 6, 7, 8],\n",
      " |      ...     [9, 10, 11, 12]\n",
      " |      ... ]).set_index([0, 1]).rename_axis(['a', 'b'])\n",
      " |      \n",
      " |      >>> df.columns = pd.MultiIndex.from_tuples([\n",
      " |      ...    ('c', 'e'), ('d', 'f')\n",
      " |      ... ], names=['level_1', 'level_2'])\n",
      " |      \n",
      " |      >>> df\n",
      " |      level_1   c   d\n",
      " |      level_2   e   f\n",
      " |      a b\n",
      " |      1 2      3   4\n",
      " |      5 6      7   8\n",
      " |      9 10    11  12\n",
      " |      \n",
      " |      >>> df.droplevel('a')\n",
      " |      level_1   c   d\n",
      " |      level_2   e   f\n",
      " |      b\n",
      " |      2        3   4\n",
      " |      6        7   8\n",
      " |      10      11  12\n",
      " |      \n",
      " |      >>> df.droplevel('level2', axis=1)\n",
      " |      level_1   c   d\n",
      " |      a b\n",
      " |      1 2      3   4\n",
      " |      5 6      7   8\n",
      " |      9 10    11  12\n",
      " |  \n",
      " |  equals(self, other)\n",
      " |      Test whether two objects contain the same elements.\n",
      " |      \n",
      " |      This function allows two Series or DataFrames to be compared against\n",
      " |      each other to see if they have the same shape and elements. NaNs in\n",
      " |      the same location are considered equal. The column headers do not\n",
      " |      need to have the same type, but the elements within the columns must\n",
      " |      be the same dtype.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series or DataFrame\n",
      " |          The other Series or DataFrame to be compared with the first.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          True if all elements are the same in both objects, False\n",
      " |          otherwise.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.eq : Compare two Series objects of the same length\n",
      " |          and return a Series where each element is True if the element\n",
      " |          in each Series is equal, False otherwise.\n",
      " |      DataFrame.eq : Compare two DataFrame objects of the same shape and\n",
      " |          return a DataFrame where each element is True if the respective\n",
      " |          element in each DataFrame is equal, False otherwise.\n",
      " |      testing.assert_series_equal : Raises an AssertionError if left and\n",
      " |          right are not equal. Provides an easy interface to ignore\n",
      " |          inequality in dtypes, indexes and precision among others.\n",
      " |      testing.assert_frame_equal : Like assert_series_equal, but targets\n",
      " |          DataFrames.\n",
      " |      numpy.array_equal : Return True if two arrays have the same shape\n",
      " |          and elements, False otherwise.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This function requires that the elements have the same dtype as their\n",
      " |      respective elements in the other Series or DataFrame. However, the\n",
      " |      column labels do not need to have the same type, as long as they are\n",
      " |      still considered equal.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({1: [10], 2: [20]})\n",
      " |      >>> df\n",
      " |          1   2\n",
      " |      0  10  20\n",
      " |      \n",
      " |      DataFrames df and exactly_equal have the same types and values for\n",
      " |      their elements and column labels, which will return True.\n",
      " |      \n",
      " |      >>> exactly_equal = pd.DataFrame({1: [10], 2: [20]})\n",
      " |      >>> exactly_equal\n",
      " |          1   2\n",
      " |      0  10  20\n",
      " |      >>> df.equals(exactly_equal)\n",
      " |      True\n",
      " |      \n",
      " |      DataFrames df and different_column_type have the same element\n",
      " |      types and values, but have different types for the column labels,\n",
      " |      which will still return True.\n",
      " |      \n",
      " |      >>> different_column_type = pd.DataFrame({1.0: [10], 2.0: [20]})\n",
      " |      >>> different_column_type\n",
      " |         1.0  2.0\n",
      " |      0   10   20\n",
      " |      >>> df.equals(different_column_type)\n",
      " |      True\n",
      " |      \n",
      " |      DataFrames df and different_data_type have different types for the\n",
      " |      same values for their elements, and will return False even though\n",
      " |      their column labels are the same values and types.\n",
      " |      \n",
      " |      >>> different_data_type = pd.DataFrame({1: [10.0], 2: [20.0]})\n",
      " |      >>> different_data_type\n",
      " |            1     2\n",
      " |      0  10.0  20.0\n",
      " |      >>> df.equals(different_data_type)\n",
      " |      False\n",
      " |  \n",
      " |  ffill(self: ~FrameOrSeries, axis=None, inplace: bool = False, limit=None, downcast=None) -> Union[~FrameOrSeries, NoneType]\n",
      " |      Synonym for :meth:`DataFrame.fillna` with ``method='ffill'``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      %(klass)s or None\n",
      " |          Object with missing values filled or None if ``inplace=True``.\n",
      " |  \n",
      " |  filter(self: ~FrameOrSeries, items=None, like: Union[str, NoneType] = None, regex: Union[str, NoneType] = None, axis=None) -> ~FrameOrSeries\n",
      " |      Subset the dataframe rows or columns according to the specified index labels.\n",
      " |      \n",
      " |      Note that this routine does not filter a dataframe on its\n",
      " |      contents. The filter is applied to the labels of the index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      items : list-like\n",
      " |          Keep labels from axis which are in items.\n",
      " |      like : str\n",
      " |          Keep labels from axis for which \"like in label == True\".\n",
      " |      regex : str (regular expression)\n",
      " |          Keep labels from axis for which re.search(regex, label) == True.\n",
      " |      axis : {0 or ‘index’, 1 or ‘columns’, None}, default None\n",
      " |          The axis to filter on, expressed either as an index (int)\n",
      " |          or axis name (str). By default this is the info axis,\n",
      " |          'index' for Series, 'columns' for DataFrame.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as input object\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The ``items``, ``like``, and ``regex`` parameters are\n",
      " |      enforced to be mutually exclusive.\n",
      " |      \n",
      " |      ``axis`` defaults to the info axis that is used when indexing\n",
      " |      with ``[]``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame(np.array(([1, 2, 3], [4, 5, 6])),\n",
      " |      ...                   index=['mouse', 'rabbit'],\n",
      " |      ...                   columns=['one', 'two', 'three'])\n",
      " |      \n",
      " |      >>> # select columns by name\n",
      " |      >>> df.filter(items=['one', 'three'])\n",
      " |               one  three\n",
      " |      mouse     1      3\n",
      " |      rabbit    4      6\n",
      " |      \n",
      " |      >>> # select columns by regular expression\n",
      " |      >>> df.filter(regex='e$', axis=1)\n",
      " |               one  three\n",
      " |      mouse     1      3\n",
      " |      rabbit    4      6\n",
      " |      \n",
      " |      >>> # select rows containing 'bbi'\n",
      " |      >>> df.filter(like='bbi', axis=0)\n",
      " |               one  two  three\n",
      " |      rabbit    4    5      6\n",
      " |  \n",
      " |  first(self: ~FrameOrSeries, offset) -> ~FrameOrSeries\n",
      " |      Method to subset initial periods of time series data based on a date offset.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      offset : str, DateOffset, dateutil.relativedelta\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      subset : same type as caller\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      last : Select final periods of time series based on a date offset.\n",
      " |      at_time : Select values at a particular time of the day.\n",
      " |      between_time : Select values between particular times of the day.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='2D')\n",
      " |      >>> ts = pd.DataFrame({'A': [1,2,3,4]}, index=i)\n",
      " |      >>> ts\n",
      " |                  A\n",
      " |      2018-04-09  1\n",
      " |      2018-04-11  2\n",
      " |      2018-04-13  3\n",
      " |      2018-04-15  4\n",
      " |      \n",
      " |      Get the rows for the first 3 days:\n",
      " |      \n",
      " |      >>> ts.first('3D')\n",
      " |                  A\n",
      " |      2018-04-09  1\n",
      " |      2018-04-11  2\n",
      " |      \n",
      " |      Notice the data for 3 first calender days were returned, not the first\n",
      " |      3 days observed in the dataset, and therefore data for 2018-04-13 was\n",
      " |      not returned.\n",
      " |  \n",
      " |  first_valid_index(self)\n",
      " |      Return index for first non-NA/null value.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar : type of index\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If all elements are non-NA/null, returns None.\n",
      " |      Also returns None for empty Series/DataFrame.\n",
      " |  \n",
      " |  get(self, key, default=None)\n",
      " |      Get item from object for given key (ex: DataFrame column).\n",
      " |      \n",
      " |      Returns default value if not found.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : object\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      value : same type as items contained in object\n",
      " |  \n",
      " |  head(self: ~FrameOrSeries, n: int = 5) -> ~FrameOrSeries\n",
      " |      Return the first `n` rows.\n",
      " |      \n",
      " |      This function returns the first `n` rows for the object based\n",
      " |      on position. It is useful for quickly testing if your object\n",
      " |      has the right type of data in it.\n",
      " |      \n",
      " |      For negative values of `n`, this function returns all rows except\n",
      " |      the last `n` rows, equivalent to ``df[:-n]``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, default 5\n",
      " |          Number of rows to select.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as caller\n",
      " |          The first `n` rows of the caller object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.tail: Returns the last `n` rows.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',\n",
      " |      ...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n",
      " |      >>> df\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      5     parrot\n",
      " |      6      shark\n",
      " |      7      whale\n",
      " |      8      zebra\n",
      " |      \n",
      " |      Viewing the first 5 lines\n",
      " |      \n",
      " |      >>> df.head()\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      \n",
      " |      Viewing the first `n` lines (three in this case)\n",
      " |      \n",
      " |      >>> df.head(3)\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      \n",
      " |      For negative values of `n`\n",
      " |      \n",
      " |      >>> df.head(-3)\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      5     parrot\n",
      " |  \n",
      " |  infer_objects(self: ~FrameOrSeries) -> ~FrameOrSeries\n",
      " |      Attempt to infer better dtypes for object columns.\n",
      " |      \n",
      " |      Attempts soft conversion of object-dtyped\n",
      " |      columns, leaving non-object and unconvertible\n",
      " |      columns unchanged. The inference rules are the\n",
      " |      same as during normal Series/DataFrame construction.\n",
      " |      \n",
      " |      .. versionadded:: 0.21.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      converted : same type as input object\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_datetime : Convert argument to datetime.\n",
      " |      to_timedelta : Convert argument to timedelta.\n",
      " |      to_numeric : Convert argument to numeric type.\n",
      " |      convert_dtypes : Convert argument to best possible dtype.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({\"A\": [\"a\", 1, 2, 3]})\n",
      " |      >>> df = df.iloc[1:]\n",
      " |      >>> df\n",
      " |         A\n",
      " |      1  1\n",
      " |      2  2\n",
      " |      3  3\n",
      " |      \n",
      " |      >>> df.dtypes\n",
      " |      A    object\n",
      " |      dtype: object\n",
      " |      \n",
      " |      >>> df.infer_objects().dtypes\n",
      " |      A    int64\n",
      " |      dtype: object\n",
      " |  \n",
      " |  interpolate(self, method='linear', axis=0, limit=None, inplace=False, limit_direction='forward', limit_area=None, downcast=None, **kwargs)\n",
      " |      Interpolate values according to different methods.\n",
      " |      \n",
      " |      Please note that only ``method='linear'`` is supported for\n",
      " |      DataFrame/Series with a MultiIndex.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : str, default 'linear'\n",
      " |          Interpolation technique to use. One of:\n",
      " |      \n",
      " |          * 'linear': Ignore the index and treat the values as equally\n",
      " |            spaced. This is the only method supported on MultiIndexes.\n",
      " |          * 'time': Works on daily and higher resolution data to interpolate\n",
      " |            given length of interval.\n",
      " |          * 'index', 'values': use the actual numerical values of the index.\n",
      " |          * 'pad': Fill in NaNs using existing values.\n",
      " |          * 'nearest', 'zero', 'slinear', 'quadratic', 'cubic', 'spline',\n",
      " |            'barycentric', 'polynomial': Passed to\n",
      " |            `scipy.interpolate.interp1d`. These methods use the numerical\n",
      " |            values of the index.  Both 'polynomial' and 'spline' require that\n",
      " |            you also specify an `order` (int), e.g.\n",
      " |            ``df.interpolate(method='polynomial', order=5)``.\n",
      " |          * 'krogh', 'piecewise_polynomial', 'spline', 'pchip', 'akima':\n",
      " |            Wrappers around the SciPy interpolation methods of similar\n",
      " |            names. See `Notes`.\n",
      " |          * 'from_derivatives': Refers to\n",
      " |            `scipy.interpolate.BPoly.from_derivatives` which\n",
      " |            replaces 'piecewise_polynomial' interpolation method in\n",
      " |            scipy 0.18.\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default None\n",
      " |          Axis to interpolate along.\n",
      " |      limit : int, optional\n",
      " |          Maximum number of consecutive NaNs to fill. Must be greater than\n",
      " |          0.\n",
      " |      inplace : bool, default False\n",
      " |          Update the data in place if possible.\n",
      " |      limit_direction : {'forward', 'backward', 'both'}, default 'forward'\n",
      " |          If limit is specified, consecutive NaNs will be filled in this\n",
      " |          direction.\n",
      " |      limit_area : {`None`, 'inside', 'outside'}, default None\n",
      " |          If limit is specified, consecutive NaNs will be filled with this\n",
      " |          restriction.\n",
      " |      \n",
      " |          * ``None``: No fill restriction.\n",
      " |          * 'inside': Only fill NaNs surrounded by valid values\n",
      " |            (interpolate).\n",
      " |          * 'outside': Only fill NaNs outside valid values (extrapolate).\n",
      " |      \n",
      " |          .. versionadded:: 0.23.0\n",
      " |      \n",
      " |      downcast : optional, 'infer' or None, defaults to None\n",
      " |          Downcast dtypes if possible.\n",
      " |      **kwargs\n",
      " |          Keyword arguments to pass on to the interpolating function.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Returns the same object type as the caller, interpolated at\n",
      " |          some or all ``NaN`` values.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      fillna : Fill missing values using different methods.\n",
      " |      scipy.interpolate.Akima1DInterpolator : Piecewise cubic polynomials\n",
      " |          (Akima interpolator).\n",
      " |      scipy.interpolate.BPoly.from_derivatives : Piecewise polynomial in the\n",
      " |          Bernstein basis.\n",
      " |      scipy.interpolate.interp1d : Interpolate a 1-D function.\n",
      " |      scipy.interpolate.KroghInterpolator : Interpolate polynomial (Krogh\n",
      " |          interpolator).\n",
      " |      scipy.interpolate.PchipInterpolator : PCHIP 1-d monotonic cubic\n",
      " |          interpolation.\n",
      " |      scipy.interpolate.CubicSpline : Cubic spline data interpolator.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The 'krogh', 'piecewise_polynomial', 'spline', 'pchip' and 'akima'\n",
      " |      methods are wrappers around the respective SciPy implementations of\n",
      " |      similar names. These use the actual numerical values of the index.\n",
      " |      For more information on their behavior, see the\n",
      " |      `SciPy documentation\n",
      " |      <http://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation>`__\n",
      " |      and `SciPy tutorial\n",
      " |      <http://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html>`__.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Filling in ``NaN`` in a :class:`~pandas.Series` via linear\n",
      " |      interpolation.\n",
      " |      \n",
      " |      >>> s = pd.Series([0, 1, np.nan, 3])\n",
      " |      >>> s\n",
      " |      0    0.0\n",
      " |      1    1.0\n",
      " |      2    NaN\n",
      " |      3    3.0\n",
      " |      dtype: float64\n",
      " |      >>> s.interpolate()\n",
      " |      0    0.0\n",
      " |      1    1.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Filling in ``NaN`` in a Series by padding, but filling at most two\n",
      " |      consecutive ``NaN`` at a time.\n",
      " |      \n",
      " |      >>> s = pd.Series([np.nan, \"single_one\", np.nan,\n",
      " |      ...                \"fill_two_more\", np.nan, np.nan, np.nan,\n",
      " |      ...                4.71, np.nan])\n",
      " |      >>> s\n",
      " |      0              NaN\n",
      " |      1       single_one\n",
      " |      2              NaN\n",
      " |      3    fill_two_more\n",
      " |      4              NaN\n",
      " |      5              NaN\n",
      " |      6              NaN\n",
      " |      7             4.71\n",
      " |      8              NaN\n",
      " |      dtype: object\n",
      " |      >>> s.interpolate(method='pad', limit=2)\n",
      " |      0              NaN\n",
      " |      1       single_one\n",
      " |      2       single_one\n",
      " |      3    fill_two_more\n",
      " |      4    fill_two_more\n",
      " |      5    fill_two_more\n",
      " |      6              NaN\n",
      " |      7             4.71\n",
      " |      8             4.71\n",
      " |      dtype: object\n",
      " |      \n",
      " |      Filling in ``NaN`` in a Series via polynomial interpolation or splines:\n",
      " |      Both 'polynomial' and 'spline' methods require that you also specify\n",
      " |      an ``order`` (int).\n",
      " |      \n",
      " |      >>> s = pd.Series([0, 2, np.nan, 8])\n",
      " |      >>> s.interpolate(method='polynomial', order=2)\n",
      " |      0    0.000000\n",
      " |      1    2.000000\n",
      " |      2    4.666667\n",
      " |      3    8.000000\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      Fill the DataFrame forward (that is, going down) along each column\n",
      " |      using linear interpolation.\n",
      " |      \n",
      " |      Note how the last entry in column 'a' is interpolated differently,\n",
      " |      because there is no entry after it to use for interpolation.\n",
      " |      Note how the first entry in column 'b' remains ``NaN``, because there\n",
      " |      is no entry before it to use for interpolation.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([(0.0, np.nan, -1.0, 1.0),\n",
      " |      ...                    (np.nan, 2.0, np.nan, np.nan),\n",
      " |      ...                    (2.0, 3.0, np.nan, 9.0),\n",
      " |      ...                    (np.nan, 4.0, -4.0, 16.0)],\n",
      " |      ...                   columns=list('abcd'))\n",
      " |      >>> df\n",
      " |           a    b    c     d\n",
      " |      0  0.0  NaN -1.0   1.0\n",
      " |      1  NaN  2.0  NaN   NaN\n",
      " |      2  2.0  3.0  NaN   9.0\n",
      " |      3  NaN  4.0 -4.0  16.0\n",
      " |      >>> df.interpolate(method='linear', limit_direction='forward', axis=0)\n",
      " |           a    b    c     d\n",
      " |      0  0.0  NaN -1.0   1.0\n",
      " |      1  1.0  2.0 -2.0   5.0\n",
      " |      2  2.0  3.0 -3.0   9.0\n",
      " |      3  2.0  4.0 -4.0  16.0\n",
      " |      \n",
      " |      Using polynomial interpolation.\n",
      " |      \n",
      " |      >>> df['d'].interpolate(method='polynomial', order=2)\n",
      " |      0     1.0\n",
      " |      1     4.0\n",
      " |      2     9.0\n",
      " |      3    16.0\n",
      " |      Name: d, dtype: float64\n",
      " |  \n",
      " |  last(self: ~FrameOrSeries, offset) -> ~FrameOrSeries\n",
      " |      Method to subset final periods of time series data based on a date offset.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      offset : str, DateOffset, dateutil.relativedelta\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      subset : same type as caller\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the index is not  a :class:`DatetimeIndex`\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      first : Select initial periods of time series based on a date offset.\n",
      " |      at_time : Select values at a particular time of the day.\n",
      " |      between_time : Select values between particular times of the day.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> i = pd.date_range('2018-04-09', periods=4, freq='2D')\n",
      " |      >>> ts = pd.DataFrame({'A': [1, 2, 3, 4]}, index=i)\n",
      " |      >>> ts\n",
      " |                  A\n",
      " |      2018-04-09  1\n",
      " |      2018-04-11  2\n",
      " |      2018-04-13  3\n",
      " |      2018-04-15  4\n",
      " |      \n",
      " |      Get the rows for the last 3 days:\n",
      " |      \n",
      " |      >>> ts.last('3D')\n",
      " |                  A\n",
      " |      2018-04-13  3\n",
      " |      2018-04-15  4\n",
      " |      \n",
      " |      Notice the data for 3 last calender days were returned, not the last\n",
      " |      3 observed days in the dataset, and therefore data for 2018-04-11 was\n",
      " |      not returned.\n",
      " |  \n",
      " |  last_valid_index(self)\n",
      " |      Return index for last non-NA/null value.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar : type of index\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If all elements are non-NA/null, returns None.\n",
      " |      Also returns None for empty Series/DataFrame.\n",
      " |  \n",
      " |  mask(self, cond, other=nan, inplace=False, axis=None, level=None, errors='raise', try_cast=False)\n",
      " |      Replace values where the condition is True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      cond : bool Series/DataFrame, array-like, or callable\n",
      " |          Where `cond` is False, keep the original value. Where\n",
      " |          True, replace with corresponding value from `other`.\n",
      " |          If `cond` is callable, it is computed on the Series/DataFrame and\n",
      " |          should return boolean Series/DataFrame or array. The callable must\n",
      " |          not change input Series/DataFrame (though pandas doesn't check it).\n",
      " |      other : scalar, Series/DataFrame, or callable\n",
      " |          Entries where `cond` is True are replaced with\n",
      " |          corresponding value from `other`.\n",
      " |          If other is callable, it is computed on the Series/DataFrame and\n",
      " |          should return scalar or Series/DataFrame. The callable must not\n",
      " |          change input Series/DataFrame (though pandas doesn't check it).\n",
      " |      inplace : bool, default False\n",
      " |          Whether to perform the operation in place on the data.\n",
      " |      axis : int, default None\n",
      " |          Alignment axis if needed.\n",
      " |      level : int, default None\n",
      " |          Alignment level if needed.\n",
      " |      errors : str, {'raise', 'ignore'}, default 'raise'\n",
      " |          Note that currently this parameter won't affect\n",
      " |          the results and will always coerce to a suitable dtype.\n",
      " |      \n",
      " |          - 'raise' : allow exceptions to be raised.\n",
      " |          - 'ignore' : suppress exceptions. On error return original object.\n",
      " |      \n",
      " |      try_cast : bool, default False\n",
      " |          Try to cast the result back to the input type (if possible).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Same type as caller\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :func:`DataFrame.where` : Return an object of same shape as\n",
      " |          self.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The mask method is an application of the if-then idiom. For each\n",
      " |      element in the calling DataFrame, if ``cond`` is ``False`` the\n",
      " |      element is used; otherwise the corresponding element from the DataFrame\n",
      " |      ``other`` is used.\n",
      " |      \n",
      " |      The signature for :func:`DataFrame.where` differs from\n",
      " |      :func:`numpy.where`. Roughly ``df1.where(m, df2)`` is equivalent to\n",
      " |      ``np.where(m, df1, df2)``.\n",
      " |      \n",
      " |      For further details and examples see the ``mask`` documentation in\n",
      " |      :ref:`indexing <indexing.where_mask>`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(range(5))\n",
      " |      >>> s.where(s > 0)\n",
      " |      0    NaN\n",
      " |      1    1.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      4    4.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.mask(s > 0)\n",
      " |      0    0.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.where(s > 1, 10)\n",
      " |      0    10\n",
      " |      1    10\n",
      " |      2    2\n",
      " |      3    3\n",
      " |      4    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  0  1\n",
      " |      1  2  3\n",
      " |      2  4  5\n",
      " |      3  6  7\n",
      " |      4  8  9\n",
      " |      >>> m = df % 3 == 0\n",
      " |      >>> df.where(m, -df)\n",
      " |         A  B\n",
      " |      0  0 -1\n",
      " |      1 -2  3\n",
      " |      2 -4 -5\n",
      " |      3  6 -7\n",
      " |      4 -8  9\n",
      " |      >>> df.where(m, -df) == np.where(m, df, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      >>> df.where(m, -df) == df.mask(~m, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |  \n",
      " |  pct_change(self: ~FrameOrSeries, periods=1, fill_method='pad', limit=None, freq=None, **kwargs) -> ~FrameOrSeries\n",
      " |      Percentage change between the current and a prior element.\n",
      " |      \n",
      " |      Computes the percentage change from the immediately previous row by\n",
      " |      default. This is useful in comparing the percentage of change in a time\n",
      " |      series of elements.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for forming percent change.\n",
      " |      fill_method : str, default 'pad'\n",
      " |          How to handle NAs before computing percent changes.\n",
      " |      limit : int, default None\n",
      " |          The number of consecutive NAs to fill before stopping.\n",
      " |      freq : DateOffset, timedelta, or str, optional\n",
      " |          Increment to use from time series API (e.g. 'M' or BDay()).\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments are passed into\n",
      " |          `DataFrame.shift` or `Series.shift`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      chg : Series or DataFrame\n",
      " |          The same type as the calling object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.diff : Compute the difference of two elements in a Series.\n",
      " |      DataFrame.diff : Compute the difference of two elements in a DataFrame.\n",
      " |      Series.shift : Shift the index by some number of periods.\n",
      " |      DataFrame.shift : Shift the index by some number of periods.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([90, 91, 85])\n",
      " |      >>> s\n",
      " |      0    90\n",
      " |      1    91\n",
      " |      2    85\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.pct_change()\n",
      " |      0         NaN\n",
      " |      1    0.011111\n",
      " |      2   -0.065934\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.pct_change(periods=2)\n",
      " |      0         NaN\n",
      " |      1         NaN\n",
      " |      2   -0.055556\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      See the percentage change in a Series where filling NAs with last\n",
      " |      valid observation forward to next valid.\n",
      " |      \n",
      " |      >>> s = pd.Series([90, 91, None, 85])\n",
      " |      >>> s\n",
      " |      0    90.0\n",
      " |      1    91.0\n",
      " |      2     NaN\n",
      " |      3    85.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.pct_change(fill_method='ffill')\n",
      " |      0         NaN\n",
      " |      1    0.011111\n",
      " |      2    0.000000\n",
      " |      3   -0.065934\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      Percentage change in French franc, Deutsche Mark, and Italian lira from\n",
      " |      1980-01-01 to 1980-03-01.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     'FR': [4.0405, 4.0963, 4.3149],\n",
      " |      ...     'GR': [1.7246, 1.7482, 1.8519],\n",
      " |      ...     'IT': [804.74, 810.01, 860.13]},\n",
      " |      ...     index=['1980-01-01', '1980-02-01', '1980-03-01'])\n",
      " |      >>> df\n",
      " |                      FR      GR      IT\n",
      " |      1980-01-01  4.0405  1.7246  804.74\n",
      " |      1980-02-01  4.0963  1.7482  810.01\n",
      " |      1980-03-01  4.3149  1.8519  860.13\n",
      " |      \n",
      " |      >>> df.pct_change()\n",
      " |                        FR        GR        IT\n",
      " |      1980-01-01       NaN       NaN       NaN\n",
      " |      1980-02-01  0.013810  0.013684  0.006549\n",
      " |      1980-03-01  0.053365  0.059318  0.061876\n",
      " |      \n",
      " |      Percentage of change in GOOG and APPL stock volume. Shows computing\n",
      " |      the percentage change between columns.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\n",
      " |      ...     '2016': [1769950, 30586265],\n",
      " |      ...     '2015': [1500923, 40912316],\n",
      " |      ...     '2014': [1371819, 41403351]},\n",
      " |      ...     index=['GOOG', 'APPL'])\n",
      " |      >>> df\n",
      " |                2016      2015      2014\n",
      " |      GOOG   1769950   1500923   1371819\n",
      " |      APPL  30586265  40912316  41403351\n",
      " |      \n",
      " |      >>> df.pct_change(axis='columns')\n",
      " |            2016      2015      2014\n",
      " |      GOOG   NaN -0.151997 -0.086016\n",
      " |      APPL   NaN  0.337604  0.012002\n",
      " |  \n",
      " |  pipe(self, func, *args, **kwargs)\n",
      " |      Apply func(self, \\*args, \\*\\*kwargs).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |          Function to apply to the Series/DataFrame.\n",
      " |          ``args``, and ``kwargs`` are passed into ``func``.\n",
      " |          Alternatively a ``(callable, data_keyword)`` tuple where\n",
      " |          ``data_keyword`` is a string indicating the keyword of\n",
      " |          ``callable`` that expects the Series/DataFrame.\n",
      " |      args : iterable, optional\n",
      " |          Positional arguments passed into ``func``.\n",
      " |      kwargs : mapping, optional\n",
      " |          A dictionary of keyword arguments passed into ``func``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      object : the return type of ``func``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.apply\n",
      " |      DataFrame.applymap\n",
      " |      Series.map\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      \n",
      " |      Use ``.pipe`` when chaining together functions that expect\n",
      " |      Series, DataFrames or GroupBy objects. Instead of writing\n",
      " |      \n",
      " |      >>> f(g(h(df), arg1=a), arg2=b, arg3=c)\n",
      " |      \n",
      " |      You can write\n",
      " |      \n",
      " |      >>> (df.pipe(h)\n",
      " |      ...    .pipe(g, arg1=a)\n",
      " |      ...    .pipe(f, arg2=b, arg3=c)\n",
      " |      ... )\n",
      " |      \n",
      " |      If you have a function that takes the data as (say) the second\n",
      " |      argument, pass a tuple indicating which keyword expects the\n",
      " |      data. For example, suppose ``f`` takes its data as ``arg2``:\n",
      " |      \n",
      " |      >>> (df.pipe(h)\n",
      " |      ...    .pipe(g, arg1=a)\n",
      " |      ...    .pipe((f, 'arg2'), arg1=a, arg3=c)\n",
      " |      ...  )\n",
      " |  \n",
      " |  pop(self: ~FrameOrSeries, item) -> ~FrameOrSeries\n",
      " |      Return item and drop from frame. Raise KeyError if not found.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      item : str\n",
      " |          Label of column to be popped.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('falcon', 'bird', 389.0),\n",
      " |      ...                    ('parrot', 'bird', 24.0),\n",
      " |      ...                    ('lion', 'mammal', 80.5),\n",
      " |      ...                    ('monkey', 'mammal', np.nan)],\n",
      " |      ...                   columns=('name', 'class', 'max_speed'))\n",
      " |      >>> df\n",
      " |           name   class  max_speed\n",
      " |      0  falcon    bird      389.0\n",
      " |      1  parrot    bird       24.0\n",
      " |      2    lion  mammal       80.5\n",
      " |      3  monkey  mammal        NaN\n",
      " |      \n",
      " |      >>> df.pop('class')\n",
      " |      0      bird\n",
      " |      1      bird\n",
      " |      2    mammal\n",
      " |      3    mammal\n",
      " |      Name: class, dtype: object\n",
      " |      \n",
      " |      >>> df\n",
      " |           name  max_speed\n",
      " |      0  falcon      389.0\n",
      " |      1  parrot       24.0\n",
      " |      2    lion       80.5\n",
      " |      3  monkey        NaN\n",
      " |  \n",
      " |  rank(self: ~FrameOrSeries, axis=0, method: str = 'average', numeric_only: Union[bool, NoneType] = None, na_option: str = 'keep', ascending: bool = True, pct: bool = False) -> ~FrameOrSeries\n",
      " |      Compute numerical data ranks (1 through n) along axis.\n",
      " |      \n",
      " |      By default, equal values are assigned a rank that is the average of the\n",
      " |      ranks of those values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Index to direct ranking.\n",
      " |      method : {'average', 'min', 'max', 'first', 'dense'}, default 'average'\n",
      " |          How to rank the group of records that have the same value (i.e. ties):\n",
      " |      \n",
      " |          * average: average rank of the group\n",
      " |          * min: lowest rank in the group\n",
      " |          * max: highest rank in the group\n",
      " |          * first: ranks assigned in order they appear in the array\n",
      " |          * dense: like 'min', but rank always increases by 1 between groups.\n",
      " |      \n",
      " |      numeric_only : bool, optional\n",
      " |          For DataFrame objects, rank only numeric columns if set to True.\n",
      " |      na_option : {'keep', 'top', 'bottom'}, default 'keep'\n",
      " |          How to rank NaN values:\n",
      " |      \n",
      " |          * keep: assign NaN rank to NaN values\n",
      " |          * top: assign smallest rank to NaN values if ascending\n",
      " |          * bottom: assign highest rank to NaN values if ascending.\n",
      " |      \n",
      " |      ascending : bool, default True\n",
      " |          Whether or not the elements should be ranked in ascending order.\n",
      " |      pct : bool, default False\n",
      " |          Whether or not to display the returned rankings in percentile\n",
      " |          form.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as caller\n",
      " |          Return a Series or DataFrame with data ranks as values.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      core.groupby.GroupBy.rank : Rank of values within each group.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(data={'Animal': ['cat', 'penguin', 'dog',\n",
      " |      ...                                    'spider', 'snake'],\n",
      " |      ...                         'Number_legs': [4, 2, 4, 8, np.nan]})\n",
      " |      >>> df\n",
      " |          Animal  Number_legs\n",
      " |      0      cat          4.0\n",
      " |      1  penguin          2.0\n",
      " |      2      dog          4.0\n",
      " |      3   spider          8.0\n",
      " |      4    snake          NaN\n",
      " |      \n",
      " |      The following example shows how the method behaves with the above\n",
      " |      parameters:\n",
      " |      \n",
      " |      * default_rank: this is the default behaviour obtained without using\n",
      " |        any parameter.\n",
      " |      * max_rank: setting ``method = 'max'`` the records that have the\n",
      " |        same values are ranked using the highest rank (e.g.: since 'cat'\n",
      " |        and 'dog' are both in the 2nd and 3rd position, rank 3 is assigned.)\n",
      " |      * NA_bottom: choosing ``na_option = 'bottom'``, if there are records\n",
      " |        with NaN values they are placed at the bottom of the ranking.\n",
      " |      * pct_rank: when setting ``pct = True``, the ranking is expressed as\n",
      " |        percentile rank.\n",
      " |      \n",
      " |      >>> df['default_rank'] = df['Number_legs'].rank()\n",
      " |      >>> df['max_rank'] = df['Number_legs'].rank(method='max')\n",
      " |      >>> df['NA_bottom'] = df['Number_legs'].rank(na_option='bottom')\n",
      " |      >>> df['pct_rank'] = df['Number_legs'].rank(pct=True)\n",
      " |      >>> df\n",
      " |          Animal  Number_legs  default_rank  max_rank  NA_bottom  pct_rank\n",
      " |      0      cat          4.0           2.5       3.0        2.5     0.625\n",
      " |      1  penguin          2.0           1.0       1.0        1.0     0.250\n",
      " |      2      dog          4.0           2.5       3.0        2.5     0.625\n",
      " |      3   spider          8.0           4.0       4.0        4.0     1.000\n",
      " |      4    snake          NaN           NaN       NaN        5.0       NaN\n",
      " |  \n",
      " |  reindex_like(self: ~FrameOrSeries, other, method: Union[str, NoneType] = None, copy: bool = True, limit=None, tolerance=None) -> ~FrameOrSeries\n",
      " |      Return an object with matching indices as other object.\n",
      " |      \n",
      " |      Conform the object to the same index on all axes. Optional\n",
      " |      filling logic, placing NaN in locations having no value\n",
      " |      in the previous index. A new object is produced unless the\n",
      " |      new index is equivalent to the current one and copy=False.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Object of the same data type\n",
      " |          Its row and column indices are used to define the new indices\n",
      " |          of this object.\n",
      " |      method : {None, 'backfill'/'bfill', 'pad'/'ffill', 'nearest'}\n",
      " |          Method to use for filling holes in reindexed DataFrame.\n",
      " |          Please note: this is only applicable to DataFrames/Series with a\n",
      " |          monotonically increasing/decreasing index.\n",
      " |      \n",
      " |          * None (default): don't fill gaps\n",
      " |          * pad / ffill: propagate last valid observation forward to next\n",
      " |            valid\n",
      " |          * backfill / bfill: use next valid observation to fill gap\n",
      " |          * nearest: use nearest valid observations to fill gap.\n",
      " |      \n",
      " |      copy : bool, default True\n",
      " |          Return a new object, even if the passed indexes are the same.\n",
      " |      limit : int, default None\n",
      " |          Maximum number of consecutive labels to fill for inexact matches.\n",
      " |      tolerance : optional\n",
      " |          Maximum distance between original and new labels for inexact\n",
      " |          matches. The values of the index at the matching locations most\n",
      " |          satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      " |      \n",
      " |          Tolerance may be a scalar value, which applies the same tolerance\n",
      " |          to all values, or list-like, which applies variable tolerance per\n",
      " |          element. List-like includes list, tuple, array, Series, and must be\n",
      " |          the same size as the index and its dtype must exactly match the\n",
      " |          index's type.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0 (list-like tolerance)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Same type as caller, but with changed indices on each axis.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.set_index : Set row labels.\n",
      " |      DataFrame.reset_index : Remove row labels or move them to new columns.\n",
      " |      DataFrame.reindex : Change to new indices or expand indices.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Same as calling\n",
      " |      ``.reindex(index=other.index, columns=other.columns,...)``.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df1 = pd.DataFrame([[24.3, 75.7, 'high'],\n",
      " |      ...                     [31, 87.8, 'high'],\n",
      " |      ...                     [22, 71.6, 'medium'],\n",
      " |      ...                     [35, 95, 'medium']],\n",
      " |      ...                    columns=['temp_celsius', 'temp_fahrenheit',\n",
      " |      ...                             'windspeed'],\n",
      " |      ...                    index=pd.date_range(start='2014-02-12',\n",
      " |      ...                                        end='2014-02-15', freq='D'))\n",
      " |      \n",
      " |      >>> df1\n",
      " |                  temp_celsius  temp_fahrenheit windspeed\n",
      " |      2014-02-12          24.3             75.7      high\n",
      " |      2014-02-13          31.0             87.8      high\n",
      " |      2014-02-14          22.0             71.6    medium\n",
      " |      2014-02-15          35.0             95.0    medium\n",
      " |      \n",
      " |      >>> df2 = pd.DataFrame([[28, 'low'],\n",
      " |      ...                     [30, 'low'],\n",
      " |      ...                     [35.1, 'medium']],\n",
      " |      ...                    columns=['temp_celsius', 'windspeed'],\n",
      " |      ...                    index=pd.DatetimeIndex(['2014-02-12', '2014-02-13',\n",
      " |      ...                                            '2014-02-15']))\n",
      " |      \n",
      " |      >>> df2\n",
      " |                  temp_celsius windspeed\n",
      " |      2014-02-12          28.0       low\n",
      " |      2014-02-13          30.0       low\n",
      " |      2014-02-15          35.1    medium\n",
      " |      \n",
      " |      >>> df2.reindex_like(df1)\n",
      " |                  temp_celsius  temp_fahrenheit windspeed\n",
      " |      2014-02-12          28.0              NaN       low\n",
      " |      2014-02-13          30.0              NaN       low\n",
      " |      2014-02-14           NaN              NaN       NaN\n",
      " |      2014-02-15          35.1              NaN    medium\n",
      " |  \n",
      " |  rename_axis(self, mapper=None, index=None, columns=None, axis=None, copy=True, inplace=False)\n",
      " |      Set the name of the axis for the index or columns.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      mapper : scalar, list-like, optional\n",
      " |          Value to set the axis name attribute.\n",
      " |      index, columns : scalar, list-like, dict-like or function, optional\n",
      " |          A scalar, list-like, dict-like or functions transformations to\n",
      " |          apply to that axis' values.\n",
      " |      \n",
      " |          Use either ``mapper`` and ``axis`` to\n",
      " |          specify the axis to target with ``mapper``, or ``index``\n",
      " |          and/or ``columns``.\n",
      " |      \n",
      " |          .. versionchanged:: 0.24.0\n",
      " |      \n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to rename.\n",
      " |      copy : bool, default True\n",
      " |          Also copy underlying data.\n",
      " |      inplace : bool, default False\n",
      " |          Modifies the object directly, instead of creating a new Series\n",
      " |          or DataFrame.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series, DataFrame, or None\n",
      " |          The same type as the caller or None if `inplace` is True.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.rename : Alter Series index labels or name.\n",
      " |      DataFrame.rename : Alter DataFrame index labels or name.\n",
      " |      Index.rename : Set new names on index.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      ``DataFrame.rename_axis`` supports two calling conventions\n",
      " |      \n",
      " |      * ``(index=index_mapper, columns=columns_mapper, ...)``\n",
      " |      * ``(mapper, axis={'index', 'columns'}, ...)``\n",
      " |      \n",
      " |      The first calling convention will only modify the names of\n",
      " |      the index and/or the names of the Index object that is the columns.\n",
      " |      In this case, the parameter ``copy`` is ignored.\n",
      " |      \n",
      " |      The second calling convention will modify the names of the\n",
      " |      the corresponding index if mapper is a list or a scalar.\n",
      " |      However, if mapper is dict-like or a function, it will use the\n",
      " |      deprecated behavior of modifying the axis *labels*.\n",
      " |      \n",
      " |      We *highly* recommend using keyword arguments to clarify your\n",
      " |      intent.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([\"dog\", \"cat\", \"monkey\"])\n",
      " |      >>> s\n",
      " |      0       dog\n",
      " |      1       cat\n",
      " |      2    monkey\n",
      " |      dtype: object\n",
      " |      >>> s.rename_axis(\"animal\")\n",
      " |      animal\n",
      " |      0    dog\n",
      " |      1    cat\n",
      " |      2    monkey\n",
      " |      dtype: object\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"num_legs\": [4, 4, 2],\n",
      " |      ...                    \"num_arms\": [0, 0, 2]},\n",
      " |      ...                   [\"dog\", \"cat\", \"monkey\"])\n",
      " |      >>> df\n",
      " |              num_legs  num_arms\n",
      " |      dog            4         0\n",
      " |      cat            4         0\n",
      " |      monkey         2         2\n",
      " |      >>> df = df.rename_axis(\"animal\")\n",
      " |      >>> df\n",
      " |              num_legs  num_arms\n",
      " |      animal\n",
      " |      dog            4         0\n",
      " |      cat            4         0\n",
      " |      monkey         2         2\n",
      " |      >>> df = df.rename_axis(\"limbs\", axis=\"columns\")\n",
      " |      >>> df\n",
      " |      limbs   num_legs  num_arms\n",
      " |      animal\n",
      " |      dog            4         0\n",
      " |      cat            4         0\n",
      " |      monkey         2         2\n",
      " |      \n",
      " |      **MultiIndex**\n",
      " |      \n",
      " |      >>> df.index = pd.MultiIndex.from_product([['mammal'],\n",
      " |      ...                                        ['dog', 'cat', 'monkey']],\n",
      " |      ...                                       names=['type', 'name'])\n",
      " |      >>> df\n",
      " |      limbs          num_legs  num_arms\n",
      " |      type   name\n",
      " |      mammal dog            4         0\n",
      " |             cat            4         0\n",
      " |             monkey         2         2\n",
      " |      \n",
      " |      >>> df.rename_axis(index={'type': 'class'})\n",
      " |      limbs          num_legs  num_arms\n",
      " |      class  name\n",
      " |      mammal dog            4         0\n",
      " |             cat            4         0\n",
      " |             monkey         2         2\n",
      " |      \n",
      " |      >>> df.rename_axis(columns=str.upper)\n",
      " |      LIMBS          num_legs  num_arms\n",
      " |      type   name\n",
      " |      mammal dog            4         0\n",
      " |             cat            4         0\n",
      " |             monkey         2         2\n",
      " |  \n",
      " |  resample(self, rule, axis=0, closed: Union[str, NoneType] = None, label: Union[str, NoneType] = None, convention: str = 'start', kind: Union[str, NoneType] = None, loffset=None, base: int = 0, on=None, level=None)\n",
      " |      Resample time-series data.\n",
      " |      \n",
      " |      Convenience method for frequency conversion and resampling of time\n",
      " |      series. Object must have a datetime-like index (`DatetimeIndex`,\n",
      " |      `PeriodIndex`, or `TimedeltaIndex`), or pass datetime-like values\n",
      " |      to the `on` or `level` keyword.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      rule : DateOffset, Timedelta or str\n",
      " |          The offset string or object representing target conversion.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Which axis to use for up- or down-sampling. For `Series` this\n",
      " |          will default to 0, i.e. along the rows. Must be\n",
      " |          `DatetimeIndex`, `TimedeltaIndex` or `PeriodIndex`.\n",
      " |      closed : {'right', 'left'}, default None\n",
      " |          Which side of bin interval is closed. The default is 'left'\n",
      " |          for all frequency offsets except for 'M', 'A', 'Q', 'BM',\n",
      " |          'BA', 'BQ', and 'W' which all have a default of 'right'.\n",
      " |      label : {'right', 'left'}, default None\n",
      " |          Which bin edge label to label bucket with. The default is 'left'\n",
      " |          for all frequency offsets except for 'M', 'A', 'Q', 'BM',\n",
      " |          'BA', 'BQ', and 'W' which all have a default of 'right'.\n",
      " |      convention : {'start', 'end', 's', 'e'}, default 'start'\n",
      " |          For `PeriodIndex` only, controls whether to use the start or\n",
      " |          end of `rule`.\n",
      " |      kind : {'timestamp', 'period'}, optional, default None\n",
      " |          Pass 'timestamp' to convert the resulting index to a\n",
      " |          `DateTimeIndex` or 'period' to convert it to a `PeriodIndex`.\n",
      " |          By default the input representation is retained.\n",
      " |      loffset : timedelta, default None\n",
      " |          Adjust the resampled time labels.\n",
      " |      base : int, default 0\n",
      " |          For frequencies that evenly subdivide 1 day, the \"origin\" of the\n",
      " |          aggregated intervals. For example, for '5min' frequency, base could\n",
      " |          range from 0 through 4. Defaults to 0.\n",
      " |      on : str, optional\n",
      " |          For a DataFrame, column to use instead of index for resampling.\n",
      " |          Column must be datetime-like.\n",
      " |      \n",
      " |      level : str or int, optional\n",
      " |          For a MultiIndex, level (name or number) to use for\n",
      " |          resampling. `level` must be datetime-like.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Resampler object\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      groupby : Group by mapping, function, label, or list of labels.\n",
      " |      Series.resample : Resample a Series.\n",
      " |      DataFrame.resample: Resample a DataFrame.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the `user guide\n",
      " |      <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#resampling>`_\n",
      " |      for more.\n",
      " |      \n",
      " |      To learn more about the offset strings, please see `this link\n",
      " |      <https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects>`__.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Start by creating a series with 9 one minute timestamps.\n",
      " |      \n",
      " |      >>> index = pd.date_range('1/1/2000', periods=9, freq='T')\n",
      " |      >>> series = pd.Series(range(9), index=index)\n",
      " |      >>> series\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      2000-01-01 00:03:00    3\n",
      " |      2000-01-01 00:04:00    4\n",
      " |      2000-01-01 00:05:00    5\n",
      " |      2000-01-01 00:06:00    6\n",
      " |      2000-01-01 00:07:00    7\n",
      " |      2000-01-01 00:08:00    8\n",
      " |      Freq: T, dtype: int64\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins and sum the values\n",
      " |      of the timestamps falling into a bin.\n",
      " |      \n",
      " |      >>> series.resample('3T').sum()\n",
      " |      2000-01-01 00:00:00     3\n",
      " |      2000-01-01 00:03:00    12\n",
      " |      2000-01-01 00:06:00    21\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins as above, but label each\n",
      " |      bin using the right edge instead of the left. Please note that the\n",
      " |      value in the bucket used as the label is not included in the bucket,\n",
      " |      which it labels. For example, in the original series the\n",
      " |      bucket ``2000-01-01 00:03:00`` contains the value 3, but the summed\n",
      " |      value in the resampled bucket with the label ``2000-01-01 00:03:00``\n",
      " |      does not include 3 (if it did, the summed value would be 6, not 3).\n",
      " |      To include this value close the right side of the bin interval as\n",
      " |      illustrated in the example below this one.\n",
      " |      \n",
      " |      >>> series.resample('3T', label='right').sum()\n",
      " |      2000-01-01 00:03:00     3\n",
      " |      2000-01-01 00:06:00    12\n",
      " |      2000-01-01 00:09:00    21\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      Downsample the series into 3 minute bins as above, but close the right\n",
      " |      side of the bin interval.\n",
      " |      \n",
      " |      >>> series.resample('3T', label='right', closed='right').sum()\n",
      " |      2000-01-01 00:00:00     0\n",
      " |      2000-01-01 00:03:00     6\n",
      " |      2000-01-01 00:06:00    15\n",
      " |      2000-01-01 00:09:00    15\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      Upsample the series into 30 second bins.\n",
      " |      \n",
      " |      >>> series.resample('30S').asfreq()[0:5]   # Select first 5 rows\n",
      " |      2000-01-01 00:00:00   0.0\n",
      " |      2000-01-01 00:00:30   NaN\n",
      " |      2000-01-01 00:01:00   1.0\n",
      " |      2000-01-01 00:01:30   NaN\n",
      " |      2000-01-01 00:02:00   2.0\n",
      " |      Freq: 30S, dtype: float64\n",
      " |      \n",
      " |      Upsample the series into 30 second bins and fill the ``NaN``\n",
      " |      values using the ``pad`` method.\n",
      " |      \n",
      " |      >>> series.resample('30S').pad()[0:5]\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:00:30    0\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:01:30    1\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      Freq: 30S, dtype: int64\n",
      " |      \n",
      " |      Upsample the series into 30 second bins and fill the\n",
      " |      ``NaN`` values using the ``bfill`` method.\n",
      " |      \n",
      " |      >>> series.resample('30S').bfill()[0:5]\n",
      " |      2000-01-01 00:00:00    0\n",
      " |      2000-01-01 00:00:30    1\n",
      " |      2000-01-01 00:01:00    1\n",
      " |      2000-01-01 00:01:30    2\n",
      " |      2000-01-01 00:02:00    2\n",
      " |      Freq: 30S, dtype: int64\n",
      " |      \n",
      " |      Pass a custom function via ``apply``\n",
      " |      \n",
      " |      >>> def custom_resampler(array_like):\n",
      " |      ...     return np.sum(array_like) + 5\n",
      " |      ...\n",
      " |      >>> series.resample('3T').apply(custom_resampler)\n",
      " |      2000-01-01 00:00:00     8\n",
      " |      2000-01-01 00:03:00    17\n",
      " |      2000-01-01 00:06:00    26\n",
      " |      Freq: 3T, dtype: int64\n",
      " |      \n",
      " |      For a Series with a PeriodIndex, the keyword `convention` can be\n",
      " |      used to control whether to use the start or end of `rule`.\n",
      " |      \n",
      " |      Resample a year by quarter using 'start' `convention`. Values are\n",
      " |      assigned to the first quarter of the period.\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2], index=pd.period_range('2012-01-01',\n",
      " |      ...                                             freq='A',\n",
      " |      ...                                             periods=2))\n",
      " |      >>> s\n",
      " |      2012    1\n",
      " |      2013    2\n",
      " |      Freq: A-DEC, dtype: int64\n",
      " |      >>> s.resample('Q', convention='start').asfreq()\n",
      " |      2012Q1    1.0\n",
      " |      2012Q2    NaN\n",
      " |      2012Q3    NaN\n",
      " |      2012Q4    NaN\n",
      " |      2013Q1    2.0\n",
      " |      2013Q2    NaN\n",
      " |      2013Q3    NaN\n",
      " |      2013Q4    NaN\n",
      " |      Freq: Q-DEC, dtype: float64\n",
      " |      \n",
      " |      Resample quarters by month using 'end' `convention`. Values are\n",
      " |      assigned to the last month of the period.\n",
      " |      \n",
      " |      >>> q = pd.Series([1, 2, 3, 4], index=pd.period_range('2018-01-01',\n",
      " |      ...                                                   freq='Q',\n",
      " |      ...                                                   periods=4))\n",
      " |      >>> q\n",
      " |      2018Q1    1\n",
      " |      2018Q2    2\n",
      " |      2018Q3    3\n",
      " |      2018Q4    4\n",
      " |      Freq: Q-DEC, dtype: int64\n",
      " |      >>> q.resample('M', convention='end').asfreq()\n",
      " |      2018-03    1.0\n",
      " |      2018-04    NaN\n",
      " |      2018-05    NaN\n",
      " |      2018-06    2.0\n",
      " |      2018-07    NaN\n",
      " |      2018-08    NaN\n",
      " |      2018-09    3.0\n",
      " |      2018-10    NaN\n",
      " |      2018-11    NaN\n",
      " |      2018-12    4.0\n",
      " |      Freq: M, dtype: float64\n",
      " |      \n",
      " |      For DataFrame objects, the keyword `on` can be used to specify the\n",
      " |      column instead of the index for resampling.\n",
      " |      \n",
      " |      >>> d = dict({'price': [10, 11, 9, 13, 14, 18, 17, 19],\n",
      " |      ...           'volume': [50, 60, 40, 100, 50, 100, 40, 50]})\n",
      " |      >>> df = pd.DataFrame(d)\n",
      " |      >>> df['week_starting'] = pd.date_range('01/01/2018',\n",
      " |      ...                                     periods=8,\n",
      " |      ...                                     freq='W')\n",
      " |      >>> df\n",
      " |         price  volume week_starting\n",
      " |      0     10      50    2018-01-07\n",
      " |      1     11      60    2018-01-14\n",
      " |      2      9      40    2018-01-21\n",
      " |      3     13     100    2018-01-28\n",
      " |      4     14      50    2018-02-04\n",
      " |      5     18     100    2018-02-11\n",
      " |      6     17      40    2018-02-18\n",
      " |      7     19      50    2018-02-25\n",
      " |      >>> df.resample('M', on='week_starting').mean()\n",
      " |                     price  volume\n",
      " |      week_starting\n",
      " |      2018-01-31     10.75    62.5\n",
      " |      2018-02-28     17.00    60.0\n",
      " |      \n",
      " |      For a DataFrame with MultiIndex, the keyword `level` can be used to\n",
      " |      specify on which level the resampling needs to take place.\n",
      " |      \n",
      " |      >>> days = pd.date_range('1/1/2000', periods=4, freq='D')\n",
      " |      >>> d2 = dict({'price': [10, 11, 9, 13, 14, 18, 17, 19],\n",
      " |      ...            'volume': [50, 60, 40, 100, 50, 100, 40, 50]})\n",
      " |      >>> df2 = pd.DataFrame(d2,\n",
      " |      ...                    index=pd.MultiIndex.from_product([days,\n",
      " |      ...                                                     ['morning',\n",
      " |      ...                                                      'afternoon']]\n",
      " |      ...                                                     ))\n",
      " |      >>> df2\n",
      " |                            price  volume\n",
      " |      2000-01-01 morning       10      50\n",
      " |                 afternoon     11      60\n",
      " |      2000-01-02 morning        9      40\n",
      " |                 afternoon     13     100\n",
      " |      2000-01-03 morning       14      50\n",
      " |                 afternoon     18     100\n",
      " |      2000-01-04 morning       17      40\n",
      " |                 afternoon     19      50\n",
      " |      >>> df2.resample('D', level=0).sum()\n",
      " |                  price  volume\n",
      " |      2000-01-01     21     110\n",
      " |      2000-01-02     22     140\n",
      " |      2000-01-03     32     150\n",
      " |      2000-01-04     36      90\n",
      " |  \n",
      " |  sample(self: ~FrameOrSeries, n=None, frac=None, replace=False, weights=None, random_state=None, axis=None) -> ~FrameOrSeries\n",
      " |      Return a random sample of items from an axis of object.\n",
      " |      \n",
      " |      You can use `random_state` for reproducibility.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, optional\n",
      " |          Number of items from axis to return. Cannot be used with `frac`.\n",
      " |          Default = 1 if `frac` = None.\n",
      " |      frac : float, optional\n",
      " |          Fraction of axis items to return. Cannot be used with `n`.\n",
      " |      replace : bool, default False\n",
      " |          Allow or disallow sampling of the same row more than once.\n",
      " |      weights : str or ndarray-like, optional\n",
      " |          Default 'None' results in equal probability weighting.\n",
      " |          If passed a Series, will align with target object on index. Index\n",
      " |          values in weights not found in sampled object will be ignored and\n",
      " |          index values in sampled object not in weights will be assigned\n",
      " |          weights of zero.\n",
      " |          If called on a DataFrame, will accept the name of a column\n",
      " |          when axis = 0.\n",
      " |          Unless weights are a Series, weights must be same length as axis\n",
      " |          being sampled.\n",
      " |          If weights do not sum to 1, they will be normalized to sum to 1.\n",
      " |          Missing values in the weights column will be treated as zero.\n",
      " |          Infinite values not allowed.\n",
      " |      random_state : int or numpy.random.RandomState, optional\n",
      " |          Seed for the random number generator (if int), or numpy RandomState\n",
      " |          object.\n",
      " |      axis : {0 or ‘index’, 1 or ‘columns’, None}, default None\n",
      " |          Axis to sample. Accepts axis number or name. Default is stat axis\n",
      " |          for given data type (0 for Series and DataFrames).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          A new object of same type as caller containing `n` items randomly\n",
      " |          sampled from the caller object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.random.choice: Generates a random sample from a given 1-D numpy\n",
      " |          array.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If `frac` > 1, `replacement` should be set to `True`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'num_legs': [2, 4, 8, 0],\n",
      " |      ...                    'num_wings': [2, 0, 0, 0],\n",
      " |      ...                    'num_specimen_seen': [10, 2, 1, 8]},\n",
      " |      ...                   index=['falcon', 'dog', 'spider', 'fish'])\n",
      " |      >>> df\n",
      " |              num_legs  num_wings  num_specimen_seen\n",
      " |      falcon         2          2                 10\n",
      " |      dog            4          0                  2\n",
      " |      spider         8          0                  1\n",
      " |      fish           0          0                  8\n",
      " |      \n",
      " |      Extract 3 random elements from the ``Series`` ``df['num_legs']``:\n",
      " |      Note that we use `random_state` to ensure the reproducibility of\n",
      " |      the examples.\n",
      " |      \n",
      " |      >>> df['num_legs'].sample(n=3, random_state=1)\n",
      " |      fish      0\n",
      " |      spider    8\n",
      " |      falcon    2\n",
      " |      Name: num_legs, dtype: int64\n",
      " |      \n",
      " |      A random 50% sample of the ``DataFrame`` with replacement:\n",
      " |      \n",
      " |      >>> df.sample(frac=0.5, replace=True, random_state=1)\n",
      " |            num_legs  num_wings  num_specimen_seen\n",
      " |      dog          4          0                  2\n",
      " |      fish         0          0                  8\n",
      " |      \n",
      " |      An upsample sample of the ``DataFrame`` with replacement:\n",
      " |      Note that `replace` parameter has to be `True` for `frac` parameter > 1.\n",
      " |      \n",
      " |      >>> df.sample(frac=2, replace=True, random_state=1)\n",
      " |              num_legs  num_wings  num_specimen_seen\n",
      " |      dog            4          0                  2\n",
      " |      fish           0          0                  8\n",
      " |      falcon         2          2                 10\n",
      " |      falcon         2          2                 10\n",
      " |      fish           0          0                  8\n",
      " |      dog            4          0                  2\n",
      " |      fish           0          0                  8\n",
      " |      dog            4          0                  2\n",
      " |      \n",
      " |      Using a DataFrame column as weights. Rows with larger value in the\n",
      " |      `num_specimen_seen` column are more likely to be sampled.\n",
      " |      \n",
      " |      >>> df.sample(n=2, weights='num_specimen_seen', random_state=1)\n",
      " |              num_legs  num_wings  num_specimen_seen\n",
      " |      falcon         2          2                 10\n",
      " |      fish           0          0                  8\n",
      " |  \n",
      " |  set_axis(self, labels, axis=0, inplace=False)\n",
      " |      Assign desired index to given axis.\n",
      " |      \n",
      " |      Indexes for column or row labels can be changed by assigning\n",
      " |      a list-like or Index.\n",
      " |      \n",
      " |      .. versionchanged:: 0.21.0\n",
      " |      \n",
      " |         The signature is now `labels` and `axis`, consistent with\n",
      " |         the rest of pandas API. Previously, the `axis` and `labels`\n",
      " |         arguments were respectively the first and second positional\n",
      " |         arguments.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      labels : list-like, Index\n",
      " |          The values for the new index.\n",
      " |      \n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          The axis to update. The value 0 identifies the rows, and 1\n",
      " |          identifies the columns.\n",
      " |      \n",
      " |      inplace : bool, default False\n",
      " |          Whether to return a new %(klass)s instance.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      renamed : %(klass)s or None\n",
      " |          An object of same type as caller if inplace=False, None otherwise.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.rename_axis : Alter the name of the index or columns.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Series**\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> s.set_axis(['a', 'b', 'c'], axis=0)\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      c    3\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      **DataFrame**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
      " |      \n",
      " |      Change the row labels.\n",
      " |      \n",
      " |      >>> df.set_axis(['a', 'b', 'c'], axis='index')\n",
      " |         A  B\n",
      " |      a  1  4\n",
      " |      b  2  5\n",
      " |      c  3  6\n",
      " |      \n",
      " |      Change the column labels.\n",
      " |      \n",
      " |      >>> df.set_axis(['I', 'II'], axis='columns')\n",
      " |         I  II\n",
      " |      0  1   4\n",
      " |      1  2   5\n",
      " |      2  3   6\n",
      " |      \n",
      " |      Now, update the labels inplace.\n",
      " |      \n",
      " |      >>> df.set_axis(['i', 'ii'], axis='columns', inplace=True)\n",
      " |      >>> df\n",
      " |         i  ii\n",
      " |      0  1   4\n",
      " |      1  2   5\n",
      " |      2  3   6\n",
      " |  \n",
      " |  slice_shift(self: ~FrameOrSeries, periods: int = 1, axis=0) -> ~FrameOrSeries\n",
      " |      Equivalent to `shift` without copying data.\n",
      " |      \n",
      " |      The shifted data will not include the dropped periods and the\n",
      " |      shifted axis will be smaller than the original.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : same type as caller\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      While the `slice_shift` is faster than `shift`, you may pay for it\n",
      " |      later during alignment.\n",
      " |  \n",
      " |  squeeze(self, axis=None)\n",
      " |      Squeeze 1 dimensional axis objects into scalars.\n",
      " |      \n",
      " |      Series or DataFrames with a single element are squeezed to a scalar.\n",
      " |      DataFrames with a single column or a single row are squeezed to a\n",
      " |      Series. Otherwise the object is unchanged.\n",
      " |      \n",
      " |      This method is most useful when you don't know if your\n",
      " |      object is a Series or DataFrame, but you do know it has just a single\n",
      " |      column. In that case you can safely call `squeeze` to ensure you have a\n",
      " |      Series.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0 or 'index', 1 or 'columns', None}, default None\n",
      " |          A specific axis to squeeze. By default, all length-1 axes are\n",
      " |          squeezed.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame, Series, or scalar\n",
      " |          The projection after squeezing `axis` or all the axes.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.iloc : Integer-location based indexing for selecting scalars.\n",
      " |      DataFrame.iloc : Integer-location based indexing for selecting Series.\n",
      " |      Series.to_frame : Inverse of DataFrame.squeeze for a\n",
      " |          single-column DataFrame.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> primes = pd.Series([2, 3, 5, 7])\n",
      " |      \n",
      " |      Slicing might produce a Series with a single value:\n",
      " |      \n",
      " |      >>> even_primes = primes[primes % 2 == 0]\n",
      " |      >>> even_primes\n",
      " |      0    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> even_primes.squeeze()\n",
      " |      2\n",
      " |      \n",
      " |      Squeezing objects with more than one value in every axis does nothing:\n",
      " |      \n",
      " |      >>> odd_primes = primes[primes % 2 == 1]\n",
      " |      >>> odd_primes\n",
      " |      1    3\n",
      " |      2    5\n",
      " |      3    7\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> odd_primes.squeeze()\n",
      " |      1    3\n",
      " |      2    5\n",
      " |      3    7\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Squeezing is even more effective when used with DataFrames.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2], [3, 4]], columns=['a', 'b'])\n",
      " |      >>> df\n",
      " |         a  b\n",
      " |      0  1  2\n",
      " |      1  3  4\n",
      " |      \n",
      " |      Slicing a single column will produce a DataFrame with the columns\n",
      " |      having only one value:\n",
      " |      \n",
      " |      >>> df_a = df[['a']]\n",
      " |      >>> df_a\n",
      " |         a\n",
      " |      0  1\n",
      " |      1  3\n",
      " |      \n",
      " |      So the columns can be squeezed down, resulting in a Series:\n",
      " |      \n",
      " |      >>> df_a.squeeze('columns')\n",
      " |      0    1\n",
      " |      1    3\n",
      " |      Name: a, dtype: int64\n",
      " |      \n",
      " |      Slicing a single row from a single column will produce a single\n",
      " |      scalar DataFrame:\n",
      " |      \n",
      " |      >>> df_0a = df.loc[df.index < 1, ['a']]\n",
      " |      >>> df_0a\n",
      " |         a\n",
      " |      0  1\n",
      " |      \n",
      " |      Squeezing the rows produces a single scalar Series:\n",
      " |      \n",
      " |      >>> df_0a.squeeze('rows')\n",
      " |      a    1\n",
      " |      Name: 0, dtype: int64\n",
      " |      \n",
      " |      Squeezing all axes will project directly into a scalar:\n",
      " |      \n",
      " |      >>> df_0a.squeeze()\n",
      " |      1\n",
      " |  \n",
      " |  swapaxes(self: ~FrameOrSeries, axis1, axis2, copy=True) -> ~FrameOrSeries\n",
      " |      Interchange axes and swap values axes appropriately.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : same as input\n",
      " |  \n",
      " |  tail(self: ~FrameOrSeries, n: int = 5) -> ~FrameOrSeries\n",
      " |      Return the last `n` rows.\n",
      " |      \n",
      " |      This function returns last `n` rows from the object based on\n",
      " |      position. It is useful for quickly verifying data, for example,\n",
      " |      after sorting or appending rows.\n",
      " |      \n",
      " |      For negative values of `n`, this function returns all rows except\n",
      " |      the first `n` rows, equivalent to ``df[n:]``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int, default 5\n",
      " |          Number of rows to select.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of caller\n",
      " |          The last `n` rows of the caller object.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.head : The first `n` rows of the caller object.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'animal': ['alligator', 'bee', 'falcon', 'lion',\n",
      " |      ...                    'monkey', 'parrot', 'shark', 'whale', 'zebra']})\n",
      " |      >>> df\n",
      " |            animal\n",
      " |      0  alligator\n",
      " |      1        bee\n",
      " |      2     falcon\n",
      " |      3       lion\n",
      " |      4     monkey\n",
      " |      5     parrot\n",
      " |      6      shark\n",
      " |      7      whale\n",
      " |      8      zebra\n",
      " |      \n",
      " |      Viewing the last 5 lines\n",
      " |      \n",
      " |      >>> df.tail()\n",
      " |         animal\n",
      " |      4  monkey\n",
      " |      5  parrot\n",
      " |      6   shark\n",
      " |      7   whale\n",
      " |      8   zebra\n",
      " |      \n",
      " |      Viewing the last `n` lines (three in this case)\n",
      " |      \n",
      " |      >>> df.tail(3)\n",
      " |        animal\n",
      " |      6  shark\n",
      " |      7  whale\n",
      " |      8  zebra\n",
      " |      \n",
      " |      For negative values of `n`\n",
      " |      \n",
      " |      >>> df.tail(-3)\n",
      " |         animal\n",
      " |      3    lion\n",
      " |      4  monkey\n",
      " |      5  parrot\n",
      " |      6   shark\n",
      " |      7   whale\n",
      " |      8   zebra\n",
      " |  \n",
      " |  to_clipboard(self, excel: bool = True, sep: Union[str, NoneType] = None, **kwargs) -> None\n",
      " |      Copy object to the system clipboard.\n",
      " |      \n",
      " |      Write a text representation of object to the system clipboard.\n",
      " |      This can be pasted into Excel, for example.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      excel : bool, default True\n",
      " |          Produce output in a csv format for easy pasting into excel.\n",
      " |      \n",
      " |          - True, use the provided separator for csv pasting.\n",
      " |          - False, write a string representation of the object to the clipboard.\n",
      " |      \n",
      " |      sep : str, default ``'\\t'``\n",
      " |          Field delimiter.\n",
      " |      **kwargs\n",
      " |          These parameters will be passed to DataFrame.to_csv.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.to_csv : Write a DataFrame to a comma-separated values\n",
      " |          (csv) file.\n",
      " |      read_clipboard : Read text from clipboard and pass to read_table.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Requirements for your platform.\n",
      " |      \n",
      " |        - Linux : `xclip`, or `xsel` (with `PyQt4` modules)\n",
      " |        - Windows : none\n",
      " |        - OS X : none\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Copy the contents of a DataFrame to the clipboard.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2, 3], [4, 5, 6]], columns=['A', 'B', 'C'])\n",
      " |      >>> df.to_clipboard(sep=',')\n",
      " |      ... # Wrote the following to the system clipboard:\n",
      " |      ... # ,A,B,C\n",
      " |      ... # 0,1,2,3\n",
      " |      ... # 1,4,5,6\n",
      " |      \n",
      " |      We can omit the the index by passing the keyword `index` and setting\n",
      " |      it to false.\n",
      " |      \n",
      " |      >>> df.to_clipboard(sep=',', index=False)\n",
      " |      ... # Wrote the following to the system clipboard:\n",
      " |      ... # A,B,C\n",
      " |      ... # 1,2,3\n",
      " |      ... # 4,5,6\n",
      " |  \n",
      " |  to_csv(self, path_or_buf: Union[str, pathlib.Path, IO[~AnyStr], NoneType] = None, sep: str = ',', na_rep: str = '', float_format: Union[str, NoneType] = None, columns: Union[Sequence[Union[Hashable, NoneType]], NoneType] = None, header: Union[bool, List[str]] = True, index: bool = True, index_label: Union[bool, str, Sequence[Union[Hashable, NoneType]], NoneType] = None, mode: str = 'w', encoding: Union[str, NoneType] = None, compression: Union[str, Mapping[str, str], NoneType] = 'infer', quoting: Union[int, NoneType] = None, quotechar: str = '\"', line_terminator: Union[str, NoneType] = None, chunksize: Union[int, NoneType] = None, date_format: Union[str, NoneType] = None, doublequote: bool = True, escapechar: Union[str, NoneType] = None, decimal: Union[str, NoneType] = '.') -> Union[str, NoneType]\n",
      " |      Write object to a comma-separated values (csv) file.\n",
      " |      \n",
      " |      .. versionchanged:: 0.24.0\n",
      " |          The order of arguments for Series was changed.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : str or file handle, default None\n",
      " |          File path or object, if None is provided the result is returned as\n",
      " |          a string.  If a file object is passed it should be opened with\n",
      " |          `newline=''`, disabling universal newlines.\n",
      " |      \n",
      " |          .. versionchanged:: 0.24.0\n",
      " |      \n",
      " |             Was previously named \"path\" for Series.\n",
      " |      \n",
      " |      sep : str, default ','\n",
      " |          String of length 1. Field delimiter for the output file.\n",
      " |      na_rep : str, default ''\n",
      " |          Missing data representation.\n",
      " |      float_format : str, default None\n",
      " |          Format string for floating point numbers.\n",
      " |      columns : sequence, optional\n",
      " |          Columns to write.\n",
      " |      header : bool or list of str, default True\n",
      " |          Write out the column names. If a list of strings is given it is\n",
      " |          assumed to be aliases for the column names.\n",
      " |      \n",
      " |          .. versionchanged:: 0.24.0\n",
      " |      \n",
      " |             Previously defaulted to False for Series.\n",
      " |      \n",
      " |      index : bool, default True\n",
      " |          Write row names (index).\n",
      " |      index_label : str or sequence, or False, default None\n",
      " |          Column label for index column(s) if desired. If None is given, and\n",
      " |          `header` and `index` are True, then the index names are used. A\n",
      " |          sequence should be given if the object uses MultiIndex. If\n",
      " |          False do not print fields for index names. Use index_label=False\n",
      " |          for easier importing in R.\n",
      " |      mode : str\n",
      " |          Python write mode, default 'w'.\n",
      " |      encoding : str, optional\n",
      " |          A string representing the encoding to use in the output file,\n",
      " |          defaults to 'utf-8'.\n",
      " |      compression : str or dict, default 'infer'\n",
      " |          If str, represents compression mode. If dict, value at 'method' is\n",
      " |          the compression mode. Compression mode may be any of the following\n",
      " |          possible values: {'infer', 'gzip', 'bz2', 'zip', 'xz', None}. If\n",
      " |          compression mode is 'infer' and `path_or_buf` is path-like, then\n",
      " |          detect compression mode from the following extensions: '.gz',\n",
      " |          '.bz2', '.zip' or '.xz'. (otherwise no compression). If dict given\n",
      " |          and mode is 'zip' or inferred as 'zip', other entries passed as\n",
      " |          additional compression options.\n",
      " |      \n",
      " |          .. versionchanged:: 1.0.0\n",
      " |      \n",
      " |             May now be a dict with key 'method' as compression mode\n",
      " |             and other entries as additional compression options if\n",
      " |             compression mode is 'zip'.\n",
      " |      \n",
      " |      quoting : optional constant from csv module\n",
      " |          Defaults to csv.QUOTE_MINIMAL. If you have set a `float_format`\n",
      " |          then floats are converted to strings and thus csv.QUOTE_NONNUMERIC\n",
      " |          will treat them as non-numeric.\n",
      " |      quotechar : str, default '\\\"'\n",
      " |          String of length 1. Character used to quote fields.\n",
      " |      line_terminator : str, optional\n",
      " |          The newline character or character sequence to use in the output\n",
      " |          file. Defaults to `os.linesep`, which depends on the OS in which\n",
      " |          this method is called ('\\n' for linux, '\\r\\n' for Windows, i.e.).\n",
      " |      \n",
      " |          .. versionchanged:: 0.24.0\n",
      " |      chunksize : int or None\n",
      " |          Rows to write at a time.\n",
      " |      date_format : str, default None\n",
      " |          Format string for datetime objects.\n",
      " |      doublequote : bool, default True\n",
      " |          Control quoting of `quotechar` inside a field.\n",
      " |      escapechar : str, default None\n",
      " |          String of length 1. Character used to escape `sep` and `quotechar`\n",
      " |          when appropriate.\n",
      " |      decimal : str, default '.'\n",
      " |          Character recognized as decimal separator. E.g. use ',' for\n",
      " |          European data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      None or str\n",
      " |          If path_or_buf is None, returns the resulting csv format as a\n",
      " |          string. Otherwise returns None.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_csv : Load a CSV file into a DataFrame.\n",
      " |      to_excel : Write DataFrame to an Excel file.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'name': ['Raphael', 'Donatello'],\n",
      " |      ...                    'mask': ['red', 'purple'],\n",
      " |      ...                    'weapon': ['sai', 'bo staff']})\n",
      " |      >>> df.to_csv(index=False)\n",
      " |      'name,mask,weapon\\nRaphael,red,sai\\nDonatello,purple,bo staff\\n'\n",
      " |      \n",
      " |      Create 'out.zip' containing 'out.csv'\n",
      " |      \n",
      " |      >>> compression_opts = dict(method='zip',\n",
      " |      ...                         archive_name='out.csv')  # doctest: +SKIP\n",
      " |      >>> df.to_csv('out.zip', index=False,\n",
      " |      ...           compression=compression_opts)  # doctest: +SKIP\n",
      " |  \n",
      " |  to_excel(self, excel_writer, sheet_name='Sheet1', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, startrow=0, startcol=0, engine=None, merge_cells=True, encoding=None, inf_rep='inf', verbose=True, freeze_panes=None) -> None\n",
      " |      Write object to an Excel sheet.\n",
      " |      \n",
      " |      To write a single object to an Excel .xlsx file it is only necessary to\n",
      " |      specify a target file name. To write to multiple sheets it is necessary to\n",
      " |      create an `ExcelWriter` object with a target file name, and specify a sheet\n",
      " |      in the file to write to.\n",
      " |      \n",
      " |      Multiple sheets may be written to by specifying unique `sheet_name`.\n",
      " |      With all data written to the file it is necessary to save the changes.\n",
      " |      Note that creating an `ExcelWriter` object with a file name that already\n",
      " |      exists will result in the contents of the existing file being erased.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      excel_writer : str or ExcelWriter object\n",
      " |          File path or existing ExcelWriter.\n",
      " |      sheet_name : str, default 'Sheet1'\n",
      " |          Name of sheet which will contain DataFrame.\n",
      " |      na_rep : str, default ''\n",
      " |          Missing data representation.\n",
      " |      float_format : str, optional\n",
      " |          Format string for floating point numbers. For example\n",
      " |          ``float_format=\"%.2f\"`` will format 0.1234 to 0.12.\n",
      " |      columns : sequence or list of str, optional\n",
      " |          Columns to write.\n",
      " |      header : bool or list of str, default True\n",
      " |          Write out the column names. If a list of string is given it is\n",
      " |          assumed to be aliases for the column names.\n",
      " |      index : bool, default True\n",
      " |          Write row names (index).\n",
      " |      index_label : str or sequence, optional\n",
      " |          Column label for index column(s) if desired. If not specified, and\n",
      " |          `header` and `index` are True, then the index names are used. A\n",
      " |          sequence should be given if the DataFrame uses MultiIndex.\n",
      " |      startrow : int, default 0\n",
      " |          Upper left cell row to dump data frame.\n",
      " |      startcol : int, default 0\n",
      " |          Upper left cell column to dump data frame.\n",
      " |      engine : str, optional\n",
      " |          Write engine to use, 'openpyxl' or 'xlsxwriter'. You can also set this\n",
      " |          via the options ``io.excel.xlsx.writer``, ``io.excel.xls.writer``, and\n",
      " |          ``io.excel.xlsm.writer``.\n",
      " |      merge_cells : bool, default True\n",
      " |          Write MultiIndex and Hierarchical Rows as merged cells.\n",
      " |      encoding : str, optional\n",
      " |          Encoding of the resulting excel file. Only necessary for xlwt,\n",
      " |          other writers support unicode natively.\n",
      " |      inf_rep : str, default 'inf'\n",
      " |          Representation for infinity (there is no native representation for\n",
      " |          infinity in Excel).\n",
      " |      verbose : bool, default True\n",
      " |          Display more information in the error logs.\n",
      " |      freeze_panes : tuple of int (length 2), optional\n",
      " |          Specifies the one-based bottommost row and rightmost column that\n",
      " |          is to be frozen.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
      " |      ExcelWriter : Class for writing DataFrame objects into excel sheets.\n",
      " |      read_excel : Read an Excel file into a pandas DataFrame.\n",
      " |      read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For compatibility with :meth:`~DataFrame.to_csv`,\n",
      " |      to_excel serializes lists and dicts to strings before writing.\n",
      " |      \n",
      " |      Once a workbook has been saved it is not possible write further data\n",
      " |      without rewriting the whole workbook.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Create, write to and save a workbook:\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame([['a', 'b'], ['c', 'd']],\n",
      " |      ...                    index=['row 1', 'row 2'],\n",
      " |      ...                    columns=['col 1', 'col 2'])\n",
      " |      >>> df1.to_excel(\"output.xlsx\")  # doctest: +SKIP\n",
      " |      \n",
      " |      To specify the sheet name:\n",
      " |      \n",
      " |      >>> df1.to_excel(\"output.xlsx\",\n",
      " |      ...              sheet_name='Sheet_name_1')  # doctest: +SKIP\n",
      " |      \n",
      " |      If you wish to write to more than one sheet in the workbook, it is\n",
      " |      necessary to specify an ExcelWriter object:\n",
      " |      \n",
      " |      >>> df2 = df1.copy()\n",
      " |      >>> with pd.ExcelWriter('output.xlsx') as writer:  # doctest: +SKIP\n",
      " |      ...     df1.to_excel(writer, sheet_name='Sheet_name_1')\n",
      " |      ...     df2.to_excel(writer, sheet_name='Sheet_name_2')\n",
      " |      \n",
      " |      ExcelWriter can also be used to append to an existing Excel file:\n",
      " |      \n",
      " |      >>> with pd.ExcelWriter('output.xlsx',\n",
      " |      ...                     mode='a') as writer:  # doctest: +SKIP\n",
      " |      ...     df.to_excel(writer, sheet_name='Sheet_name_3')\n",
      " |      \n",
      " |      To set the library that is used to write the Excel file,\n",
      " |      you can pass the `engine` keyword (the default engine is\n",
      " |      automatically chosen depending on the file extension):\n",
      " |      \n",
      " |      >>> df1.to_excel('output1.xlsx', engine='xlsxwriter')  # doctest: +SKIP\n",
      " |  \n",
      " |  to_hdf(self, path_or_buf, key: str, mode: str = 'a', complevel: Union[int, NoneType] = None, complib: Union[str, NoneType] = None, append: bool = False, format: Union[str, NoneType] = None, index: bool = True, min_itemsize: Union[int, Dict[str, int], NoneType] = None, nan_rep=None, dropna: Union[bool, NoneType] = None, data_columns: Union[List[str], NoneType] = None, errors: str = 'strict', encoding: str = 'UTF-8') -> None\n",
      " |      Write the contained data to an HDF5 file using HDFStore.\n",
      " |      \n",
      " |      Hierarchical Data Format (HDF) is self-describing, allowing an\n",
      " |      application to interpret the structure and contents of a file with\n",
      " |      no outside information. One HDF file can hold a mix of related objects\n",
      " |      which can be accessed as a group or as individual objects.\n",
      " |      \n",
      " |      In order to add another DataFrame or Series to an existing HDF file\n",
      " |      please use append mode and a different a key.\n",
      " |      \n",
      " |      For more information see the :ref:`user guide <io.hdf5>`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : str or pandas.HDFStore\n",
      " |          File path or HDFStore object.\n",
      " |      key : str\n",
      " |          Identifier for the group in the store.\n",
      " |      mode : {'a', 'w', 'r+'}, default 'a'\n",
      " |          Mode to open file:\n",
      " |      \n",
      " |          - 'w': write, a new file is created (an existing file with\n",
      " |            the same name would be deleted).\n",
      " |          - 'a': append, an existing file is opened for reading and\n",
      " |            writing, and if the file does not exist it is created.\n",
      " |          - 'r+': similar to 'a', but the file must already exist.\n",
      " |      complevel : {0-9}, optional\n",
      " |          Specifies a compression level for data.\n",
      " |          A value of 0 disables compression.\n",
      " |      complib : {'zlib', 'lzo', 'bzip2', 'blosc'}, default 'zlib'\n",
      " |          Specifies the compression library to be used.\n",
      " |          As of v0.20.2 these additional compressors for Blosc are supported\n",
      " |          (default if no compressor specified: 'blosc:blosclz'):\n",
      " |          {'blosc:blosclz', 'blosc:lz4', 'blosc:lz4hc', 'blosc:snappy',\n",
      " |          'blosc:zlib', 'blosc:zstd'}.\n",
      " |          Specifying a compression library which is not available issues\n",
      " |          a ValueError.\n",
      " |      append : bool, default False\n",
      " |          For Table formats, append the input data to the existing.\n",
      " |      format : {'fixed', 'table', None}, default 'fixed'\n",
      " |          Possible values:\n",
      " |      \n",
      " |          - 'fixed': Fixed format. Fast writing/reading. Not-appendable,\n",
      " |            nor searchable.\n",
      " |          - 'table': Table format. Write as a PyTables Table structure\n",
      " |            which may perform worse but allow more flexible operations\n",
      " |            like searching / selecting subsets of the data.\n",
      " |          - If None, pd.get_option('io.hdf.default_format') is checked,\n",
      " |            followed by fallback to \"fixed\"\n",
      " |      errors : str, default 'strict'\n",
      " |          Specifies how encoding and decoding errors are to be handled.\n",
      " |          See the errors argument for :func:`open` for a full list\n",
      " |          of options.\n",
      " |      encoding : str, default \"UTF-8\"\n",
      " |      min_itemsize : dict or int, optional\n",
      " |          Map column names to minimum string sizes for columns.\n",
      " |      nan_rep : Any, optional\n",
      " |          How to represent null values as str.\n",
      " |          Not allowed with append=True.\n",
      " |      data_columns : list of columns or True, optional\n",
      " |          List of columns to create as indexed data columns for on-disk\n",
      " |          queries, or True to use all columns. By default only the axes\n",
      " |          of the object are indexed. See :ref:`io.hdf5-query-data-columns`.\n",
      " |          Applicable only to format='table'.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.read_hdf : Read from HDF file.\n",
      " |      DataFrame.to_parquet : Write a DataFrame to the binary parquet format.\n",
      " |      DataFrame.to_sql : Write to a sql table.\n",
      " |      DataFrame.to_feather : Write out feather-format for DataFrames.\n",
      " |      DataFrame.to_csv : Write out to a csv file.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]},\n",
      " |      ...                   index=['a', 'b', 'c'])\n",
      " |      >>> df.to_hdf('data.h5', key='df', mode='w')\n",
      " |      \n",
      " |      We can add another object to the same file:\n",
      " |      \n",
      " |      >>> s = pd.Series([1, 2, 3, 4])\n",
      " |      >>> s.to_hdf('data.h5', key='s')\n",
      " |      \n",
      " |      Reading from HDF file:\n",
      " |      \n",
      " |      >>> pd.read_hdf('data.h5', 'df')\n",
      " |      A  B\n",
      " |      a  1  4\n",
      " |      b  2  5\n",
      " |      c  3  6\n",
      " |      >>> pd.read_hdf('data.h5', 's')\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      3    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Deleting file with data:\n",
      " |      \n",
      " |      >>> import os\n",
      " |      >>> os.remove('data.h5')\n",
      " |  \n",
      " |  to_json(self, path_or_buf: Union[str, pathlib.Path, IO[~AnyStr], NoneType] = None, orient: Union[str, NoneType] = None, date_format: Union[str, NoneType] = None, double_precision: int = 10, force_ascii: bool = True, date_unit: str = 'ms', default_handler: Union[Callable[[Any], Union[str, int, float, bool, List, Dict]], NoneType] = None, lines: bool = False, compression: Union[str, NoneType] = 'infer', index: bool = True, indent: Union[int, NoneType] = None) -> Union[str, NoneType]\n",
      " |      Convert the object to a JSON string.\n",
      " |      \n",
      " |      Note NaN's and None will be converted to null and datetime objects\n",
      " |      will be converted to UNIX timestamps.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : str or file handle, optional\n",
      " |          File path or object. If not specified, the result is returned as\n",
      " |          a string.\n",
      " |      orient : str\n",
      " |          Indication of expected JSON string format.\n",
      " |      \n",
      " |          * Series:\n",
      " |      \n",
      " |              - default is 'index'\n",
      " |              - allowed values are: {'split','records','index','table'}.\n",
      " |      \n",
      " |          * DataFrame:\n",
      " |      \n",
      " |              - default is 'columns'\n",
      " |              - allowed values are: {'split', 'records', 'index', 'columns',\n",
      " |                'values', 'table'}.\n",
      " |      \n",
      " |          * The format of the JSON string:\n",
      " |      \n",
      " |              - 'split' : dict like {'index' -> [index], 'columns' -> [columns],\n",
      " |                'data' -> [values]}\n",
      " |              - 'records' : list like [{column -> value}, ... , {column -> value}]\n",
      " |              - 'index' : dict like {index -> {column -> value}}\n",
      " |              - 'columns' : dict like {column -> {index -> value}}\n",
      " |              - 'values' : just the values array\n",
      " |              - 'table' : dict like {'schema': {schema}, 'data': {data}}\n",
      " |      \n",
      " |              Describing the data, where data component is like ``orient='records'``.\n",
      " |      \n",
      " |          .. versionchanged:: 0.20.0\n",
      " |      \n",
      " |      date_format : {None, 'epoch', 'iso'}\n",
      " |          Type of date conversion. 'epoch' = epoch milliseconds,\n",
      " |          'iso' = ISO8601. The default depends on the `orient`. For\n",
      " |          ``orient='table'``, the default is 'iso'. For all other orients,\n",
      " |          the default is 'epoch'.\n",
      " |      double_precision : int, default 10\n",
      " |          The number of decimal places to use when encoding\n",
      " |          floating point values.\n",
      " |      force_ascii : bool, default True\n",
      " |          Force encoded string to be ASCII.\n",
      " |      date_unit : str, default 'ms' (milliseconds)\n",
      " |          The time unit to encode to, governs timestamp and ISO8601\n",
      " |          precision.  One of 's', 'ms', 'us', 'ns' for second, millisecond,\n",
      " |          microsecond, and nanosecond respectively.\n",
      " |      default_handler : callable, default None\n",
      " |          Handler to call if object cannot otherwise be converted to a\n",
      " |          suitable format for JSON. Should receive a single argument which is\n",
      " |          the object to convert and return a serialisable object.\n",
      " |      lines : bool, default False\n",
      " |          If 'orient' is 'records' write out line delimited json format. Will\n",
      " |          throw ValueError if incorrect 'orient' since others are not list\n",
      " |          like.\n",
      " |      \n",
      " |      compression : {'infer', 'gzip', 'bz2', 'zip', 'xz', None}\n",
      " |      \n",
      " |          A string representing the compression to use in the output file,\n",
      " |          only used when the first argument is a filename. By default, the\n",
      " |          compression is inferred from the filename.\n",
      " |      \n",
      " |          .. versionadded:: 0.21.0\n",
      " |          .. versionchanged:: 0.24.0\n",
      " |             'infer' option added and set to default\n",
      " |      index : bool, default True\n",
      " |          Whether to include the index values in the JSON string. Not\n",
      " |          including the index (``index=False``) is only supported when\n",
      " |          orient is 'split' or 'table'.\n",
      " |      \n",
      " |          .. versionadded:: 0.23.0\n",
      " |      \n",
      " |      indent : int, optional\n",
      " |         Length of whitespace used to indent each record.\n",
      " |      \n",
      " |         .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      None or str\n",
      " |          If path_or_buf is None, returns the resulting json format as a\n",
      " |          string. Otherwise returns None.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_json\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The behavior of ``indent=0`` varies from the stdlib, which does not\n",
      " |      indent the output but does insert newlines. Currently, ``indent=0``\n",
      " |      and the default ``indent=None`` are equivalent in pandas, though this\n",
      " |      may change in a future release.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([['a', 'b'], ['c', 'd']],\n",
      " |      ...                   index=['row 1', 'row 2'],\n",
      " |      ...                   columns=['col 1', 'col 2'])\n",
      " |      >>> df.to_json(orient='split')\n",
      " |      '{\"columns\":[\"col 1\",\"col 2\"],\n",
      " |        \"index\":[\"row 1\",\"row 2\"],\n",
      " |        \"data\":[[\"a\",\"b\"],[\"c\",\"d\"]]}'\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'records'`` formatted JSON.\n",
      " |      Note that index labels are not preserved with this encoding.\n",
      " |      \n",
      " |      >>> df.to_json(orient='records')\n",
      " |      '[{\"col 1\":\"a\",\"col 2\":\"b\"},{\"col 1\":\"c\",\"col 2\":\"d\"}]'\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'index'`` formatted JSON:\n",
      " |      \n",
      " |      >>> df.to_json(orient='index')\n",
      " |      '{\"row 1\":{\"col 1\":\"a\",\"col 2\":\"b\"},\"row 2\":{\"col 1\":\"c\",\"col 2\":\"d\"}}'\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'columns'`` formatted JSON:\n",
      " |      \n",
      " |      >>> df.to_json(orient='columns')\n",
      " |      '{\"col 1\":{\"row 1\":\"a\",\"row 2\":\"c\"},\"col 2\":{\"row 1\":\"b\",\"row 2\":\"d\"}}'\n",
      " |      \n",
      " |      Encoding/decoding a Dataframe using ``'values'`` formatted JSON:\n",
      " |      \n",
      " |      >>> df.to_json(orient='values')\n",
      " |      '[[\"a\",\"b\"],[\"c\",\"d\"]]'\n",
      " |      \n",
      " |      Encoding with Table Schema\n",
      " |      \n",
      " |      >>> df.to_json(orient='table')\n",
      " |      '{\"schema\": {\"fields\": [{\"name\": \"index\", \"type\": \"string\"},\n",
      " |                              {\"name\": \"col 1\", \"type\": \"string\"},\n",
      " |                              {\"name\": \"col 2\", \"type\": \"string\"}],\n",
      " |                   \"primaryKey\": \"index\",\n",
      " |                   \"pandas_version\": \"0.20.0\"},\n",
      " |        \"data\": [{\"index\": \"row 1\", \"col 1\": \"a\", \"col 2\": \"b\"},\n",
      " |                 {\"index\": \"row 2\", \"col 1\": \"c\", \"col 2\": \"d\"}]}'\n",
      " |  \n",
      " |  to_latex(self, buf=None, columns=None, col_space=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, bold_rows=False, column_format=None, longtable=None, escape=None, encoding=None, decimal='.', multicolumn=None, multicolumn_format=None, multirow=None, caption=None, label=None)\n",
      " |      Render object to a LaTeX tabular, longtable, or nested table/tabular.\n",
      " |      \n",
      " |      Requires ``\\usepackage{booktabs}``.  The output can be copy/pasted\n",
      " |      into a main LaTeX document or read from an external file\n",
      " |      with ``\\input{table.tex}``.\n",
      " |      \n",
      " |      .. versionchanged:: 0.20.2\n",
      " |         Added to Series.\n",
      " |      \n",
      " |      .. versionchanged:: 1.0.0\n",
      " |         Added caption and label arguments.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      buf : str, Path or StringIO-like, optional, default None\n",
      " |          Buffer to write to. If None, the output is returned as a string.\n",
      " |      columns : list of label, optional\n",
      " |          The subset of columns to write. Writes all columns by default.\n",
      " |      col_space : int, optional\n",
      " |          The minimum width of each column.\n",
      " |      header : bool or list of str, default True\n",
      " |          Write out the column names. If a list of strings is given,\n",
      " |          it is assumed to be aliases for the column names.\n",
      " |      index : bool, default True\n",
      " |          Write row names (index).\n",
      " |      na_rep : str, default 'NaN'\n",
      " |          Missing data representation.\n",
      " |      formatters : list of functions or dict of {str: function}, optional\n",
      " |          Formatter functions to apply to columns' elements by position or\n",
      " |          name. The result of each function must be a unicode string.\n",
      " |          List must be of length equal to the number of columns.\n",
      " |      float_format : one-parameter function or str, optional, default None\n",
      " |          Formatter for floating point numbers. For example\n",
      " |          ``float_format=\"%.2f\"`` and ``float_format=\"{:0.2f}\".format`` will\n",
      " |          both result in 0.1234 being formatted as 0.12.\n",
      " |      sparsify : bool, optional\n",
      " |          Set to False for a DataFrame with a hierarchical index to print\n",
      " |          every multiindex key at each row. By default, the value will be\n",
      " |          read from the config module.\n",
      " |      index_names : bool, default True\n",
      " |          Prints the names of the indexes.\n",
      " |      bold_rows : bool, default False\n",
      " |          Make the row labels bold in the output.\n",
      " |      column_format : str, optional\n",
      " |          The columns format as specified in `LaTeX table format\n",
      " |          <https://en.wikibooks.org/wiki/LaTeX/Tables>`__ e.g. 'rcl' for 3\n",
      " |          columns. By default, 'l' will be used for all columns except\n",
      " |          columns of numbers, which default to 'r'.\n",
      " |      longtable : bool, optional\n",
      " |          By default, the value will be read from the pandas config\n",
      " |          module. Use a longtable environment instead of tabular. Requires\n",
      " |          adding a \\usepackage{longtable} to your LaTeX preamble.\n",
      " |      escape : bool, optional\n",
      " |          By default, the value will be read from the pandas config\n",
      " |          module. When set to False prevents from escaping latex special\n",
      " |          characters in column names.\n",
      " |      encoding : str, optional\n",
      " |          A string representing the encoding to use in the output file,\n",
      " |          defaults to 'utf-8'.\n",
      " |      decimal : str, default '.'\n",
      " |          Character recognized as decimal separator, e.g. ',' in Europe.\n",
      " |      multicolumn : bool, default True\n",
      " |          Use \\multicolumn to enhance MultiIndex columns.\n",
      " |          The default will be read from the config module.\n",
      " |      multicolumn_format : str, default 'l'\n",
      " |          The alignment for multicolumns, similar to `column_format`\n",
      " |          The default will be read from the config module.\n",
      " |      multirow : bool, default False\n",
      " |          Use \\multirow to enhance MultiIndex rows. Requires adding a\n",
      " |          \\usepackage{multirow} to your LaTeX preamble. Will print\n",
      " |          centered labels (instead of top-aligned) across the contained\n",
      " |          rows, separating groups via clines. The default will be read\n",
      " |          from the pandas config module.\n",
      " |      caption : str, optional\n",
      " |          The LaTeX caption to be placed inside ``\\caption{}`` in the output.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      label : str, optional\n",
      " |          The LaTeX label to be placed inside ``\\label{}`` in the output.\n",
      " |          This is used with ``\\ref{}`` in the main ``.tex`` file.\n",
      " |      \n",
      " |          .. versionadded:: 1.0.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str or None\n",
      " |          If buf is None, returns the result as a string. Otherwise returns\n",
      " |          None.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.to_string : Render a DataFrame to a console-friendly\n",
      " |          tabular output.\n",
      " |      DataFrame.to_html : Render a DataFrame as an HTML table.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'name': ['Raphael', 'Donatello'],\n",
      " |      ...                    'mask': ['red', 'purple'],\n",
      " |      ...                    'weapon': ['sai', 'bo staff']})\n",
      " |      >>> print(df.to_latex(index=False))  # doctest: +NORMALIZE_WHITESPACE\n",
      " |      \\begin{tabular}{lll}\n",
      " |       \\toprule\n",
      " |             name &    mask &    weapon \\\\\n",
      " |       \\midrule\n",
      " |          Raphael &     red &       sai \\\\\n",
      " |        Donatello &  purple &  bo staff \\\\\n",
      " |      \\bottomrule\n",
      " |      \\end{tabular}\n",
      " |  \n",
      " |  to_pickle(self, path, compression: Union[str, NoneType] = 'infer', protocol: int = 5) -> None\n",
      " |      Pickle (serialize) object to file.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : str\n",
      " |          File path where the pickled object will be stored.\n",
      " |      compression : {'infer', 'gzip', 'bz2', 'zip', 'xz', None},         default 'infer'\n",
      " |          A string representing the compression to use in the output file. By\n",
      " |          default, infers from the file extension in specified path.\n",
      " |      protocol : int\n",
      " |          Int which indicates which protocol should be used by the pickler,\n",
      " |          default HIGHEST_PROTOCOL (see [1]_ paragraph 12.1.2). The possible\n",
      " |          values are 0, 1, 2, 3, 4. A negative value for the protocol\n",
      " |          parameter is equivalent to setting its value to HIGHEST_PROTOCOL.\n",
      " |      \n",
      " |          .. [1] https://docs.python.org/3/library/pickle.html.\n",
      " |          .. versionadded:: 0.21.0.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_pickle : Load pickled pandas object (or any object) from file.\n",
      " |      DataFrame.to_hdf : Write DataFrame to an HDF5 file.\n",
      " |      DataFrame.to_sql : Write DataFrame to a SQL database.\n",
      " |      DataFrame.to_parquet : Write a DataFrame to the binary parquet format.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> original_df = pd.DataFrame({\"foo\": range(5), \"bar\": range(5, 10)})\n",
      " |      >>> original_df\n",
      " |         foo  bar\n",
      " |      0    0    5\n",
      " |      1    1    6\n",
      " |      2    2    7\n",
      " |      3    3    8\n",
      " |      4    4    9\n",
      " |      >>> original_df.to_pickle(\"./dummy.pkl\")\n",
      " |      \n",
      " |      >>> unpickled_df = pd.read_pickle(\"./dummy.pkl\")\n",
      " |      >>> unpickled_df\n",
      " |         foo  bar\n",
      " |      0    0    5\n",
      " |      1    1    6\n",
      " |      2    2    7\n",
      " |      3    3    8\n",
      " |      4    4    9\n",
      " |      \n",
      " |      >>> import os\n",
      " |      >>> os.remove(\"./dummy.pkl\")\n",
      " |  \n",
      " |  to_sql(self, name: str, con, schema=None, if_exists: str = 'fail', index: bool = True, index_label=None, chunksize=None, dtype=None, method=None) -> None\n",
      " |      Write records stored in a DataFrame to a SQL database.\n",
      " |      \n",
      " |      Databases supported by SQLAlchemy [1]_ are supported. Tables can be\n",
      " |      newly created, appended to, or overwritten.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : str\n",
      " |          Name of SQL table.\n",
      " |      con : sqlalchemy.engine.Engine or sqlite3.Connection\n",
      " |          Using SQLAlchemy makes it possible to use any DB supported by that\n",
      " |          library. Legacy support is provided for sqlite3.Connection objects. The user\n",
      " |          is responsible for engine disposal and connection closure for the SQLAlchemy\n",
      " |          connectable See `here                 <https://docs.sqlalchemy.org/en/13/core/connections.html>`_\n",
      " |      \n",
      " |      schema : str, optional\n",
      " |          Specify the schema (if database flavor supports this). If None, use\n",
      " |          default schema.\n",
      " |      if_exists : {'fail', 'replace', 'append'}, default 'fail'\n",
      " |          How to behave if the table already exists.\n",
      " |      \n",
      " |          * fail: Raise a ValueError.\n",
      " |          * replace: Drop the table before inserting new values.\n",
      " |          * append: Insert new values to the existing table.\n",
      " |      \n",
      " |      index : bool, default True\n",
      " |          Write DataFrame index as a column. Uses `index_label` as the column\n",
      " |          name in the table.\n",
      " |      index_label : str or sequence, default None\n",
      " |          Column label for index column(s). If None is given (default) and\n",
      " |          `index` is True, then the index names are used.\n",
      " |          A sequence should be given if the DataFrame uses MultiIndex.\n",
      " |      chunksize : int, optional\n",
      " |          Specify the number of rows in each batch to be written at a time.\n",
      " |          By default, all rows will be written at once.\n",
      " |      dtype : dict or scalar, optional\n",
      " |          Specifying the datatype for columns. If a dictionary is used, the\n",
      " |          keys should be the column names and the values should be the\n",
      " |          SQLAlchemy types or strings for the sqlite3 legacy mode. If a\n",
      " |          scalar is provided, it will be applied to all columns.\n",
      " |      method : {None, 'multi', callable}, optional\n",
      " |          Controls the SQL insertion clause used:\n",
      " |      \n",
      " |          * None : Uses standard SQL ``INSERT`` clause (one per row).\n",
      " |          * 'multi': Pass multiple values in a single ``INSERT`` clause.\n",
      " |          * callable with signature ``(pd_table, conn, keys, data_iter)``.\n",
      " |      \n",
      " |          Details and a sample callable implementation can be found in the\n",
      " |          section :ref:`insert method <io.sql.method>`.\n",
      " |      \n",
      " |          .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          When the table already exists and `if_exists` is 'fail' (the\n",
      " |          default).\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      read_sql : Read a DataFrame from a table.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Timezone aware datetime columns will be written as\n",
      " |      ``Timestamp with timezone`` type with SQLAlchemy if supported by the\n",
      " |      database. Otherwise, the datetimes will be stored as timezone unaware\n",
      " |      timestamps local to the original timezone.\n",
      " |      \n",
      " |      .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] http://docs.sqlalchemy.org\n",
      " |      .. [2] https://www.python.org/dev/peps/pep-0249/\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Create an in-memory SQLite database.\n",
      " |      \n",
      " |      >>> from sqlalchemy import create_engine\n",
      " |      >>> engine = create_engine('sqlite://', echo=False)\n",
      " |      \n",
      " |      Create a table from scratch with 3 rows.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({'name' : ['User 1', 'User 2', 'User 3']})\n",
      " |      >>> df\n",
      " |           name\n",
      " |      0  User 1\n",
      " |      1  User 2\n",
      " |      2  User 3\n",
      " |      \n",
      " |      >>> df.to_sql('users', con=engine)\n",
      " |      >>> engine.execute(\"SELECT * FROM users\").fetchall()\n",
      " |      [(0, 'User 1'), (1, 'User 2'), (2, 'User 3')]\n",
      " |      \n",
      " |      >>> df1 = pd.DataFrame({'name' : ['User 4', 'User 5']})\n",
      " |      >>> df1.to_sql('users', con=engine, if_exists='append')\n",
      " |      >>> engine.execute(\"SELECT * FROM users\").fetchall()\n",
      " |      [(0, 'User 1'), (1, 'User 2'), (2, 'User 3'),\n",
      " |       (0, 'User 4'), (1, 'User 5')]\n",
      " |      \n",
      " |      Overwrite the table with just ``df1``.\n",
      " |      \n",
      " |      >>> df1.to_sql('users', con=engine, if_exists='replace',\n",
      " |      ...            index_label='id')\n",
      " |      >>> engine.execute(\"SELECT * FROM users\").fetchall()\n",
      " |      [(0, 'User 4'), (1, 'User 5')]\n",
      " |      \n",
      " |      Specify the dtype (especially useful for integers with missing values).\n",
      " |      Notice that while pandas is forced to store the data as floating point,\n",
      " |      the database supports nullable integers. When fetching the data with\n",
      " |      Python, we get back integer scalars.\n",
      " |      \n",
      " |      >>> df = pd.DataFrame({\"A\": [1, None, 2]})\n",
      " |      >>> df\n",
      " |           A\n",
      " |      0  1.0\n",
      " |      1  NaN\n",
      " |      2  2.0\n",
      " |      \n",
      " |      >>> from sqlalchemy.types import Integer\n",
      " |      >>> df.to_sql('integers', con=engine, index=False,\n",
      " |      ...           dtype={\"A\": Integer()})\n",
      " |      \n",
      " |      >>> engine.execute(\"SELECT * FROM integers\").fetchall()\n",
      " |      [(1,), (None,), (2,)]\n",
      " |  \n",
      " |  to_xarray(self)\n",
      " |      Return an xarray object from the pandas object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      xarray.DataArray or xarray.Dataset\n",
      " |          Data in the pandas structure converted to Dataset if the object is\n",
      " |          a DataFrame, or a DataArray if the object is a Series.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.to_hdf : Write DataFrame to an HDF5 file.\n",
      " |      DataFrame.to_parquet : Write a DataFrame to the binary parquet format.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      See the `xarray docs <http://xarray.pydata.org/en/stable/>`__\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([('falcon', 'bird', 389.0, 2),\n",
      " |      ...                    ('parrot', 'bird', 24.0, 2),\n",
      " |      ...                    ('lion', 'mammal', 80.5, 4),\n",
      " |      ...                    ('monkey', 'mammal', np.nan, 4)],\n",
      " |      ...                   columns=['name', 'class', 'max_speed',\n",
      " |      ...                            'num_legs'])\n",
      " |      >>> df\n",
      " |           name   class  max_speed  num_legs\n",
      " |      0  falcon    bird      389.0         2\n",
      " |      1  parrot    bird       24.0         2\n",
      " |      2    lion  mammal       80.5         4\n",
      " |      3  monkey  mammal        NaN         4\n",
      " |      \n",
      " |      >>> df.to_xarray()\n",
      " |      <xarray.Dataset>\n",
      " |      Dimensions:    (index: 4)\n",
      " |      Coordinates:\n",
      " |        * index      (index) int64 0 1 2 3\n",
      " |      Data variables:\n",
      " |          name       (index) object 'falcon' 'parrot' 'lion' 'monkey'\n",
      " |          class      (index) object 'bird' 'bird' 'mammal' 'mammal'\n",
      " |          max_speed  (index) float64 389.0 24.0 80.5 nan\n",
      " |          num_legs   (index) int64 2 2 4 4\n",
      " |      \n",
      " |      >>> df['max_speed'].to_xarray()\n",
      " |      <xarray.DataArray 'max_speed' (index: 4)>\n",
      " |      array([389. ,  24. ,  80.5,   nan])\n",
      " |      Coordinates:\n",
      " |        * index    (index) int64 0 1 2 3\n",
      " |      \n",
      " |      >>> dates = pd.to_datetime(['2018-01-01', '2018-01-01',\n",
      " |      ...                         '2018-01-02', '2018-01-02'])\n",
      " |      >>> df_multiindex = pd.DataFrame({'date': dates,\n",
      " |      ...                               'animal': ['falcon', 'parrot',\n",
      " |      ...                                          'falcon', 'parrot'],\n",
      " |      ...                               'speed': [350, 18, 361, 15]})\n",
      " |      >>> df_multiindex = df_multiindex.set_index(['date', 'animal'])\n",
      " |      \n",
      " |      >>> df_multiindex\n",
      " |                         speed\n",
      " |      date       animal\n",
      " |      2018-01-01 falcon    350\n",
      " |                 parrot     18\n",
      " |      2018-01-02 falcon    361\n",
      " |                 parrot     15\n",
      " |      \n",
      " |      >>> df_multiindex.to_xarray()\n",
      " |      <xarray.Dataset>\n",
      " |      Dimensions:  (animal: 2, date: 2)\n",
      " |      Coordinates:\n",
      " |        * date     (date) datetime64[ns] 2018-01-01 2018-01-02\n",
      " |        * animal   (animal) object 'falcon' 'parrot'\n",
      " |      Data variables:\n",
      " |          speed    (date, animal) int64 350 18 361 15\n",
      " |  \n",
      " |  truncate(self: ~FrameOrSeries, before=None, after=None, axis=None, copy: bool = True) -> ~FrameOrSeries\n",
      " |      Truncate a Series or DataFrame before and after some index value.\n",
      " |      \n",
      " |      This is a useful shorthand for boolean indexing based on index\n",
      " |      values above or below certain thresholds.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      before : date, str, int\n",
      " |          Truncate all rows before this index value.\n",
      " |      after : date, str, int\n",
      " |          Truncate all rows after this index value.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, optional\n",
      " |          Axis to truncate. Truncates the index (rows) by default.\n",
      " |      copy : bool, default is True,\n",
      " |          Return a copy of the truncated section.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of caller\n",
      " |          The truncated Series or DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Select a subset of a DataFrame by label.\n",
      " |      DataFrame.iloc : Select a subset of a DataFrame by position.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If the index being truncated contains only datetime values,\n",
      " |      `before` and `after` may be specified as strings instead of\n",
      " |      Timestamps.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'A': ['a', 'b', 'c', 'd', 'e'],\n",
      " |      ...                    'B': ['f', 'g', 'h', 'i', 'j'],\n",
      " |      ...                    'C': ['k', 'l', 'm', 'n', 'o']},\n",
      " |      ...                   index=[1, 2, 3, 4, 5])\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |      1  a  f  k\n",
      " |      2  b  g  l\n",
      " |      3  c  h  m\n",
      " |      4  d  i  n\n",
      " |      5  e  j  o\n",
      " |      \n",
      " |      >>> df.truncate(before=2, after=4)\n",
      " |         A  B  C\n",
      " |      2  b  g  l\n",
      " |      3  c  h  m\n",
      " |      4  d  i  n\n",
      " |      \n",
      " |      The columns of a DataFrame can be truncated.\n",
      " |      \n",
      " |      >>> df.truncate(before=\"A\", after=\"B\", axis=\"columns\")\n",
      " |         A  B\n",
      " |      1  a  f\n",
      " |      2  b  g\n",
      " |      3  c  h\n",
      " |      4  d  i\n",
      " |      5  e  j\n",
      " |      \n",
      " |      For Series, only rows can be truncated.\n",
      " |      \n",
      " |      >>> df['A'].truncate(before=2, after=4)\n",
      " |      2    b\n",
      " |      3    c\n",
      " |      4    d\n",
      " |      Name: A, dtype: object\n",
      " |      \n",
      " |      The index values in ``truncate`` can be datetimes or string\n",
      " |      dates.\n",
      " |      \n",
      " |      >>> dates = pd.date_range('2016-01-01', '2016-02-01', freq='s')\n",
      " |      >>> df = pd.DataFrame(index=dates, data={'A': 1})\n",
      " |      >>> df.tail()\n",
      " |                           A\n",
      " |      2016-01-31 23:59:56  1\n",
      " |      2016-01-31 23:59:57  1\n",
      " |      2016-01-31 23:59:58  1\n",
      " |      2016-01-31 23:59:59  1\n",
      " |      2016-02-01 00:00:00  1\n",
      " |      \n",
      " |      >>> df.truncate(before=pd.Timestamp('2016-01-05'),\n",
      " |      ...             after=pd.Timestamp('2016-01-10')).tail()\n",
      " |                           A\n",
      " |      2016-01-09 23:59:56  1\n",
      " |      2016-01-09 23:59:57  1\n",
      " |      2016-01-09 23:59:58  1\n",
      " |      2016-01-09 23:59:59  1\n",
      " |      2016-01-10 00:00:00  1\n",
      " |      \n",
      " |      Because the index is a DatetimeIndex containing only dates, we can\n",
      " |      specify `before` and `after` as strings. They will be coerced to\n",
      " |      Timestamps before truncation.\n",
      " |      \n",
      " |      >>> df.truncate('2016-01-05', '2016-01-10').tail()\n",
      " |                           A\n",
      " |      2016-01-09 23:59:56  1\n",
      " |      2016-01-09 23:59:57  1\n",
      " |      2016-01-09 23:59:58  1\n",
      " |      2016-01-09 23:59:59  1\n",
      " |      2016-01-10 00:00:00  1\n",
      " |      \n",
      " |      Note that ``truncate`` assumes a 0 value for any unspecified time\n",
      " |      component (midnight). This differs from partial string slicing, which\n",
      " |      returns any partially matching dates.\n",
      " |      \n",
      " |      >>> df.loc['2016-01-05':'2016-01-10', :].tail()\n",
      " |                           A\n",
      " |      2016-01-10 23:59:55  1\n",
      " |      2016-01-10 23:59:56  1\n",
      " |      2016-01-10 23:59:57  1\n",
      " |      2016-01-10 23:59:58  1\n",
      " |      2016-01-10 23:59:59  1\n",
      " |  \n",
      " |  tshift(self: ~FrameOrSeries, periods: int = 1, freq=None, axis=0) -> ~FrameOrSeries\n",
      " |      Shift the time index, using the index's frequency if available.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative.\n",
      " |      freq : DateOffset, timedelta, or str, default None\n",
      " |          Increment to use from the tseries module\n",
      " |          or time rule expressed as a string (e.g. 'EOM').\n",
      " |      axis : {0 or ‘index’, 1 or ‘columns’, None}, default 0\n",
      " |          Corresponds to the axis that contains the Index.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : Series/DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If freq is not specified then tries to use the freq or inferred_freq\n",
      " |      attributes of the index. If neither of those attributes exist, a\n",
      " |      ValueError is thrown\n",
      " |  \n",
      " |  tz_convert(self: ~FrameOrSeries, tz, axis=0, level=None, copy: bool = True) -> ~FrameOrSeries\n",
      " |      Convert tz-aware axis to target time zone.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      tz : str or tzinfo object\n",
      " |      axis : the axis to convert\n",
      " |      level : int, str, default None\n",
      " |          If axis is a MultiIndex, convert a specific level. Otherwise\n",
      " |          must be None.\n",
      " |      copy : bool, default True\n",
      " |          Also make a copy of the underlying data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      %(klass)s\n",
      " |          Object with time zone converted axis.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the axis is tz-naive.\n",
      " |  \n",
      " |  tz_localize(self: ~FrameOrSeries, tz, axis=0, level=None, copy: bool = True, ambiguous='raise', nonexistent: str = 'raise') -> ~FrameOrSeries\n",
      " |      Localize tz-naive index of a Series or DataFrame to target time zone.\n",
      " |      \n",
      " |      This operation localizes the Index. To localize the values in a\n",
      " |      timezone-naive Series, use :meth:`Series.dt.tz_localize`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      tz : str or tzinfo\n",
      " |      axis : the axis to localize\n",
      " |      level : int, str, default None\n",
      " |          If axis ia a MultiIndex, localize a specific level. Otherwise\n",
      " |          must be None.\n",
      " |      copy : bool, default True\n",
      " |          Also make a copy of the underlying data.\n",
      " |      ambiguous : 'infer', bool-ndarray, 'NaT', default 'raise'\n",
      " |          When clocks moved backward due to DST, ambiguous times may arise.\n",
      " |          For example in Central European Time (UTC+01), when going from\n",
      " |          03:00 DST to 02:00 non-DST, 02:30:00 local time occurs both at\n",
      " |          00:30:00 UTC and at 01:30:00 UTC. In such a situation, the\n",
      " |          `ambiguous` parameter dictates how ambiguous times should be\n",
      " |          handled.\n",
      " |      \n",
      " |          - 'infer' will attempt to infer fall dst-transition hours based on\n",
      " |            order\n",
      " |          - bool-ndarray where True signifies a DST time, False designates\n",
      " |            a non-DST time (note that this flag is only applicable for\n",
      " |            ambiguous times)\n",
      " |          - 'NaT' will return NaT where there are ambiguous times\n",
      " |          - 'raise' will raise an AmbiguousTimeError if there are ambiguous\n",
      " |            times.\n",
      " |      nonexistent : str, default 'raise'\n",
      " |          A nonexistent time does not exist in a particular timezone\n",
      " |          where clocks moved forward due to DST. Valid values are:\n",
      " |      \n",
      " |          - 'shift_forward' will shift the nonexistent time forward to the\n",
      " |            closest existing time\n",
      " |          - 'shift_backward' will shift the nonexistent time backward to the\n",
      " |            closest existing time\n",
      " |          - 'NaT' will return NaT where there are nonexistent times\n",
      " |          - timedelta objects will shift nonexistent times by the timedelta\n",
      " |          - 'raise' will raise an NonExistentTimeError if there are\n",
      " |            nonexistent times.\n",
      " |      \n",
      " |          .. versionadded:: 0.24.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Same type as the input.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the TimeSeries is tz-aware and tz is not None.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Localize local times:\n",
      " |      \n",
      " |      >>> s = pd.Series([1],\n",
      " |      ...               index=pd.DatetimeIndex(['2018-09-15 01:30:00']))\n",
      " |      >>> s.tz_localize('CET')\n",
      " |      2018-09-15 01:30:00+02:00    1\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      Be careful with DST changes. When there is sequential data, pandas\n",
      " |      can infer the DST time:\n",
      " |      \n",
      " |      >>> s = pd.Series(range(7),\n",
      " |      ...               index=pd.DatetimeIndex(['2018-10-28 01:30:00',\n",
      " |      ...                                       '2018-10-28 02:00:00',\n",
      " |      ...                                       '2018-10-28 02:30:00',\n",
      " |      ...                                       '2018-10-28 02:00:00',\n",
      " |      ...                                       '2018-10-28 02:30:00',\n",
      " |      ...                                       '2018-10-28 03:00:00',\n",
      " |      ...                                       '2018-10-28 03:30:00']))\n",
      " |      >>> s.tz_localize('CET', ambiguous='infer')\n",
      " |      2018-10-28 01:30:00+02:00    0\n",
      " |      2018-10-28 02:00:00+02:00    1\n",
      " |      2018-10-28 02:30:00+02:00    2\n",
      " |      2018-10-28 02:00:00+01:00    3\n",
      " |      2018-10-28 02:30:00+01:00    4\n",
      " |      2018-10-28 03:00:00+01:00    5\n",
      " |      2018-10-28 03:30:00+01:00    6\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      In some cases, inferring the DST is impossible. In such cases, you can\n",
      " |      pass an ndarray to the ambiguous parameter to set the DST explicitly\n",
      " |      \n",
      " |      >>> s = pd.Series(range(3),\n",
      " |      ...               index=pd.DatetimeIndex(['2018-10-28 01:20:00',\n",
      " |      ...                                       '2018-10-28 02:36:00',\n",
      " |      ...                                       '2018-10-28 03:46:00']))\n",
      " |      >>> s.tz_localize('CET', ambiguous=np.array([True, True, False]))\n",
      " |      2018-10-28 01:20:00+02:00    0\n",
      " |      2018-10-28 02:36:00+02:00    1\n",
      " |      2018-10-28 03:46:00+01:00    2\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      If the DST transition causes nonexistent times, you can shift these\n",
      " |      dates forward or backwards with a timedelta object or `'shift_forward'`\n",
      " |      or `'shift_backwards'`.\n",
      " |      >>> s = pd.Series(range(2),\n",
      " |      ...               index=pd.DatetimeIndex(['2015-03-29 02:30:00',\n",
      " |      ...                                       '2015-03-29 03:30:00']))\n",
      " |      >>> s.tz_localize('Europe/Warsaw', nonexistent='shift_forward')\n",
      " |      2015-03-29 03:00:00+02:00    0\n",
      " |      2015-03-29 03:30:00+02:00    1\n",
      " |      dtype: int64\n",
      " |      >>> s.tz_localize('Europe/Warsaw', nonexistent='shift_backward')\n",
      " |      2015-03-29 01:59:59.999999999+01:00    0\n",
      " |      2015-03-29 03:30:00+02:00              1\n",
      " |      dtype: int64\n",
      " |      >>> s.tz_localize('Europe/Warsaw', nonexistent=pd.Timedelta('1H'))\n",
      " |      2015-03-29 03:30:00+02:00    0\n",
      " |      2015-03-29 03:30:00+02:00    1\n",
      " |      dtype: int64\n",
      " |  \n",
      " |  where(self, cond, other=nan, inplace=False, axis=None, level=None, errors='raise', try_cast=False)\n",
      " |      Replace values where the condition is False.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      cond : bool Series/DataFrame, array-like, or callable\n",
      " |          Where `cond` is True, keep the original value. Where\n",
      " |          False, replace with corresponding value from `other`.\n",
      " |          If `cond` is callable, it is computed on the Series/DataFrame and\n",
      " |          should return boolean Series/DataFrame or array. The callable must\n",
      " |          not change input Series/DataFrame (though pandas doesn't check it).\n",
      " |      other : scalar, Series/DataFrame, or callable\n",
      " |          Entries where `cond` is False are replaced with\n",
      " |          corresponding value from `other`.\n",
      " |          If other is callable, it is computed on the Series/DataFrame and\n",
      " |          should return scalar or Series/DataFrame. The callable must not\n",
      " |          change input Series/DataFrame (though pandas doesn't check it).\n",
      " |      inplace : bool, default False\n",
      " |          Whether to perform the operation in place on the data.\n",
      " |      axis : int, default None\n",
      " |          Alignment axis if needed.\n",
      " |      level : int, default None\n",
      " |          Alignment level if needed.\n",
      " |      errors : str, {'raise', 'ignore'}, default 'raise'\n",
      " |          Note that currently this parameter won't affect\n",
      " |          the results and will always coerce to a suitable dtype.\n",
      " |      \n",
      " |          - 'raise' : allow exceptions to be raised.\n",
      " |          - 'ignore' : suppress exceptions. On error return original object.\n",
      " |      \n",
      " |      try_cast : bool, default False\n",
      " |          Try to cast the result back to the input type (if possible).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Same type as caller\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :func:`DataFrame.mask` : Return an object of same shape as\n",
      " |          self.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The where method is an application of the if-then idiom. For each\n",
      " |      element in the calling DataFrame, if ``cond`` is ``True`` the\n",
      " |      element is used; otherwise the corresponding element from the DataFrame\n",
      " |      ``other`` is used.\n",
      " |      \n",
      " |      The signature for :func:`DataFrame.where` differs from\n",
      " |      :func:`numpy.where`. Roughly ``df1.where(m, df2)`` is equivalent to\n",
      " |      ``np.where(m, df1, df2)``.\n",
      " |      \n",
      " |      For further details and examples see the ``where`` documentation in\n",
      " |      :ref:`indexing <indexing.where_mask>`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(range(5))\n",
      " |      >>> s.where(s > 0)\n",
      " |      0    NaN\n",
      " |      1    1.0\n",
      " |      2    2.0\n",
      " |      3    3.0\n",
      " |      4    4.0\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.mask(s > 0)\n",
      " |      0    0.0\n",
      " |      1    NaN\n",
      " |      2    NaN\n",
      " |      3    NaN\n",
      " |      4    NaN\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.where(s > 1, 10)\n",
      " |      0    10\n",
      " |      1    10\n",
      " |      2    2\n",
      " |      3    3\n",
      " |      4    4\n",
      " |      dtype: int64\n",
      " |      \n",
      " |      >>> df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  0  1\n",
      " |      1  2  3\n",
      " |      2  4  5\n",
      " |      3  6  7\n",
      " |      4  8  9\n",
      " |      >>> m = df % 3 == 0\n",
      " |      >>> df.where(m, -df)\n",
      " |         A  B\n",
      " |      0  0 -1\n",
      " |      1 -2  3\n",
      " |      2 -4 -5\n",
      " |      3  6 -7\n",
      " |      4 -8  9\n",
      " |      >>> df.where(m, -df) == np.where(m, df, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |      >>> df.where(m, -df) == df.mask(~m, -df)\n",
      " |            A     B\n",
      " |      0  True  True\n",
      " |      1  True  True\n",
      " |      2  True  True\n",
      " |      3  True  True\n",
      " |      4  True  True\n",
      " |  \n",
      " |  xs(self, key, axis=0, level=None, drop_level: bool = True)\n",
      " |      Return cross-section from the Series/DataFrame.\n",
      " |      \n",
      " |      This method takes a `key` argument to select data at a particular\n",
      " |      level of a MultiIndex.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : label or tuple of label\n",
      " |          Label contained in the index, or partially in a MultiIndex.\n",
      " |      axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      " |          Axis to retrieve cross-section on.\n",
      " |      level : object, defaults to first n levels (n=1 or len(key))\n",
      " |          In case of a key partially contained in a MultiIndex, indicate\n",
      " |          which levels are used. Levels can be referred by label or position.\n",
      " |      drop_level : bool, default True\n",
      " |          If False, returns object with same levels as self.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame\n",
      " |          Cross-section from the original Series or DataFrame\n",
      " |          corresponding to the selected index levels.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.loc : Access a group of rows and columns\n",
      " |          by label(s) or a boolean array.\n",
      " |      DataFrame.iloc : Purely integer-location based indexing\n",
      " |          for selection by position.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      `xs` can not be used to set values.\n",
      " |      \n",
      " |      MultiIndex Slicers is a generic way to get/set values on\n",
      " |      any level or levels.\n",
      " |      It is a superset of `xs` functionality, see\n",
      " |      :ref:`MultiIndex Slicers <advanced.mi_slicers>`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> d = {'num_legs': [4, 4, 2, 2],\n",
      " |      ...      'num_wings': [0, 0, 2, 2],\n",
      " |      ...      'class': ['mammal', 'mammal', 'mammal', 'bird'],\n",
      " |      ...      'animal': ['cat', 'dog', 'bat', 'penguin'],\n",
      " |      ...      'locomotion': ['walks', 'walks', 'flies', 'walks']}\n",
      " |      >>> df = pd.DataFrame(data=d)\n",
      " |      >>> df = df.set_index(['class', 'animal', 'locomotion'])\n",
      " |      >>> df\n",
      " |                                 num_legs  num_wings\n",
      " |      class  animal  locomotion\n",
      " |      mammal cat     walks              4          0\n",
      " |             dog     walks              4          0\n",
      " |             bat     flies              2          2\n",
      " |      bird   penguin walks              2          2\n",
      " |      \n",
      " |      Get values at specified index\n",
      " |      \n",
      " |      >>> df.xs('mammal')\n",
      " |                         num_legs  num_wings\n",
      " |      animal locomotion\n",
      " |      cat    walks              4          0\n",
      " |      dog    walks              4          0\n",
      " |      bat    flies              2          2\n",
      " |      \n",
      " |      Get values at several indexes\n",
      " |      \n",
      " |      >>> df.xs(('mammal', 'dog'))\n",
      " |                  num_legs  num_wings\n",
      " |      locomotion\n",
      " |      walks              4          0\n",
      " |      \n",
      " |      Get values at specified index and level\n",
      " |      \n",
      " |      >>> df.xs('cat', level=1)\n",
      " |                         num_legs  num_wings\n",
      " |      class  locomotion\n",
      " |      mammal walks              4          0\n",
      " |      \n",
      " |      Get values at several indexes and levels\n",
      " |      \n",
      " |      >>> df.xs(('bird', 'walks'),\n",
      " |      ...       level=[0, 'locomotion'])\n",
      " |               num_legs  num_wings\n",
      " |      animal\n",
      " |      penguin         2          2\n",
      " |      \n",
      " |      Get values at specified column and axis\n",
      " |      \n",
      " |      >>> df.xs('num_wings', axis=1)\n",
      " |      class   animal   locomotion\n",
      " |      mammal  cat      walks         0\n",
      " |              dog      walks         0\n",
      " |              bat      flies         2\n",
      " |      bird    penguin  walks         2\n",
      " |      Name: num_wings, dtype: int64\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  attrs\n",
      " |      Dictionary of global attributes on this object.\n",
      " |      \n",
      " |      .. warning::\n",
      " |      \n",
      " |         attrs is experimental and may change without warning.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.PandasObject:\n",
      " |  \n",
      " |  __sizeof__(self)\n",
      " |      Generates the total memory usage for an object that returns\n",
      " |      either a value or Series of values\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.accessor.DirNamesMixin:\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      Provide method name lookup and completion.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Only provide 'public' methods.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from pandas.core.indexing.IndexingMixin:\n",
      " |  \n",
      " |  at\n",
      " |      Access a single value for a row/column label pair.\n",
      " |      \n",
      " |      Similar to ``loc``, in that both provide label-based lookups. Use\n",
      " |      ``at`` if you only need to get or set a single value in a DataFrame\n",
      " |      or Series.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError\n",
      " |          If 'label' does not exist in DataFrame.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.iat : Access a single value for a row/column pair by integer\n",
      " |          position.\n",
      " |      DataFrame.loc : Access a group of rows and columns by label(s).\n",
      " |      Series.at : Access a single value using a label.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],\n",
      " |      ...                   index=[4, 5, 6], columns=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |          A   B   C\n",
      " |      4   0   2   3\n",
      " |      5   0   4   1\n",
      " |      6  10  20  30\n",
      " |      \n",
      " |      Get value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.at[4, 'B']\n",
      " |      2\n",
      " |      \n",
      " |      Set value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.at[4, 'B'] = 10\n",
      " |      >>> df.at[4, 'B']\n",
      " |      10\n",
      " |      \n",
      " |      Get value within a Series\n",
      " |      \n",
      " |      >>> df.loc[5].at['B']\n",
      " |      4\n",
      " |  \n",
      " |  iat\n",
      " |      Access a single value for a row/column pair by integer position.\n",
      " |      \n",
      " |      Similar to ``iloc``, in that both provide integer-based lookups. Use\n",
      " |      ``iat`` if you only need to get or set a single value in a DataFrame\n",
      " |      or Series.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      IndexError\n",
      " |          When integer position is out of bounds.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.at : Access a single value for a row/column label pair.\n",
      " |      DataFrame.loc : Access a group of rows and columns by label(s).\n",
      " |      DataFrame.iloc : Access a group of rows and columns by integer position(s).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],\n",
      " |      ...                   columns=['A', 'B', 'C'])\n",
      " |      >>> df\n",
      " |          A   B   C\n",
      " |      0   0   2   3\n",
      " |      1   0   4   1\n",
      " |      2  10  20  30\n",
      " |      \n",
      " |      Get value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.iat[1, 2]\n",
      " |      1\n",
      " |      \n",
      " |      Set value at specified row/column pair\n",
      " |      \n",
      " |      >>> df.iat[1, 2] = 10\n",
      " |      >>> df.iat[1, 2]\n",
      " |      10\n",
      " |      \n",
      " |      Get value within a series\n",
      " |      \n",
      " |      >>> df.loc[0].iat[1]\n",
      " |      2\n",
      " |  \n",
      " |  iloc\n",
      " |      Purely integer-location based indexing for selection by position.\n",
      " |      \n",
      " |      ``.iloc[]`` is primarily integer position based (from ``0`` to\n",
      " |      ``length-1`` of the axis), but may also be used with a boolean\n",
      " |      array.\n",
      " |      \n",
      " |      Allowed inputs are:\n",
      " |      \n",
      " |      - An integer, e.g. ``5``.\n",
      " |      - A list or array of integers, e.g. ``[4, 3, 0]``.\n",
      " |      - A slice object with ints, e.g. ``1:7``.\n",
      " |      - A boolean array.\n",
      " |      - A ``callable`` function with one argument (the calling Series or\n",
      " |        DataFrame) and that returns valid output for indexing (one of the above).\n",
      " |        This is useful in method chains, when you don't have a reference to the\n",
      " |        calling object, but would like to base your selection on some value.\n",
      " |      \n",
      " |      ``.iloc`` will raise ``IndexError`` if a requested indexer is\n",
      " |      out-of-bounds, except *slice* indexers which allow out-of-bounds\n",
      " |      indexing (this conforms with python/numpy *slice* semantics).\n",
      " |      \n",
      " |      See more at :ref:`Selection by Position <indexing.integer>`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.iat : Fast integer location scalar accessor.\n",
      " |      DataFrame.loc : Purely label-location based indexer for selection by label.\n",
      " |      Series.iloc : Purely integer-location based indexing for\n",
      " |                     selection by position.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> mydict = [{'a': 1, 'b': 2, 'c': 3, 'd': 4},\n",
      " |      ...           {'a': 100, 'b': 200, 'c': 300, 'd': 400},\n",
      " |      ...           {'a': 1000, 'b': 2000, 'c': 3000, 'd': 4000 }]\n",
      " |      >>> df = pd.DataFrame(mydict)\n",
      " |      >>> df\n",
      " |            a     b     c     d\n",
      " |      0     1     2     3     4\n",
      " |      1   100   200   300   400\n",
      " |      2  1000  2000  3000  4000\n",
      " |      \n",
      " |      **Indexing just the rows**\n",
      " |      \n",
      " |      With a scalar integer.\n",
      " |      \n",
      " |      >>> type(df.iloc[0])\n",
      " |      <class 'pandas.core.series.Series'>\n",
      " |      >>> df.iloc[0]\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      c    3\n",
      " |      d    4\n",
      " |      Name: 0, dtype: int64\n",
      " |      \n",
      " |      With a list of integers.\n",
      " |      \n",
      " |      >>> df.iloc[[0]]\n",
      " |         a  b  c  d\n",
      " |      0  1  2  3  4\n",
      " |      >>> type(df.iloc[[0]])\n",
      " |      <class 'pandas.core.frame.DataFrame'>\n",
      " |      \n",
      " |      >>> df.iloc[[0, 1]]\n",
      " |           a    b    c    d\n",
      " |      0    1    2    3    4\n",
      " |      1  100  200  300  400\n",
      " |      \n",
      " |      With a `slice` object.\n",
      " |      \n",
      " |      >>> df.iloc[:3]\n",
      " |            a     b     c     d\n",
      " |      0     1     2     3     4\n",
      " |      1   100   200   300   400\n",
      " |      2  1000  2000  3000  4000\n",
      " |      \n",
      " |      With a boolean mask the same length as the index.\n",
      " |      \n",
      " |      >>> df.iloc[[True, False, True]]\n",
      " |            a     b     c     d\n",
      " |      0     1     2     3     4\n",
      " |      2  1000  2000  3000  4000\n",
      " |      \n",
      " |      With a callable, useful in method chains. The `x` passed\n",
      " |      to the ``lambda`` is the DataFrame being sliced. This selects\n",
      " |      the rows whose index label even.\n",
      " |      \n",
      " |      >>> df.iloc[lambda x: x.index % 2 == 0]\n",
      " |            a     b     c     d\n",
      " |      0     1     2     3     4\n",
      " |      2  1000  2000  3000  4000\n",
      " |      \n",
      " |      **Indexing both axes**\n",
      " |      \n",
      " |      You can mix the indexer types for the index and columns. Use ``:`` to\n",
      " |      select the entire axis.\n",
      " |      \n",
      " |      With scalar integers.\n",
      " |      \n",
      " |      >>> df.iloc[0, 1]\n",
      " |      2\n",
      " |      \n",
      " |      With lists of integers.\n",
      " |      \n",
      " |      >>> df.iloc[[0, 2], [1, 3]]\n",
      " |            b     d\n",
      " |      0     2     4\n",
      " |      2  2000  4000\n",
      " |      \n",
      " |      With `slice` objects.\n",
      " |      \n",
      " |      >>> df.iloc[1:3, 0:3]\n",
      " |            a     b     c\n",
      " |      1   100   200   300\n",
      " |      2  1000  2000  3000\n",
      " |      \n",
      " |      With a boolean array whose length matches the columns.\n",
      " |      \n",
      " |      >>> df.iloc[:, [True, False, True, False]]\n",
      " |            a     c\n",
      " |      0     1     3\n",
      " |      1   100   300\n",
      " |      2  1000  3000\n",
      " |      \n",
      " |      With a callable function that expects the Series or DataFrame.\n",
      " |      \n",
      " |      >>> df.iloc[:, lambda df: [0, 2]]\n",
      " |            a     c\n",
      " |      0     1     3\n",
      " |      1   100   300\n",
      " |      2  1000  3000\n",
      " |  \n",
      " |  loc\n",
      " |      Access a group of rows and columns by label(s) or a boolean array.\n",
      " |      \n",
      " |      ``.loc[]`` is primarily label based, but may also be used with a\n",
      " |      boolean array.\n",
      " |      \n",
      " |      Allowed inputs are:\n",
      " |      \n",
      " |      - A single label, e.g. ``5`` or ``'a'``, (note that ``5`` is\n",
      " |        interpreted as a *label* of the index, and **never** as an\n",
      " |        integer position along the index).\n",
      " |      - A list or array of labels, e.g. ``['a', 'b', 'c']``.\n",
      " |      - A slice object with labels, e.g. ``'a':'f'``.\n",
      " |      \n",
      " |        .. warning:: Note that contrary to usual python slices, **both** the\n",
      " |            start and the stop are included\n",
      " |      \n",
      " |      - A boolean array of the same length as the axis being sliced,\n",
      " |        e.g. ``[True, False, True]``.\n",
      " |      - A ``callable`` function with one argument (the calling Series or\n",
      " |        DataFrame) and that returns valid output for indexing (one of the above)\n",
      " |      \n",
      " |      See more at :ref:`Selection by Label <indexing.label>`\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError\n",
      " |          If any items are not found.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.at : Access a single value for a row/column label pair.\n",
      " |      DataFrame.iloc : Access group of rows and columns by integer position(s).\n",
      " |      DataFrame.xs : Returns a cross-section (row(s) or column(s)) from the\n",
      " |          Series/DataFrame.\n",
      " |      Series.loc : Access group of values using labels.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      **Getting values**\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n",
      " |      ...      index=['cobra', 'viper', 'sidewinder'],\n",
      " |      ...      columns=['max_speed', 'shield'])\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra               1       2\n",
      " |      viper               4       5\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Single label. Note this returns the row as a Series.\n",
      " |      \n",
      " |      >>> df.loc['viper']\n",
      " |      max_speed    4\n",
      " |      shield       5\n",
      " |      Name: viper, dtype: int64\n",
      " |      \n",
      " |      List of labels. Note using ``[[]]`` returns a DataFrame.\n",
      " |      \n",
      " |      >>> df.loc[['viper', 'sidewinder']]\n",
      " |                  max_speed  shield\n",
      " |      viper               4       5\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Single label for row and column\n",
      " |      \n",
      " |      >>> df.loc['cobra', 'shield']\n",
      " |      2\n",
      " |      \n",
      " |      Slice with labels for row and single label for column. As mentioned\n",
      " |      above, note that both the start and stop of the slice are included.\n",
      " |      \n",
      " |      >>> df.loc['cobra':'viper', 'max_speed']\n",
      " |      cobra    1\n",
      " |      viper    4\n",
      " |      Name: max_speed, dtype: int64\n",
      " |      \n",
      " |      Boolean list with the same length as the row axis\n",
      " |      \n",
      " |      >>> df.loc[[False, False, True]]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Conditional that returns a boolean Series\n",
      " |      \n",
      " |      >>> df.loc[df['shield'] > 6]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      Conditional that returns a boolean Series with column labels specified\n",
      " |      \n",
      " |      >>> df.loc[df['shield'] > 6, ['max_speed']]\n",
      " |                  max_speed\n",
      " |      sidewinder          7\n",
      " |      \n",
      " |      Callable that returns a boolean Series\n",
      " |      \n",
      " |      >>> df.loc[lambda df: df['shield'] == 8]\n",
      " |                  max_speed  shield\n",
      " |      sidewinder          7       8\n",
      " |      \n",
      " |      **Setting values**\n",
      " |      \n",
      " |      Set value for all items matching the list of labels\n",
      " |      \n",
      " |      >>> df.loc[['viper', 'sidewinder'], ['shield']] = 50\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra               1       2\n",
      " |      viper               4      50\n",
      " |      sidewinder          7      50\n",
      " |      \n",
      " |      Set value for an entire row\n",
      " |      \n",
      " |      >>> df.loc['cobra'] = 10\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              10      10\n",
      " |      viper               4      50\n",
      " |      sidewinder          7      50\n",
      " |      \n",
      " |      Set value for an entire column\n",
      " |      \n",
      " |      >>> df.loc[:, 'max_speed'] = 30\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              30      10\n",
      " |      viper              30      50\n",
      " |      sidewinder         30      50\n",
      " |      \n",
      " |      Set value for rows matching callable condition\n",
      " |      \n",
      " |      >>> df.loc[df['shield'] > 35] = 0\n",
      " |      >>> df\n",
      " |                  max_speed  shield\n",
      " |      cobra              30      10\n",
      " |      viper               0       0\n",
      " |      sidewinder          0       0\n",
      " |      \n",
      " |      **Getting values on a DataFrame with an index that has integer labels**\n",
      " |      \n",
      " |      Another example using integers for the index\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n",
      " |      ...      index=[7, 8, 9], columns=['max_speed', 'shield'])\n",
      " |      >>> df\n",
      " |         max_speed  shield\n",
      " |      7          1       2\n",
      " |      8          4       5\n",
      " |      9          7       8\n",
      " |      \n",
      " |      Slice with integer labels for rows. As mentioned above, note that both\n",
      " |      the start and stop of the slice are included.\n",
      " |      \n",
      " |      >>> df.loc[7:9]\n",
      " |         max_speed  shield\n",
      " |      7          1       2\n",
      " |      8          4       5\n",
      " |      9          7       8\n",
      " |      \n",
      " |      **Getting values with a MultiIndex**\n",
      " |      \n",
      " |      A number of examples using a DataFrame with a MultiIndex\n",
      " |      \n",
      " |      >>> tuples = [\n",
      " |      ...    ('cobra', 'mark i'), ('cobra', 'mark ii'),\n",
      " |      ...    ('sidewinder', 'mark i'), ('sidewinder', 'mark ii'),\n",
      " |      ...    ('viper', 'mark ii'), ('viper', 'mark iii')\n",
      " |      ... ]\n",
      " |      >>> index = pd.MultiIndex.from_tuples(tuples)\n",
      " |      >>> values = [[12, 2], [0, 4], [10, 20],\n",
      " |      ...         [1, 4], [7, 1], [16, 36]]\n",
      " |      >>> df = pd.DataFrame(values, columns=['max_speed', 'shield'], index=index)\n",
      " |      >>> df\n",
      " |                           max_speed  shield\n",
      " |      cobra      mark i           12       2\n",
      " |                 mark ii           0       4\n",
      " |      sidewinder mark i           10      20\n",
      " |                 mark ii           1       4\n",
      " |      viper      mark ii           7       1\n",
      " |                 mark iii         16      36\n",
      " |      \n",
      " |      Single label. Note this returns a DataFrame with a single index.\n",
      " |      \n",
      " |      >>> df.loc['cobra']\n",
      " |               max_speed  shield\n",
      " |      mark i          12       2\n",
      " |      mark ii          0       4\n",
      " |      \n",
      " |      Single index tuple. Note this returns a Series.\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark ii')]\n",
      " |      max_speed    0\n",
      " |      shield       4\n",
      " |      Name: (cobra, mark ii), dtype: int64\n",
      " |      \n",
      " |      Single label for row and column. Similar to passing in a tuple, this\n",
      " |      returns a Series.\n",
      " |      \n",
      " |      >>> df.loc['cobra', 'mark i']\n",
      " |      max_speed    12\n",
      " |      shield        2\n",
      " |      Name: (cobra, mark i), dtype: int64\n",
      " |      \n",
      " |      Single tuple. Note using ``[[]]`` returns a DataFrame.\n",
      " |      \n",
      " |      >>> df.loc[[('cobra', 'mark ii')]]\n",
      " |                     max_speed  shield\n",
      " |      cobra mark ii          0       4\n",
      " |      \n",
      " |      Single tuple for the index with a single label for the column\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark i'), 'shield']\n",
      " |      2\n",
      " |      \n",
      " |      Slice from index tuple to single label\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark i'):'viper']\n",
      " |                           max_speed  shield\n",
      " |      cobra      mark i           12       2\n",
      " |                 mark ii           0       4\n",
      " |      sidewinder mark i           10      20\n",
      " |                 mark ii           1       4\n",
      " |      viper      mark ii           7       1\n",
      " |                 mark iii         16      36\n",
      " |      \n",
      " |      Slice from index tuple to index tuple\n",
      " |      \n",
      " |      >>> df.loc[('cobra', 'mark i'):('viper', 'mark ii')]\n",
      " |                          max_speed  shield\n",
      " |      cobra      mark i          12       2\n",
      " |                 mark ii          0       4\n",
      " |      sidewinder mark i          10      20\n",
      " |                 mark ii          1       4\n",
      " |      viper      mark ii          7       1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(series_designation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   first  second third\n",
      "0      1     1.1     a\n",
      "1      3     3.5     b\n",
      "2      4     4.7     c\n",
      "3      5     5.8     d\n",
      "4      6     2.9     e\n",
      "5      2     9.3   NaN\n",
      "6      9     NaN   NaN\n"
     ]
    }
   ],
   "source": [
    "# Program to create Dataframe of three series \n",
    "import pandas as pd \n",
    "\n",
    "s1 = pd.Series([1, 3, 4, 5, 6, 2, 9])\t\t # Define series 1 \n",
    "s2 = pd.Series([1.1, 3.5, 4.7, 5.8, 2.9, 9.3]) # Define series 2 \n",
    "s3 = pd.Series(['a', 'b', 'c', 'd', 'e'])\t # Define series 3 \n",
    "\n",
    "\n",
    "Data ={'first':s1, 'second':s2, 'third':s3} # Define Data \n",
    "dfseries = pd.DataFrame(Data)\t\t\t # Create DataFrame \n",
    "print(dfseries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       first     second\n",
      "0  [2, 3, 4]  [2, 4, 8]\n",
      "1  [5, 6, 7]  [1, 3, 9]\n"
     ]
    }
   ],
   "source": [
    "# Program to create DataFrame from 2D array \n",
    "import pandas as pd # Import Library \n",
    "d1 =[[2, 3, 4], [5, 6, 7]] # Define 2d array 1 \n",
    "d2 =[[2, 4, 8], [1, 3, 9]] # Define 2d array 2 \n",
    "Data ={'first': d1, 'second': d2} # Define Data \n",
    "df2d = pd.DataFrame(Data) # Create DataFrame \n",
    "print(df2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# import wget\n",
    "# !wget 46.101.230.157/dilan/pandas_tutorial_read.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('zoo.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniq_id</th>\n",
       "      <th>water_need</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1011.500000</td>\n",
       "      <td>347.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.493587</td>\n",
       "      <td>147.549243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1001.000000</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1006.250000</td>\n",
       "      <td>232.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1011.500000</td>\n",
       "      <td>325.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1016.750000</td>\n",
       "      <td>427.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1022.000000</td>\n",
       "      <td>600.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           uniq_id  water_need\n",
       "count    22.000000   22.000000\n",
       "mean   1011.500000  347.727273\n",
       "std       6.493587  147.549243\n",
       "min    1001.000000   80.000000\n",
       "25%    1006.250000  232.500000\n",
       "50%    1011.500000  325.000000\n",
       "75%    1016.750000  427.500000\n",
       "max    1022.000000  600.000000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>my_datetime</th>\n",
       "      <th>event</th>\n",
       "      <th>country</th>\n",
       "      <th>user_id</th>\n",
       "      <th>source</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:01:01</td>\n",
       "      <td>read</td>\n",
       "      <td>country_7</td>\n",
       "      <td>2458151261</td>\n",
       "      <td>SEO</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 00:03:20</td>\n",
       "      <td>read</td>\n",
       "      <td>country_7</td>\n",
       "      <td>2458151262</td>\n",
       "      <td>SEO</td>\n",
       "      <td>South America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 00:04:01</td>\n",
       "      <td>read</td>\n",
       "      <td>country_7</td>\n",
       "      <td>2458151263</td>\n",
       "      <td>AdWords</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 00:04:02</td>\n",
       "      <td>read</td>\n",
       "      <td>country_7</td>\n",
       "      <td>2458151264</td>\n",
       "      <td>AdWords</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 00:05:03</td>\n",
       "      <td>read</td>\n",
       "      <td>country_8</td>\n",
       "      <td>2458151265</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>2018-01-01 23:57:14</td>\n",
       "      <td>read</td>\n",
       "      <td>country_2</td>\n",
       "      <td>2458153051</td>\n",
       "      <td>AdWords</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791</th>\n",
       "      <td>2018-01-01 23:58:33</td>\n",
       "      <td>read</td>\n",
       "      <td>country_8</td>\n",
       "      <td>2458153052</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>2018-01-01 23:59:36</td>\n",
       "      <td>read</td>\n",
       "      <td>country_6</td>\n",
       "      <td>2458153053</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>2018-01-01 23:59:36</td>\n",
       "      <td>read</td>\n",
       "      <td>country_7</td>\n",
       "      <td>2458153054</td>\n",
       "      <td>AdWords</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>2018-01-01 23:59:38</td>\n",
       "      <td>read</td>\n",
       "      <td>country_5</td>\n",
       "      <td>2458153055</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1795 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              my_datetime event    country     user_id   source          topic\n",
       "0     2018-01-01 00:01:01  read  country_7  2458151261      SEO  North America\n",
       "1     2018-01-01 00:03:20  read  country_7  2458151262      SEO  South America\n",
       "2     2018-01-01 00:04:01  read  country_7  2458151263  AdWords         Africa\n",
       "3     2018-01-01 00:04:02  read  country_7  2458151264  AdWords         Europe\n",
       "4     2018-01-01 00:05:03  read  country_8  2458151265   Reddit  North America\n",
       "...                   ...   ...        ...         ...      ...            ...\n",
       "1790  2018-01-01 23:57:14  read  country_2  2458153051  AdWords  North America\n",
       "1791  2018-01-01 23:58:33  read  country_8  2458153052      SEO           Asia\n",
       "1792  2018-01-01 23:59:36  read  country_6  2458153053   Reddit           Asia\n",
       "1793  2018-01-01 23:59:36  read  country_7  2458153054  AdWords         Europe\n",
       "1794  2018-01-01 23:59:38  read  country_5  2458153055   Reddit           Asia\n",
       "\n",
       "[1795 rows x 6 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.read_csv('pandas_tutorial_read.csv',delimiter=';',names = ['my_datetime', 'event', 'country', 'user_id', 'source', 'topic'])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>my_datetime</th>\n",
       "      <th>event</th>\n",
       "      <th>country</th>\n",
       "      <th>user_id</th>\n",
       "      <th>source</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:01:01</td>\n",
       "      <td>read</td>\n",
       "      <td>country_7</td>\n",
       "      <td>2458151261</td>\n",
       "      <td>SEO</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 00:03:20</td>\n",
       "      <td>read</td>\n",
       "      <td>country_7</td>\n",
       "      <td>2458151262</td>\n",
       "      <td>SEO</td>\n",
       "      <td>South America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 00:04:01</td>\n",
       "      <td>read</td>\n",
       "      <td>country_7</td>\n",
       "      <td>2458151263</td>\n",
       "      <td>AdWords</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 00:04:02</td>\n",
       "      <td>read</td>\n",
       "      <td>country_7</td>\n",
       "      <td>2458151264</td>\n",
       "      <td>AdWords</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 00:05:03</td>\n",
       "      <td>read</td>\n",
       "      <td>country_8</td>\n",
       "      <td>2458151265</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           my_datetime event    country     user_id   source          topic\n",
       "0  2018-01-01 00:01:01  read  country_7  2458151261      SEO  North America\n",
       "1  2018-01-01 00:03:20  read  country_7  2458151262      SEO  South America\n",
       "2  2018-01-01 00:04:01  read  country_7  2458151263  AdWords         Africa\n",
       "3  2018-01-01 00:04:02  read  country_7  2458151264  AdWords         Europe\n",
       "4  2018-01-01 00:05:03  read  country_8  2458151265   Reddit  North America"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2018-01-01 00:01:01</th>\n",
       "      <th>read</th>\n",
       "      <th>country_7</th>\n",
       "      <th>2458151261</th>\n",
       "      <th>SEO</th>\n",
       "      <th>North America</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1789</td>\n",
       "      <td>2018-01-01 23:57:14</td>\n",
       "      <td>read</td>\n",
       "      <td>country_2</td>\n",
       "      <td>2458153051</td>\n",
       "      <td>AdWords</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1790</td>\n",
       "      <td>2018-01-01 23:58:33</td>\n",
       "      <td>read</td>\n",
       "      <td>country_8</td>\n",
       "      <td>2458153052</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1791</td>\n",
       "      <td>2018-01-01 23:59:36</td>\n",
       "      <td>read</td>\n",
       "      <td>country_6</td>\n",
       "      <td>2458153053</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1792</td>\n",
       "      <td>2018-01-01 23:59:36</td>\n",
       "      <td>read</td>\n",
       "      <td>country_7</td>\n",
       "      <td>2458153054</td>\n",
       "      <td>AdWords</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1793</td>\n",
       "      <td>2018-01-01 23:59:38</td>\n",
       "      <td>read</td>\n",
       "      <td>country_5</td>\n",
       "      <td>2458153055</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      2018-01-01 00:01:01  read  country_7  2458151261      SEO  North America\n",
       "1789  2018-01-01 23:57:14  read  country_2  2458153051  AdWords  North America\n",
       "1790  2018-01-01 23:58:33  read  country_8  2458153052      SEO           Asia\n",
       "1791  2018-01-01 23:59:36  read  country_6  2458153053   Reddit           Asia\n",
       "1792  2018-01-01 23:59:36  read  country_7  2458153054  AdWords         Europe\n",
       "1793  2018-01-01 23:59:38  read  country_5  2458153055   Reddit           Asia"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1795, 6)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows,columns=df1.shape\n",
    "rows,columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        True\n",
       "1        True\n",
       "2       False\n",
       "3       False\n",
       "4       False\n",
       "        ...  \n",
       "1790    False\n",
       "1791     True\n",
       "1792    False\n",
       "1793    False\n",
       "1794    False\n",
       "Name: source, Length: 1795, dtype: bool"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df1.source=='SEO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>my_datetime</th>\n",
       "      <th>event</th>\n",
       "      <th>country</th>\n",
       "      <th>user_id</th>\n",
       "      <th>source</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:01:01</td>\n",
       "      <td>read</td>\n",
       "      <td>country_7</td>\n",
       "      <td>2458151261</td>\n",
       "      <td>SEO</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 00:03:20</td>\n",
       "      <td>read</td>\n",
       "      <td>country_7</td>\n",
       "      <td>2458151262</td>\n",
       "      <td>SEO</td>\n",
       "      <td>South America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-01-01 00:08:57</td>\n",
       "      <td>read</td>\n",
       "      <td>country_7</td>\n",
       "      <td>2458151272</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018-01-01 00:11:22</td>\n",
       "      <td>read</td>\n",
       "      <td>country_7</td>\n",
       "      <td>2458151276</td>\n",
       "      <td>SEO</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018-01-01 00:13:05</td>\n",
       "      <td>read</td>\n",
       "      <td>country_8</td>\n",
       "      <td>2458151277</td>\n",
       "      <td>SEO</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1772</th>\n",
       "      <td>2018-01-01 23:45:58</td>\n",
       "      <td>read</td>\n",
       "      <td>country_7</td>\n",
       "      <td>2458153033</td>\n",
       "      <td>SEO</td>\n",
       "      <td>South America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>2018-01-01 23:49:52</td>\n",
       "      <td>read</td>\n",
       "      <td>country_5</td>\n",
       "      <td>2458153038</td>\n",
       "      <td>SEO</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>2018-01-01 23:51:25</td>\n",
       "      <td>read</td>\n",
       "      <td>country_4</td>\n",
       "      <td>2458153040</td>\n",
       "      <td>SEO</td>\n",
       "      <td>South America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1784</th>\n",
       "      <td>2018-01-01 23:54:03</td>\n",
       "      <td>read</td>\n",
       "      <td>country_2</td>\n",
       "      <td>2458153045</td>\n",
       "      <td>SEO</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791</th>\n",
       "      <td>2018-01-01 23:58:33</td>\n",
       "      <td>read</td>\n",
       "      <td>country_8</td>\n",
       "      <td>2458153052</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>346 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              my_datetime event    country     user_id source          topic\n",
       "0     2018-01-01 00:01:01  read  country_7  2458151261    SEO  North America\n",
       "1     2018-01-01 00:03:20  read  country_7  2458151262    SEO  South America\n",
       "11    2018-01-01 00:08:57  read  country_7  2458151272    SEO      Australia\n",
       "15    2018-01-01 00:11:22  read  country_7  2458151276    SEO  North America\n",
       "16    2018-01-01 00:13:05  read  country_8  2458151277    SEO  North America\n",
       "...                   ...   ...        ...         ...    ...            ...\n",
       "1772  2018-01-01 23:45:58  read  country_7  2458153033    SEO  South America\n",
       "1777  2018-01-01 23:49:52  read  country_5  2458153038    SEO  North America\n",
       "1779  2018-01-01 23:51:25  read  country_4  2458153040    SEO  South America\n",
       "1784  2018-01-01 23:54:03  read  country_2  2458153045    SEO  North America\n",
       "1791  2018-01-01 23:58:33  read  country_8  2458153052    SEO           Asia\n",
       "\n",
       "[346 rows x 6 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[df1['source']=='SEO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>my_datetime</th>\n",
       "      <th>event</th>\n",
       "      <th>country</th>\n",
       "      <th>user_id</th>\n",
       "      <th>source</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01 00:01:01</td>\n",
       "      <td>read</td>\n",
       "      <td>country_7</td>\n",
       "      <td>2458151261</td>\n",
       "      <td>SEO</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01 00:03:20</td>\n",
       "      <td>read</td>\n",
       "      <td>country_7</td>\n",
       "      <td>2458151262</td>\n",
       "      <td>SEO</td>\n",
       "      <td>South America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-01 00:04:01</td>\n",
       "      <td>read</td>\n",
       "      <td>country_7</td>\n",
       "      <td>2458151263</td>\n",
       "      <td>AdWords</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2018-01-01 00:04:02</td>\n",
       "      <td>read</td>\n",
       "      <td>country_7</td>\n",
       "      <td>2458151264</td>\n",
       "      <td>AdWords</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2018-01-01 00:05:03</td>\n",
       "      <td>read</td>\n",
       "      <td>country_8</td>\n",
       "      <td>2458151265</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2018-01-01 00:05:42</td>\n",
       "      <td>read</td>\n",
       "      <td>country_6</td>\n",
       "      <td>2458151266</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2018-01-01 00:06:06</td>\n",
       "      <td>read</td>\n",
       "      <td>country_2</td>\n",
       "      <td>2458151267</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2018-01-01 00:06:15</td>\n",
       "      <td>read</td>\n",
       "      <td>country_6</td>\n",
       "      <td>2458151268</td>\n",
       "      <td>AdWords</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2018-01-01 00:07:21</td>\n",
       "      <td>read</td>\n",
       "      <td>country_7</td>\n",
       "      <td>2458151269</td>\n",
       "      <td>AdWords</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2018-01-01 00:07:29</td>\n",
       "      <td>read</td>\n",
       "      <td>country_5</td>\n",
       "      <td>2458151270</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           my_datetime event    country     user_id   source          topic\n",
       "0  2018-01-01 00:01:01  read  country_7  2458151261      SEO  North America\n",
       "1  2018-01-01 00:03:20  read  country_7  2458151262      SEO  South America\n",
       "2  2018-01-01 00:04:01  read  country_7  2458151263  AdWords         Africa\n",
       "3  2018-01-01 00:04:02  read  country_7  2458151264  AdWords         Europe\n",
       "4  2018-01-01 00:05:03  read  country_8  2458151265   Reddit  North America\n",
       "5  2018-01-01 00:05:42  read  country_6  2458151266   Reddit  North America\n",
       "6  2018-01-01 00:06:06  read  country_2  2458151267   Reddit         Europe\n",
       "7  2018-01-01 00:06:15  read  country_6  2458151268  AdWords         Europe\n",
       "8  2018-01-01 00:07:21  read  country_7  2458151269  AdWords  North America\n",
       "9  2018-01-01 00:07:29  read  country_5  2458151270   Reddit  North America"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[df1.index<10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>read</td>\n",
       "      <td>country_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>read</td>\n",
       "      <td>country_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>read</td>\n",
       "      <td>country_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>read</td>\n",
       "      <td>country_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>read</td>\n",
       "      <td>country_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>read</td>\n",
       "      <td>country_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791</th>\n",
       "      <td>read</td>\n",
       "      <td>country_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>read</td>\n",
       "      <td>country_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>read</td>\n",
       "      <td>country_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>read</td>\n",
       "      <td>country_5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1795 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     event    country\n",
       "0     read  country_7\n",
       "1     read  country_7\n",
       "2     read  country_7\n",
       "3     read  country_7\n",
       "4     read  country_8\n",
       "...    ...        ...\n",
       "1790  read  country_2\n",
       "1791  read  country_8\n",
       "1792  read  country_6\n",
       "1793  read  country_7\n",
       "1794  read  country_5\n",
       "\n",
       "[1795 rows x 2 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[['event','country']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>country_2</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>country_2</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>country_2</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>country_2</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>country_2</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      country   topic\n",
       "6   country_2  Europe\n",
       "13  country_2  Europe\n",
       "17  country_2    Asia\n",
       "19  country_2    Asia\n",
       "20  country_2    Asia"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[df1['country']=='country_2'][['country','topic']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my_datetime', 'event', 'country', 'user_id', 'source', 'topic']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df1.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "my_datetime    object\n",
       "event          object\n",
       "country        object\n",
       "user_id         int64\n",
       "source         object\n",
       "topic          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  col1 col2  col3\n",
       "0    a    b     1\n",
       "1    a    b     2\n",
       "2    c    d     3"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from io import StringIO, BytesIO\n",
    "import pandas as pd\n",
    "data = ('col1,col2,col3\\n'\n",
    "            'a,b,1\\n'\n",
    "            'a,b,2\\n'\n",
    "            'c,d,3')\n",
    "df4=pd.read_csv(StringIO(data))\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data', header=None)\n",
    "# df\n",
    "# df.to_excel('winetest.xlsx')\n",
    "df.to_csv('winetest.csv',index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "matplotlib is required for plotting when the default backend \"matplotlib\" is selected.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-adbb6705558b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;31m# ts.show()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\pandas\\plotting\\_core.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 767\u001b[1;33m         \u001b[0mplot_backend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_plot_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"backend\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    768\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m         x, y, kind, kwargs = self._get_call_args(\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\pandas\\plotting\\_core.py\u001b[0m in \u001b[0;36m_get_plot_backend\u001b[1;34m(backend)\u001b[0m\n\u001b[0;32m   1664\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplotting\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_matplotlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1665\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1666\u001b[1;33m             raise ImportError(\n\u001b[0m\u001b[0;32m   1667\u001b[0m                 \u001b[1;34m\"matplotlib is required for plotting when the \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1668\u001b[0m                 \u001b[1;34m'default backend \"matplotlib\" is selected.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: matplotlib is required for plotting when the default backend \"matplotlib\" is selected."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "ts = pd.Series(np.random.randn(1000),\n",
    "                  index=pd.date_range('1/1/2000', periods=1000))\n",
    " \n",
    "ts = ts.cumsum()\n",
    "\n",
    "ts.plot()\n",
    "# ts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x13299ed0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEFCAYAAAAG45eHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOydd3gUVffHP7Ob3gtppBBCDUrvRRAEQQQREURFsSB20ddesaDYXl8FlWZDLDRFkCaIgkiVGnpJCOm9193szu+Puzu7m92EAJsA/ubzPDyZcmfu3bA5c+fcc75HkmUZFRUVFZV/J5pLPQAVFRUVlcZDNfIqKioq/2JUI6+ioqLyL0Y18ioqKir/YlQjr6KiovIvRjXyKioqKv9inGLkJUkKkCRpuSRJxyVJOiZJUl9JkoIkSdooSdIp089AZ/SloqKiotJwJGfEyUuStBDYKsvyF5IkuQFewEtAgSzL70qS9AIQKMvy8/Xdp1mzZnJsbOxFj0dFRUXl/xN79+7Nk2U5xNG5izbykiT5AQeBONnqZpIknQCulWU5U5KkCGCzLMvt6rtXjx495D179lzUeFRUVFT+vyFJ0l5Zlns4OucMd00ckAt8LUnSfkmSvpAkyRsIk2U5E8D0M7SOwU2VJGmPJEl7cnNznTAcFRUVFRUzzjDyLkA3YI4sy12BcuCFhl4sy/J8WZZ7yLLcIyTE4duGioqKisoF4gwjnwakybK8y7S/HGH0s01uGkw/c5zQl4qKiorKeXDRRl6W5SwgVZIks7/9OuAosAqYbDo2GVh5sX2pqKioqJwfLk66z+PA96bImiTgXsQDZKkkSfcDKcB4J/WloqKiotJAnGLkZVk+ADha2b3OGfdXUVFRUbkw1IxXFRUVlSZAlmVkna7J+1WNvIqKikojoEtNxVBcjGw0ApA7axbHO3XGWF3dpONQjbyKioqKkzFWVZE47HqSRt/E8Q5XUfr77+TPmQtA+bbtTToW1cirqKioOJnyHTsAqMkRkeO5s2YjubkBUH3ieJOORTXyKioqKk6m8sBB2wNareKPr/jHudItZVu31nteNfIqKioqTqYmO9tmv/rYMQA0Xl6U79qFbDA4ra/cjz+p97xq5FVUVFSciC4lheLVq5V9rb+/su3ZrRsYDBQtW3be9zWUlWOsrLQ5ZqyspOp4/e4f1cirqKioOAlZpyPx+uFQU4NX7960XPEzLVf8jN/IkfiPGYP/mDEAZL3+BobS0gbfV5+VxamBAznRtRvJd9yJrNOhz8xEn5kJ53grcFbGq4qKisplQ8n69QD4jRjRZH3qc3I4PXCQsi/rdHjExwMQ+dF/Aag8cEA5X3XkCN59+jTo3sUrVyFXVIh77NvH8U6dAYiYOfOc16ozeRUVlX8VxooK0p98ivQnn2qyPuWaGip27lT23Vq2JPjBqXbtPDp2JHiqOK5PT2/w/XVJiQ6PZ7744jmvVY28isq/CNloVJJv/r9iDlsEqCksbJI+z4y9hYznLIXvWv6yAt9rr7VrJ2m1NHv0EQDKt+9o8P2rzyTj1bcPoc8+c95jU428isoVjrGqirSnniLrzbdIHj+Bs7ff4bBd8cqVHGsfT82/vDhPTUGBsl11+LDNOUNJCYVLlzqMbpFlGd3Zs+fdn6GkhOpTpywHtFo07u51tjefK1mzBlmvR66pob4KfbIsoztzBveWLfEZPBgAr549abNjO82eeJywl1+ud3yqkVdRucI5c8s4Stetp/CHH6g6coTKgwcp+HYRhrIyDGVlSrvCJUsBSL5t4iXRUGkqDNZGvlbkScGiRWS9Np3iFStsjud++hnH4zuQOHwEZVu2ACJyxVBcfM7+qhOFK8U1MhLfESOIP3L4HFdY0KWlcaJHTzKeeRZ9djYl63+z/zx5eRhLS3GLbYlby5aEvfQSkbM+wSUwkJBHHiHorkn19qEaeRWVKxxdUpLdsex33uFkj56kPvgQstFI5quvKrNNfUbGBc1YrxSs31T0Kam2J00z+LK/LAlEck0NeZ9+quyXbf0bgOQJt3Gy97kXRs2//5ivviTq4/81aIyxi38EIOmGkchVVZSsWcPpQdeS/uSTNm8iABV79wHg2akjkiQRdPdduAQGNqgfUI28isoVjazX13u+cu9earKyKFq2HKNVyF7V0aPnvPZKQa6pAaAmP5/CpUupPp2I5OWFR6dOdg+zmrx8AKpPnlSOmUMZza4QfUYG+V99rTwUbVwxDqhOTEJyc8M1KopyfTl6w7l/r+7t2tV5rurQIRt3UvmunWi8vPC46qpz3tcRqpFXUbkCKV69htLNm6k+fRoA9zatlXPNnnjcpm1lwiG76zOef4GT/Qc0yB1xOWMoLuZkr95kvPIKZ24dT9Zr0yn8/nvc4+Lw6tqVygMHMJpCD8GSiWo92zeaXFq+11+Pz3XXoUtKIuf995XzKVMesOmzfOdO9FlZyr4uMRG3li2RtFr6/NCHJ/584pzj1nh6EjDxNofnMp57nuNXXY2xqgoQEgmeXbsiubqe874O+7qgq1RUVC4J+qwsCpcuJeOZZ0h76GFK1q0HrZbIWbPQeHsDEDx5MpH/+4jI2bMASH/ySQACxt9K7LKlyr2MJSWUbtzY9B/CiVQdOYKxooLi5T9Rk5mpHPe7YQRevXoi63TKg7Dy4EGLv728nKx33iFt2pMkDrseAK2fL17du6NLThb7Ic3w6tOHmuxsDCUlgMg6TbnnXlKmTKFg4ULOTrqLyoMHcW8VR5lOPCz+Tv+7QWOPeP112h3YT/ADUwCIXrBA9GF68BYtWUJ1YiL61FTcYmMv+HekGnkVlSuI3E8/Jeu16cp+8S+/4N2vH+4tW9Ly55+IW7cWjbc3fjfcgGfHjjbXBk2ejMdVV+E/dixRc+fgGh1NyW8bmvojOA19Tg4VVslF1ri3bo1bXBwA1afFwmjybRMBcI2OBqDw20WU/mZZ6NT4+uJ340gkd3c0Pj5Ef/45zaaKWXzlwYOmn6I/3elEsme+S8WePRiKivAdMYKzpee/zqHx8CD06adpt38fPtcMoNkjjyjnsme+S9KNozCWleEaFXXe91b6uOArVVRUmhTZaKR4+U82x2pycggYdwsAbi1a4N6ypXLONTwcjZeXsu/WogWSRkPzme/ge+21ePfrR+XBg/WG712u5H/5FacHDiJv1mwkDw+iPp1tc94lNBS3mBi0gYGUb9tmcy706acd3lPr64trWBit1q6hzV9b8OzYEbdWwg2W+oApgSnNcQKT79ChnC22GHmd4fyilzSengCE1HK1mXFv3drh8Qbd+4KvVFFRaVKqTEqGAKHPPadse3btVuc14dNfAyB6/jw7n65HfHuMJSXUZGQ4eaSNS3VSEjkffKDsu8W1xHfoUEKenIZLSAgArs2bI2m1eA8YQMXu3eizc9B4exN41134DLzG4X1dQkPFtZGRysPRJTREOV/29zaypou3KN9hQ2m58heiPp1Ny5UrkTQam5l8buWF5yK03vQ7Gl9fsSNJoNHg1a3rBd9P1a5RUblCMM8i/ceOJeiuSRiKinCNjsI1LLTOa/xGjcKrVy9cIyLsznm0bw9A5ZEjuEZGNs6gG4AuLY3K/QfwHz3K4XlZr6cmPx/X8HAA9OmWh5J7fDwx8+YB0Oyhhwh+8EFknU5JOPLs2JGSX3/l9CChKeMSGoLGy4vWW7ag8fbi1MBBiiaMNijIrm9Jkgh5+j/k/vcjUqdMUY5HzRZvDh5WUTK7M3cr2zkVOUT6XNjv1DUyEo2nJ8bSUqLnz8erezebN7LzRZ3Jq6hcIVSfOAFA2MsvIbm6EvqfpwgcP77eaySt1qGBB3Bv2xbJ05PCbxc5faznQ/JtE8l49lklFLI2WW++xelrB1O4bBkn+/Sl8EcRYx75ySfErfhZmb2DMMrW2abe1wywuZdbixYAuIaFovXxofXGDWhMUsCSJDnsv7Y8Qdy6tfZjLM9ib/ZeRseNBiAhN6G+j3xOgiZPBrhoAw+qkVdRuSIwVlRQuGwpXr17o/Xxcco9NV5eBE4YT0WtMENnkj1zJsfax9uEHNbGkC9i1+uS3i0yZadmvfoahqIiyv74A21QEL7Dhp6zf/eWLQm4faKyXztKxSU4mDZb/6Ldvr1136NNG8U95h4fb7PuYeZ4wXFkZCa0mwDAh3s+xGC88MIgQffdS/vDhy7awINq5FVUrgjKtm3DkJtH8JT7nXpfr959oKbGJjnImRQs/BaA09cOJm/uvHrbGuuK2Xcww/e55hokTcPMV8T06bTe/CdhL76Ae5s2duc1bm7nNKbB991L+2NHafnzTw7P51QIUbTmPs25voUIyRzx8wjmJ8xv0BhrI0kSkotzvOmqkVdRucypPHSI9MefQOPtjVfPnk69t3vrVgCU79xF0U8/N6qCpVnjvS4MJSXoMzNJue9+Ml58CVmWkQ0GZcG45cqVRM2dg1tsLEH33XtefbuGhxM0eXKdLpmGIElSndfnVOSgkTQEeQTxdA8RvZNVnsXs/bPZkrrlgvt0BurCq4rKZU7hd98BEPL0f9B4eDj13q6RkUju7uR+/DEAbjHRyoNElmWyZ7yN7/Dr8e7VC9loPOfsubCqEC9XL9y1wi/u1rIlujNnCH5gCvkLvsBQUoLWz09pb51xm/70M+hTLVozzR56UIxDryfi7bfxaNcWj3ZtHUr4XmpyK3MJ9gjGReNChLftGshjfzzGwbsPopEuzZxancmrqFzmmDNZAydOPEfL80fSapWkIYCKvcI3bSwv51SfvhR+/z0pd09Gn5nJ8Q5Xkf/1N3Xe62zJWQYuGcjsfSLyRJ+RgS4lheAp9+Njim7JtpILAKGhY8bawIPIZjUrPJrfOC5XsiuyCfUSUU6SJNkZ+q8Of3UphgU40chLkqSVJGm/JEmrTfstJUnaJUnSKUmSlkiS5OasvlRU/r8gyzI1BYW4tohpsA/6fHG3MvJVx0UET+mfm21m2acHDwGgaOlS6uJAjsgGXX5qOWBSczQY8L9lHF49euA7fDglv64mb+48yv76C4DKQ0KW13vQQOU+wQ+ILNPM19+gcp9QYLR+EF1u6I16tqVvw8PF8pb1RLcn6BXeS9nfm133wm5j48xvzTTgmNX+e8D/ZFluAxQCzl0xUlH5f0DR0mWUrl9fZ6alszEvwFafFsqLXn1tpXbdakWW6NLSldDHsyUiGeipRaUULF1C0dKlaPz8cGsZC4D/mDHI1dXkfvwxqVMfpGzLFopXrsQ9Ph7Pq65W7hk4SeijG0tKyP/qayQvL7Tm5KDLkD9T/gQgyMMSZz8qbhRfDv+SeUPFYrPMpcsqdoqRlyQpCrgR+MK0LwFDgOWmJguBm53Rl4rK/ydKVq8WGw4qGTkL/5tEbLff6NHokpMxVlWhSzqDW2wsLb7+Wmnn2b27UpBDl5xM2da/SRw6lJwPPgSEke+caKTTGSPZr70uxMNKSpTFSo/49jb9pj74ELrERALvuB2fIUOU4y5BgUr2KUaj09chnM2hPKHy+WqfV+3O9YvsR//I/hRVFTX1sBSctfD6MfAcYH7cBgNFsiybY5/SAIfpX5IkTQWmAsTExDhpOCoqVz661FQq/vkHgObvv9do/fgMGkT7Y0cp/W0DJb/+SvGKFZRu2IBHhw4AxC5ZjD4zi9Lff6dy/35kWSZxxA3K9ZUJIvGn4uRxXl5ad3SOS1iYw+OeHTvi0b49cWvXIFdXI7m60mr9Ok506w7YVnq6HEktTaWVfysCPRwX8ghyDyK5OLlpB2XFRc/kJUkaBeTIsmztdHIUZ+TwfUWW5fmyLPeQZblHiFXmmorK/3cq9+8HhJH1v+mmRu1LkiTc27YFIOuNNwEU5UPPzp3xGzEc99at0Ken2yyWgjDyiYl7if/zTP19aDQETpokCmZotcpxs/F3j4vDIz4ewClJQE1FVnkW4d7hdZ4P8AggszyTrPK6E8IaE2e4a/oDN0mSlAwsRrhpPgYCJEkyvylEAVeWCpKKShMi63Tk/PcjakzZn/rsbDKeex5AmVE3Nm4tYpBMkgDagAAi3p5hc96zixDJSh53q+2FBgOFn8zGvxzkAD+8+vRWTm18qj9VNVXKfvgrLxO38hfaHz6E96CBwt8eEFDvuKw18C9HMssz6zXyge6BGGUjw5YPu6gs2Avloo28LMsvyrIcJctyLDAR+EOW5TuBPwHzt2EysPJi+1JR+TdRk5vL6euHU7FvPxX7D5C/YAFpT0wDoGLPHgC8+/W94IpA54uk1eLeSoQq+o0aZbfY6d2nN+4d4h1ee+bEbnwrZFxbtyLglluU499JO+n5fU92Zu607UuSiJ47l7Zb/zpnglJtXfzGYmvaVmbsnEF+ZX6Dr8mvzKegqoA4/7qjfwI8LA+x9LKmWUC3pjHj5J8H/iNJ0mmEj/7LRuxLReWKo2L/fvQpKWQ88wyGwkJA1GSVZZnybduRvLyInju3ScekNRWIdouz12cBlHh3M/533M6udhIBZTK+leAeHIJnly7K+SpT4PT2jO1295IkSckBcET0F18Qu2Tx+X6EC2J10moe2fQIS04sYemJhr05bEjewCvbXgGgbVDbOtsFuFuM/Jni+l1ajYFTjbwsy5tlWR5l2k6SZbmXLMutZVkeL8tytTP7UlG50qnJywNE0pC5RB+IhcaStWvxv/FGJLemTS8xG12X4GYOz/sMFPHsIdOewHfECGruGkOOP4QWg385uAYG4mYVQCGbZumSg2U6o2xkffL6Ogts+Azoj2fnzhf1eRpCQVUBL2590Wb/XOiNep7e8rRS6q9zSN3jtM50vRid+QtFlTVQUbkEyLJsV+XJTOWBA8hVVfhcN8Th+cYk9LnnkFy0+NSS6DXj1bUr7Q8lKC6kUStG0d5fwq1Gxq0GXMNFpmfMtwupOnSIn266hnGrxjl0gSw+vpiZu2fyUu+XaOnfkp5hPdFqtHbtGpva2jJl+rJ623da2IlroiyFR26MuxFPF8862w+MGsgjnR/h84OfXxIjr8oaqKg0Mfr0dHL/97FdlIoZc01S14jmTTksANyiIon86KN6o1vMBt5gNHC25CzZVpGDrs2Fkffu1Yvg+++nbWBb2gS2oVRnKyOsM+j44fgPAKxJWsMDGx64YMXGi+WDPaLK1MoxK4n1i1UKcjuiuLoYGZm/0kTGbqRPJM/2eLbe+7tqXHm4y8MEuAeQXvrv8smrqKg44Ozdk8mfLwxa0D332J03p/LXV/HpcqBYJ2QPPPpY0vdrZ8QC+Ln5UaIrsTl2MPegkiF7MFcUyf784OdNHn2SWpKqPIDiAuIwyAY2p22m2mDrXa6qqeLv9L/ZkblDOdYhuAPrx60n2DO4QX31Cu/FysSVnCg44bwP0ABUI6+i0sTo0y2zudBnn7E7X7ZlC9rgYKVi0eVKQaXwXY+Lv42ozz8j6N578bj6art2vm6+iiGtrKnk3d3vKoZ9QtsJNm1PFZ1q5FHbMnLFSAAe7CQUL1NLhUjaE388oTxwThWeouf3PXn494d5dotl1h7je37Jm8NjhwNw66+3UmN0XAWrMVCNvIpKEyLLsuLuCH7oQSStlpivv6LZ448pRbdBRLFcjPZ5U5BfJfzsgR6B+A4ZQtjzzzkcs5+bn2Lkp2+bzvfHvueTfZ/g6eLJ9bHX27Q9Vdh0Rt4sqAYwMk4Y+wc6CnG07Rnb2Zq+FYCNZzc6vL6uDNe66NPcogOUVpp2XtdeDKqRV1FpIoqWL+d4fAdkvZ7QF54n1BRR4923LyGPPkrAxIl4XyMW9PxuHNno4zEYDRdlVM2z3ijfqHrb+bv7U1BVwC+nf2Fd8jrl+COdH6FneE/e7Pcmm8ZvApo2+sSsOfPhoA+VOPdb2lhi/M1RMaeLTttc1z1MyC30Du/N+eDn5seSUUsAxyGljYUaXaOi0gTIRiOZr1gErByFRkqSRMyC+Rirq22KUTfKeGSZ/ov7U64vZ/no5bQLanfe9zhTfAZ3rbuddnpt+kT0YdHRRby321Z/Z2TcSDSShrFtxgLg7epNZlkmlTWVvP/P+0ztOJUIn/rvfTFklmeKt4kWlrcJayXJQ3mHiPaNZuPZjcT5x/HLmF9IK00jyjeKk4UnL+h3Fh8UT6RPJHuy93BH/B1O+RznQp3JqzQpBqOBrPIsiqqKkOVLJ7/alBgrK0mfNk3ZdwkPx2/YsDrbN7aBB1HkolxfDly46yC5JJkYv5hzVjzqG9EXX1dfyvRl9I7ozbg24wAI8bTVqtIb9Cw+sZhe3/di+cnlvLXzrQsa14pTK/h0/6fn/H6dLjxNmFeYjYvJ08WTlv5i8XjuwblKslNScZLI0vWLRpKkCzLwIB7kIZ4hdgvRjYlq5FWajL/T/6bLoi4MWz6Ma5Zcw+z9sy/1kJqE8p07Kd34OwBxa9fSZvOfuFxiMT7rzMvsiuzzvl6WZU4Xnqaln+PMWGtcta5E+goR2jYBbZjedzoH7z5o57/XGW2Toramb6VCX3He43pt+2vMS5inuGMcUVBVwI7MHQxtMdTmuCRJLL7RkmWbkCsUNpt5Ok4OuxD83P0oqVaNvMq/kAUJC2z3Dy1g+cnlnCo8hT4zkwqT6mJDKNeXszppNZ/s+4Tvj33v7KE6Fet4eHMBjUuNtZGfuXumjYjYuaisqeTmlTeTUZ5Bj/AeDbrGHInTKaSTkDNwMPsfFTcKEL7w/pH9AfjP5v9QXF1s17YuEosSle3NqZsdtsksy+S21bcB0L95f7vzjhKbvh7+td2xC8VRSGljovrkL0MO5BwgwD2AWP/YSz2Ui+JsyVkCPQLxcxOFmx2li7+x4w2QZZbP9sBYXk7rTb/jGumw9AAAR/KP0D6wPd8d/Y5PD3yqHL8z/k7nfwAnUbLqV7TBwbTe9PtlEzGTVJxks5+Qm0CviF51tLZl1elVyvVjW49t0DVxAXHkVObQr3m/Otu80e8Nnuz2JGHeYVToK+j9Q2+2ZWxjwOIBuGvdWT12NeHe4czcNZMyfRkz+s+w+32+s/sdAII9gvkn6x+H/Xy09yNF9rdDsL3CpyRJ7LpjFwuPLOTzg58zInaEU/8Wm9rIqzP5RqbGWMPpwtPnbmjFXevuYvQvozHKdRdguNzRG/WMWjGKQUsGKb5Rs1vAenELoPtpGWO58A9X7D9AXZwsPMnE1ROZc3COXcTD1A1TeX376zbHdmfuPq8Z6oVSefAgRb/84vCcLMvo0tPxu3HkZVHhKKMsgw//+ZBt6dvoHtYdV40I58yrzGvwPfbmiNIR7wx4x6auaX28P/B9lo5air973bH/blo3wryFtryXq23GbbWhmltW3cLSE0v54fgPrEpcRX5VPvMOziOjzKJinluRS6xfLL0jeishnrUxf2ZH/VgfH99uPGNbj+XuDnc36DM2lACPAEp1pegNeqfety5UI9/IdF3UlbGrxrI1bWuD2lsb9mP5x+ppeXmQWZbJujPreHTTo2xO3awY9G6LugHiIXeq6BQV+goqayp5sNOD/Dr2V17ra4kJ73TGskBmyK/b2JgN0byEeaxPXm9zbkfmDn469RPVhmpOFp4kpyKH+zfcT+8fejf6rCn5tolkvmARuMqe+S7H2sdTnZiIsawMamoUTZdLSY2xhuE/DWfh0YWklaUxKm4Uf04Q9Um3pFn0W4yykRE/jeCHYz84vE92eTbdw7ozutXoBvcd6BFIfLBjmeK6WHHTCoI8goj2jQagVFdqsxi7K3MXnx74lOE/DSe/Mh9ZlsmuyGZg1ECCPIIorCp0eF+zO2b2kPrXhJp5NuPN/m/SMcS5UsehniKTuanCRVUj34hYvy5+cegLh+6KhNwEmygA6zazD1zeC5MGo4Fxv47jub+e46+0v3j8j8dZcmKJXT3LpKIk9mQLffRIn0j83PwY33Y8625Zx6T4SXhXQY4/1GhAl1v3F7/2g3JS/CQW3bDI5liP73owbtU4JXXcKBv5aM9Hzvi450Sfk4NcU0PBwoUAJN04SpEQ1gadX+JMY1Bb5nZA5AD83f0Z02oMa8+sVd44cytySS9LZ+bumWxO3cysfbN4fNPjHC84zm/Jv5FTkUOYl+NSfs6kdWBrtty2hbW3rOW/g/5rd/6FrS8o29O3TyenIofKmkrCvMII9gymTF9mJ08AUFhdSKxfLNdGX9uYw68T89tKTkVOk/Sn+uSdzL7sfQR4BNDCtwX3/Xaf5XjOPgYtGUS30G7MvGYmzX2asz19Ow/+LtKpD00WkQBmLev4oHi2pW9Db9TbvF5eTpwuOm0nPLXx7EYlOebNfm/y2vbXmH9ovpJ0Y63zEeUbxfO9nmel/DNlHiW4GMAnN9NhXwm5CXx37DubYx2bdaRLaBeH7Z/e8rSybf06fzGU/LYB3ZkzNHvoQYfnTw8cRMD48TbHEq8XqewugZfeyB/NFwvAo+NGE+wZrFQzuj3+dlYmrmTJiSUEegTaZII+/sfjyvbmtM3KtjlDtKkY1mIY34/8ngjvCDanbebNHW/anN+StoUty8XbSJh3mCIyVlhVaFO1Kas8i41nN9IttFvTDb4W5ryC9LL0Or+/zkSdyTsRo2xk8vrJjPllDMklycrxJ7o+oWzvy9nHD8d+YOPZjYqBBxTf8R8pfxAfFK/EEl/KKu/WyLLMnWvu5OvDliiDZSeX4aJxYVL8JD4e/DEDIgewL2cfK06twNfVlxta3kCQR5Bi4CN9IukT0cfu3u1dY6jwkCjygepcx7Mba9fVlI5TCPEMUWZig6IG2bWvrKkERDRHUbVzfofp06aR+/HHGCsrqTpxktSHH8FQbBv5UbRsmcNrvfr2dcoYLpRdmbt4Zdsr+Lr6MmPADJ7uYXkImt0hi08sZs7BOTYiXI6I9IlkfNvx9bZxNpIk0SmkEyFeIYxvO56/bvtLOVd7LOHe4cq6T22//H/3iDcC67/PpsaseTNr36wm6U+dyTuJ3IpcXt/xurJ/88qbARgaM5Se4T1t2u7N3svCowttjm1O28zwFsNJKU3h1ra3KroYBVUFhHg1fUz1sfxjlOpK6RXRi2Unl7E/ez8JeQkk5CXww/EfmNB2AktOLKF9UHue7yVqkfq7+fN3+t9sOMHhcqsAACAASURBVLuBa6OvxcPFg5b+LSmoKuCJrk/wQKcHHPblWlENPt4UacuVQhq1WZW0Stme1m0a07pZkov+N/h/pJam8sjvj9iUV5sUP4kyfRk7Muo3Wg0h/yvLwy3v888pXrOGmoxMqo4cwSUsjJps21jzyE8+oXDRIqqTk2nx7UI0TVz8ozZmd9kLvV+wC1/0c/OjmWczm8XX2UNmk1+Zb/OdBvhj/B8EewafMwGqsQn0CKR/ZH88tB52btBwL8vMPa00jcyyTCUe3qx82Su8YZFEjYGrVryZZ5RnoDfolf3GQjXyTmLm7pmKxrQ1L/d52c7dcjj/sF27Z7c8S/fx3RWfotnIO2sWCmAoK6N823b8hl9/zrYTVgt1wEOTD9m9GmeVZzFrv5iFWLtfrF892we1B2Byh8l4u3orqevWVCedoWL3LnSpqXS5eQQbj6xEeyiZ8hPH8G4nFulkWeb3lN85nHeYvhF9eaPfG3b3cdW4Eucfx7c3fMvm1M3sydrDuuR1TGw/kZ9P/UxBVYEQBruA8MWCqgIq9BWUf/aZqTNX8hd8oZzXnT1LTXY2PtdeS/jr08mbOxeNtzd+w69v0O+5qcivzCfQPZCbWt3k8Px1Mdex5ITQVXm86+NcG32tTSbsulvW4eHi4dSkoItl7lBRGvFQ7iFkWeaNfm9wJP8IYd5hSmLVM1uEyufiGxejM+o4VnAMH1cfXu/3+qUaNgDT+07njR1vkFeZ16jSDaAaeadhbYyHxgzl9xSR4RjkEYRG0iAhcWf8nbQJbMP07dMBoekxZ+gcui7qCogHBQifYqiXWIE3x/M6g8yXXqZ0wwY81q/DLTa2znbWC8GfHfis3nu+d41Fj8RF48KswbN44s8nlCSTwTGDGRwzWGlTU1hI3uxP0QYEkPf558rxsKEjyUsTtd5TxtyCS/MIDEs+5a3db5OQJ7IOO4d2rvcPItQrlAntJjCy5Uhuan0TLfxaEOQRhN6op6i6yKFqYN6CBegzMoiYPl05VrZtG1VHjuI1cjgj1ozEvwJmlRsIe/lljFWV5P7XspCb9YZ4AAbeNQnX8HAiXn+93t/XpSKrPMvGN12buzvcrRj5LiHiYW0tPBbpE3nZxPjXpmNIRz4Z8gmAkkRV+2F0tOCo4hJdMWYF3q5115ZtCsx/3zmVOY6/08fXQqsh4GofolptqCalJIU2gW0a1Jfqk79AcitybTShzRl934/8nv8N/h9jWo3B29Vbea1NmJzA872e55Y2tzCsxTBcNa7MGzYPF40Lf08UdSLNkqbdQ7sT6ROJq8bVLmnlYqg8KDS89Rn1L0QuOmqJWJl7UMyWuoV249sbvmXvpL3KuWaezezingfHDGbH7TuUWX3JunWkPf44hjIRB3/m5rEU/vCDjYEH8GrXntW9LF/HmoxMjv/PYuBBRIM0BB83H6Vt11DxALUOEbQm978fUfTjYnTJyVQdPUpNYSGp908h96OPWHPfCBb+z8C735gKWXTpgHc/+2SeoPvuw6e/febkpcAoGx0W3siqyFKiOhwR4xfDsBZCT8dNa3EtvXfNezzW5bHL1sDXRe2s1V8TfyW3MhdXjWuTRAadC/NDKK/CgXsyYz8svh3WOa44NXPXTG5ZdUuDcxvUmfwFYDAaGLJsCL3De/PF8C9ILUklsTiRSfGT6BTSCYAZA2YwgxkOr/9g4AdUG6qVB4C1oWwb2FbxwbcJbMPe7L0O73EhyAbxx1+dmGRjrCoPHcK9VSs0Xl4YjAa+PPwlge6BFFZb4ow/u+4zfNx8ANh1xy7cte511uM0tzOUlpL+1H8A8B2xGcnV1c53DeDWogXaZs2YNfoLPjl9P9NWiVwB/4QzYNKBmjd0Xr3Fkuvi6mZXi4dlkf3D0vphl/H8C1QePEjoc89Zrk0RbzRepii8EdvvZubw/xHbqhWBE8bj2aULpRs30uzhh897XI3FM1ueYWfmTpbcuIRov2jleFZ5Ft1Du9d77Rv93qBzSGflOwxNH0XjTFr5tyKxOJEgjyD25+wn3DucZp7NLosHllmczWGsfM5x8XPft+DhD70ehADL/+W+HFE5LLU0lWaezc5ZeFydyV8AGeXCOOzK2oUsy0p1mXPpapvRarR2mXbmeO+pnaYqx4a1GMbB3INOKTAg63QYTIuaZX/+AUDViROU79hB8vgJZDwvFk9PFZ2ioKpAWUw1YzbcILIBz1Vw2VhRQaqV8Sv+6WfSn5hm167dwQPErV2DJEn0iehD38kWI2vMtzxkeoZ0I3fWbPTZ544trj59mrRpT1J14iQaSUOkTyRfH/na7o+hYq/lAWp+y9n1hwjTPObgv7LSHZ7c8h9arVlN0OTJeHbuTOgzz6Dxrv/V/6+0v9iUsumc43YGG89upFRXym9nfwOEcf/wnw8p1ZXW664BUcFp8lWTL/miqrP4asRXLLh+AYOjhbtw3Zl1uGsbX+GzIZjduA5j5bMta3by9tmsW/+EjVCbl4uwHSklKQA8t+U56uPf8b/ZxJwsOKlsz9hpma17aC88bb1LaBf+GP+HUiIMYGTLkbhr3Xl+6/MXlZ4vGwwU/vijsl99JhmAM2NuJuVeEctfvmMnAGvPrEUjaege1p2hMSIiYd+kfefd54lu3ancI4yoz5AhlG+3FElol3CQ6C++oO2ef9C4uyNpLQ+MSJ9Ivh4qvpbNSkFrkNng/jxFc+eT9/nnpD7gOELHmpT77qf0t984M2aMzUPhsU2PKduy0UjGs8+BqyvaEIv/ttwUp1/g62C2Z5oBPrjRcZy8IwxGA49uepQn/3yy0euXWofbmtdyXtn2ihLJZZbQ/f9CkEcQfSL6UGWw/O2YXVKXGq1GS7BHcB0z+aMQEg+th/GPhzvPVZ/m7Z0z6LiwI1tStygTLLNMSFpZ/ZNA1cifJ/MT5vPk5ieV/aUnlyrb1uW9LoTaoZLNfZrzVv+3SMhN4M61dQtwlepKGbRkENvT7avNGMrKOX7V1WTPfBcA3+HDqcnM5ERP2xAyvb6aWftmcSDnAF1CuhDuHc77g95n9527zzvEy1hZqWz73jCCsOcsvkXPLl3QuLnhM6A/Wh8fu2vjg+NZ11PDJzdpcKuB4cYOFL3+NnmfzxHjTK+/2n1NYSE1ORbDXrFzhxJPfyjvkBInrU8RsyDPTp3wut+iTRJaJKPTwrfXafC86UbCXn6Z4Cn303bnDl7oJTIst2dsd+j+cYR1PHZGeQYV+ooGX3u+/Jb8m7KdkJtAbkWuTV+tA1o3Sr+XO092E3+vI2JH8EiXRy7xaCxEeEeQWW6b/Kc36skoOA0RnWDSck51EpWqViX9CsBjfzxGdrkw7ll5x5mxc4ZN2LAjVCN/HlTWVCoa6LVnBDG+MUT61K2eeKEMiRkCCHGu2gstBVUFbEvfxumi0xRUFSgKfNbokizSq5KXF77XifsZS20zVfVGPQsOLSC5OFlJjnHVuDqUXT0X1n73gLFjcYuNpd2B/fiOGEHgnfWrRUb6RLJv0j5uGiV8+c9724ZeGsvLyZ1VdxKJWdY3esEC0GgoXLqMKVW9mOIp3kq+OfKNaHdKJGiFvfA8e3wtv9fQYqjydmHVlL+Jff9Dgu6aROgzz6ANCLCZCf+S6FiQDGBb+ja+OSz6MUdMgZC+/WjvR4xZOYZDuYfQGXTojc4TqZqxS7xVhnqFcqzgGEOWDbGZKcb4nV/h6X8L4d7hHJp8iA8GfYCL5vJZhoz0jWRX5i56fNeDvMo8Bi0ZxPDl1zM8AKr9o6g2VPNu7ja768wz+P1nNigRUfVx+XziKwCz9kfrgNa8PeBtWgW0Yn/2fnZl7VIMo7Ox9iEezT9KpE8kd627i8+u+4w3d7xpo8Z4tuSsXTy4LiVV2ZYrKvDsZrv4FvPVl+R/9TW6nX+DLFNYXagUeLhQdGliZhG9YD4+ppqlGg8Poj7+X4Oud9W6csM193HSfwHlmy1RMdrgYAz5+eR9PgdDaRmhTz2Jxkv4J2tycyn7exs1WWJm5NnxalzCw6jcu5fKKVO5HjjybCv2aNMw6vXoTWN0i45my9GjWNf5CYlqQ4BHgN24zHVAAb4+/LVN9u/0vtMZGDWQZp7NeOj3hwAR0bIrcxfNvZvj6eLJ9ozt7M8RmvkvbH2BlNIUXCQXFo1cxNXNrm7Q76Y2ScVJuEquypqJp4snD3Z60EbIK9Inku9HXt6a+/9aEv+ExE1wvX0QRqxfLCBCIpedXGazZpTu5U+ZSX/JEa11Ok43MMHuoo28JEnRwLdAOGAE5suy/IkkSUHAEiAWSAYmyLLsWBbuCiGlVLziv3vNu3i6ePJol0cBoXEe6e38WbyZecPm8eDGBzmSf4T5CfMp1ZWyNmmtsvBiTVpZms0DR58q2uxtJeF7zyTioyKJ+eZr9GlpaHz98OjTm40bPqJfDfiXgyY4UCne0BB0aWkYy8vxaCfMpKG4mNQpUwDhmrlQJEnCLbYFZVuFKFnMV1/i0bEjp/oPQNbpKFy0iJqsLKJmi1l92pNPUWlaSJW8vNAGBCgPADM3Gzox8odETv98C349eiJ5eqLx9yfNvYK8EHea5YowGq+ujnVN6gu9e2OHSNKa0nGKcsxczGThDQv5eN/HrElao5wzf5dq5Bq2pW+7YCM/5pcxNvsDIgcwvu14/sn6h/XJ63mr/1vc3PrmC7r3ZUf6PgjvBNoraG66yPS7v/ZFcLNdoO8Z3pM5B4Ub8vMDtiHFC3UZ9DBl515XXsEmb8t3WQIGV1QqRt6salkXznDX1ABPy7IcD/QBHpUkqQPwArBJluU2wCbT/hWNWbrUOssT4KrgqxzO/JxFv+b9aOHXglOFp5S07MUnRAZfbW324wXHle3ynTvJ/UQYwfcmaHml4kcSixLx7tOHgFtvxW/49aSVpbEJoQvzEiPZMv7PBr+VyLJM4tBhnBlzs5JAVbjUskah9fW98A8NokSeUYRTusfHo/X1pdUGi9+5dONGZbv6mEXbxvNqYTBrR73E/J1Iu3QwnDxNyfrfcA0PR5Ik8nQFbHz3JioGCePu3ratw/FIksShyYd4tc+rDs+DUButTbh3uI0/fFL8JMa0GsN3I78jzj/OJhfgfLDO0zBze/vbkSSJt/q/xcIRCxnTaoyDK69Aco7BgsHw59tN12dVMWx6C8oaoBaZnygeQtZY7+eb3KZWiYbmpDNH/Jy8lpf+fgmAd3Pz2Xcmhe8yxGJ6SE0N3ass6po/B9avi3TRRl6W5UxZlveZtkuBY0AkMAYwC7QsBK7I6cTR/KPsztwNWLJa6yt80FhEeEeQVJRkJ3NQO0HIWk42d7aonJRs9aCfvH6yTfvU0lSSw4R7p+XsX0l/WqSBOyqCnPPxx5y85hqqz4g+DAWW10t9ejqyXq9kg8Z8c/Hl0lxDxcC1QUGKiqNreDga08NDcrUsCJvH69m5M1GfinWT5u/YrlFod1uMqaGgAFxdueGnG8irzCO/Kp9QF9GH1t+v3nG1DRQPgd4RvW2O15Y9dnQNwNM9nmbGgBl0DulMx2YdlbT886X2ot13I79TdJI8XDzoFtbtsogJdwpFprfW1F1N1+exX2Hrh7Bx+rnbzu4mHkIGqwdvjqXsIxtfhYIz8E4kJIiJkKvWlfcHvs+LvV5kaqepfDPiG34pdSFasg3z9Oj9MK5PHaHZJJERPrS8kl5tbubWklJez83Hf1v9kuROXXiVJCkW6ArsAsJkWc4E8SAAHL5TSJI0VZKkPZIk7cmtR0u8qUkuTubxTY9z2+rbuH/D/YAIUfN19b0k0r++br4kFovZgDlbLs4/TokWmNhuIqFeocpMv3jVKir37iU9ypP3xmsVf3JxdbGN7+9syVlKvSyGoHT9es7cdhvH4zugS7F1B5Vt+QtDbh6F3wk3hD7V4u8v/mWlTZikx1VXXfRnNq8feHW3XUcIeVzI38p6PZUJCdTk5iJXVhL24gvELlmM1k8YafdWrWh/+BCtNm7A/1ah6pnbwZJCrqsoVcLPrm9xPf43jmzQ2LuEdmHb7dtYMMxSs/bhzg/TJbQLK8esZM7QOUrYqVkrpmd4T9oGtuWeq+6xWfzrFNKJwupCUkpTqNBXsDl1s5IXoTfqGfnzSO7/7X4losLMgZwDPLDBNpz0ctKVcTrFqeduY6hR3vwcYjTazKTPSa7prfjgD1BaT7HzCqv8C6sYdwrF3yIRnSFpM8zqAvpy+PkBSBW1Jm5oeQN3xN/B4y1upLtXFK3K8nnNz5KMtnTUUhgxE/yjiIzux9IBH/Js29txvfG/TH/4JOMaUH7Rac4tSZJ8gJ+AJ2VZLmnoDEKW5fnAfIAePXqc/3SmkVidtNpGP1tv0JNfld+obpn6MLtl4vzjuKnVTXy872OuCr6KSJ9INt66kTCvMBKLExU/fcZzIpkpz12Hf3Qrlo1ext/pfzPtz2lklmUq90stFX88Z0OghekZW3VQzHhTH36E2CWLKfj6G/Lmzwe9iASp2CcMWHWS5a0h71NLvVUAjYPwyPPFf9SNuLdpg0uwrUsq6O67qExIoGT1apIn3EbUXOHX9OjgoF6niwtu0dF4tGlDMeDTsTMcFTPg1GduhWxx7ZjWY6A1+A4bZvOGUBfmurXrx60ntyJXkXGIC4gjLkA8UA9NtszQPV08WTZ6mV2ikVl2YdQK23WQX8b8wu9nfye1NJXU0lSGLh/Kza1vJrcilw8Hfchd6+5S2r7a51V2Z+2+LNL1Gw2zwcxMgNTd4OoJ4VYVm9L2wFcjIH40jK/jLXLV43B6Izy+F9wb4ErMtVr4PLUBut3luF2BVTGWtH+guckNU5AEATEwaQWsegxOrLW0O/AdRJvUaWUZZnUFd3+oLqa1bwwU/8MHgz6wq6YV32o4tLLk0nDzZ9BqMLxRt/SzU4y8JEmuCAP/vSzLP5sOZ0uSFCHLcqYkSRFA05RBaSB6o565B+dyUyshZGVNfmU+8xLm2RxLKU3hcN5h4oPOr4SZs3ii2xOMaTWGjiEdScgVRthsTMyZjDG+MfyZ+iey0Yjk5oas0/HtYHio4/2ifqbJCOzP2c/ENRPpEdYDN60b7QLb0XLRC0SeLSftqf8gV4jsOl1SEtlvzaB45UplHF59+1CxazeG0lKqT5wArRYM9kk+znITeLRz7B/37tuXktWrAciZ+S6Sqyvu8XX/3/iPu5WaoiKqRvSnfIkoHbjVNxOyYfno5ZZxN8DAWxPpE1lv6Kz178FRJmmbwDZ4aD1sEnZASFV3D7N9g/nltAjb7PujrQ/22uhrmdBuwnmN+4qjMFn81JXCl6bw5aGvw4l1ti6cIz87NvKyLAwrQMYBaHlN/f2VZgvDHhgr+s6vp05zgVXeQ9o/cPU42LcQDi+HuGvBOxhu/xEOLoYjv4BRLx5KZopMD7BqUZugmV8UCXcnNPxvqOOt9Z6+aHeNJEbyJXBMlmXrOmurALMDeDKwsva1l4oVp1Yw6udRzE+Yz5s73uSjPR/ZLGL9ePxHu2tWnl5Jelk6PcJ7NOVQFfzc/JRak51COrH4xsXcc9U9Nm1i/GIoqCog/8+NyDodhx8dSmqIpMj+mpXv3vtHKEfuyd7D9oztdAzpSLvYHvgMGkSzhx/CZ9AgIj/5BGSZkg0bbPoIuvtuMBqpPn6cgoULcY+LI/jBB/Hs2lVpEzm78YshBIy7RfH7686exf/WcQ6Tq8xofbwJnTaN6Lbd+ebhVsy4TcMvp3+hT0Qf2gW1q/O6pmB6P8c+373Ze5ncYTJbb9tqt8BuTbBHcJ3n/jWYDaE1v79u76P3qGO9rNIqsC/nHLWTT26A/5omF10ngV8kbPsYds133L4gEZAgrCMkLIH3W4qxAQS1srTrPBHuWAwRXcQY9KakweJayUy+zZ26luIMn3x/4C5giCRJB0z/RgLvAsMkSToFDDPtX3LSStN4bftriv7M7qzdfH3kazanbgZgzsE5yix+2ehlTOs2jebezfn6iDAofZtf2go/ZuL92mDMyFbUHcHyx57/2Rxy/GGmlyjSbE7iCfIIQivZa860C7QYuWYPPED0vLn4DhsKrq7IpuzV1pv/pO2unbg2bw5A9rviQVF96hShTz1J9BwRAubWqhV+w5omddyzs0WwzHfIkAZdI0kSd9/5Hglx4qt/Xcx1jTK286F2go6E5Q+8Z3hPAjwCWDN2DQOjBtIh2OKSGhQ1iN/G/XZOHaHLnrIcEU9en+xD4VnocifcskAY09r4x8C1L4mIGH0tCZCKAovRBaHumJ9InfxqqeRGn0egxGSEN7ziuH1+IvhHQWAL+3Nh9i5EIjqDbIDsI2K/vNZaZKhzvQXOiK75W5ZlSZblTrIsdzH9WyvLcr4sy9fJstzG9LN+qbQmwpyMUpunNj9FVnmWEq8a7h1O+6D2TOk4hfs7ioVXH1cfm4SYS0n2WzNIHDqUkz16KMlHgR6BSEYZw+kkdrWT0LsIY2FeKNZqtHbhn4BD4SpJo6GZSScm9IXncQ0PR+vvj2uYcPlUHTF9QTXiK6QNCCB63lyi582zu1djofH0JHreXNw7xOPVs+e5LzBhLSTXUFG5xqRXeC9CvULpG9GXtWPXsvvO3fi6CZ9x1zDxhuTj5sNn131GjzDxJtkusB0fXfsRzX2aX7JxXxRHVkC6SSDuwzYinnzfQvt2SZsh8Q+oKoKQ9tBpAjy0FW6yWgO67zd4MsFiZGvP+vd8ZX/v2d0cL9L+8yWUWkUtWce2OzLYINw1QXEQVivXQdJA66H27SNMC6vmRVprIx/YEgIcPCwugv93sgYHcw8q28NaDLOpOWrWNQGUPyZASQ56opvVE/4SIhuNNrVEU6dMIf/LrwhKSCUqDySdnrOhEtfFXMdPN/1kc63ZLx/gbllAriskNOSJx2l/+BDB99yjHNP4+9v4rVss/EbZ9hk0CLeoxksKc4TPoEHE/fwzGo+Gi8P5u/srriuz5OulJMgjiE3jNzH/+vlE+0Xj4eLB6rGrWT56ubLAa8Ycinnv1ffa6L47nVMbhXFsDAx6WHYPLBhiO6OuHY+eeRC+HQOLTBEkgbHipyTZLoLG9BHHQkxvpLnHbW5js4DqbRXkt9M2AQmAvz+2bEeY3hTHmiYuGftBZ3lzpjRbHCtIhOBWMOg5mLrZcv75ZMuYrfGPAVcvi6Rw9mHQusFrBTDtgDJxchZXUOpYw6isqeSpzU/xZLcnFV+0NScKTtAjrAcfDvqQQI9ANJKGjgvF69/6ZLEg1zO8p03Ci5er1/kthDQyRUtti0XrkpPJ+eADtMC4eDHGIzES77SbYBOfDSK2+1DeIeKD4nms62O89897Nu6a2kgutVwJkkTrLZs51U8UyTifGfTlxMoxK/k95Xe738/lQpBHkEM//JjWY+gc0tkuWMDpfG9azOt+r6K+6TTMbgqAlY9atjfPFIuWzdoIf/W8gbbX1TaY0b3B0+p31Mz0PV56N0zdYolysQ5rvPVLWDhabGfsE7N5s1GtqRaz6t4PwfVvg0GUEKTzRBHzvu0TSNkhZufleRa/PYiZvEYLzbuKaw8urnt9QKMR7QuTRQWovd9A93vE9Y3Av24mn5CbwLb0bby27TWH5zPLM4n0ibQpRrxstK3RHB032k7v/XIx8GDRPo+ePw+Pzp1szvU7JrMtXiLfX6JbqH16/ug48QX3cPGgU0gnvh/5vd1nPRcuQUEE3XsvMd86eL2+QvBx8+Hm1jdfVv+vDSXWP7bpxn1qw7nbnC9FVvkXKTvA18rldHCx+Fk7exTsfd73bxALmWbcrL7HP04UP0syhYHuNhmGvQWx18BLGSK08fBP8Gag+FmSCTs+g5pKYcS1Lrb362NSr8w3RdIcqKUFZL3A2u8xePjvuj8/gG845J8SFaAAOt9ef/uL4F81k/8r7S8e3SRmBsklyRhlo03YWo2xhtzKXDsfdLvAdoyOG82vJjnPuoodXy7ozpzBq1cvfAYOxLNrV0p/34RcXUX5tm2Ubvyd8W/9yJSrHVdRiguIY0b/GUotzAsl7Pn6CxWoXOG4eAqDd+xXWPkYDH4RetznnHuX1IomqS6FB7fCvGtEhungl4XBBbjzJzi2CqJ61j0ztsbVC/QVwq9uNMBHprf5uEHiLQGEn90r2PKwWV7rc7UcZH9fnzBw94NcU2ROcS0N9+Zd7a+pD3df27DMsItPHqyLf81MPrciVzHwINw2uzJtw6tOFJ7AKBvtXnUlSeLN/m8yIHIA84fNv+yjFWry8nAxLYBqfX0JGHszgRMnEjHzXWIWLsS/DgNvZkzrMf/u7EiVhpOwDEoc1Pz1Nn0/9i+C8hxY/6Lz+jQbyOHvgKQVYYoRnYT7BUR264k1ItSw9XVw06y6E5Fq08Jq8vKmlSsntNai6RgH/niA8QvBxcFahyRBVA+xTlGSKaJ9wjvChG+h72PgV3eBeYdEWdVzGPJKw5KzLpB/jZE3JwgBTGgrEkM+O/CZTZv1Z9ajkTQOC0K7aFyYM3TOZRMiWR+GkhK0/vazGq2PN969ezm4QkXFAZVF8PMU+Che+KOtqSq23Q92YsGRwmRxv76PwivZIm0foJupeMsnJhfk8HfOfz1g3Bcw+hPbY70fsg9LDOsATxywv/6qeiS2gtuIn4vGircRvyjoMAaGX4BoWp+H4fmz8EouDHRcsNtZ/GuM/Joza/B08eSfO//h1b6vEuEdQUJuAolFYvW+oKqAH479QM+wngR6BF7i0V4YsixjKC3FWFKi6LOoqFww1i6HjAPCbVJRIAx8dYlt24soP2lDQRIcX21xVWhdLYbcWjKk9TCIvQCXomeAWMQMtCp1eM3Tjtv6nKcMhPltQl8uHlQBDVNrdYgkibE6emtwMle0kS+uLuafLCH0czT/KNdGXYuHiwil6xHWAxmZm1eKJ/PWtK3ojDruvfreSzbeiyV/wRecNJXt0wY0vRJmk6ErF2F2hSMqYQAAIABJREFUKo3Lni8t27nH4dNeIlsz2VSNaNyX0HMKDHpBGOXafugLwbygGukgc9y6zGTXSRfXj4tJyfG278CnDr11Ny9ws3KTeJ8jnDa8I8QNFr58XRm0GV5/+8uEK9rIT98+nft+u4+8yjxyK2wXVGtHjKxKXIWLxkURhLpYavLzSX34Ecp37HDK/RpCwbffKtuaK3kmb6iB6jLH54xGeKe5iKNWaTxKs4R/2Zxte+YvKDX55vd/J2bV8aPhxv9CuxHieOpuy/X6yvoVH+vCrCZ51wr7c56mN+we99XvNmkIPUQCIzHncL8+9g8MnylcQ/esrb8tiKgcM83aXPj4mpAr2sibK9L/kfIHOqPOphC2+RwIN0d6WTpDY4aed7hgXRR8/TVlf/5Jyr1OijiwovjX1VQesPUXGnU6G/12rx5XZnw6AD/dBzOtkqYMNZCyE36eagnZO75auA0yHPhNVS4es+bLvSI3hMMWkTax6NnZMhsOvUok62Tsh6xDsOFVeDsc/nr//PqsqRbyAi4e4OFgkhLdCyavhpEfnvfHsaPXA/BKjmUBuS78IqDvI2J9IKQBORPtrdRCz9fdc4m4oo18hLdY0V6ZuNJmH1CkCAC6fdeN9LJ0p2YIVidalOdkaxXG7KMwp7+96FBD75uURMazz5L6yKM2x/PnzgWjkebvvUvs0iVNnlnqFIpS4HV/OGrSqqsqERmPbwXDV8OFuNOPt1naz+oG8wfZLwqqXDx/vA0aV2HMO91mf97axeHiJlL2Dy2DuQNgu0mAbuechvdnNMAM0z3r8++3vMY5SUGSZHlIOZNYq6AN14ZnWV9KrkgjL8syK06tIKdCpEEr0rtWujJdQ7vyRj9Rd9OsMFm78EK9feh0HGsfT/6X9qndsixTYaonClCyZo2l7N1vL4oMu5PrG9yXobSU6kSxQFy8QsjJagMsi1BVx4+T97n4g/IbPRrPTp3sb3K5U10KH9cSlipJF8a9LiryxM+iBhSMUGk4VSWQdwK8goQBH22lGjr0dTHTrq250ryrraZLs3ZCT8Y6sak+/rAUFndqpE5T4+Yl1iqG1F0C8nLjijTym1M389r21+xqY0b72a52929uuzo/OGZwg+4vGwykTH0QECXvzBiKi9Hn5GDIz8dYUoL3QKFJnfHc82S9Np2avDzQmmYP2YfhwA+Ksl510hnS//MfagrsddpSpz5I0o2jkI1G9FkmN5NVBRtdskVwSXKyrkWTsddBduzx1RZxJnP4HIjFPmuKkhttWP8vqTKVkDQbKusZade74eUskcpvjXWyz7QEIQ8Aws1mzQetHZfLO2lyw929Cu7faH/+SqLjrTDwmUs9igZzxVmMvMo8m4Ie1tKrtcvyhXmH8du43/jrtr/YecdO7mh/R4P6KN+xk4qd4strHaV75tbxnB44CH2aiDKo7Rev2LMXKk1GfM9X8MvDivpd0siRlKxdR+mmTXb9Ve4Xyphnxt5CTY54O6nJz1fOG8vL7a654qiwfB6uMxmBXab/x6tvhZtmw30bYMB/oGOtAhjmghEqzsEcA2+dQdpzikhG8g52HJve/kbLdmALCIkX2aXp+4Sf/tOeQm+9PFdor9emLFs8yOMGiTcIlSbjijDysl4vZsnAK9te4Ui+ReDouZ4ivT7a13HManOf5gR6BOLt6t0gvY+q48dJnWKZSUomdUNjyn6lpmneq+K8d/9+ttfu/0dUhrEm5zglv1n0P7JefY3ynbazH8nTE4DqEydEtSXAWFJCTV4eNYWFZL78MgCBd955zvE3KjvnwPqXLuxaszLgQ9ug3+OAJAxC7DWWWWFMbxg63Tb+WOuuGnln48jI3/hfoQVTF15B0PkOaG7SQ9K6CNXHxE3w9Y2Qd1LotDvCaBSTH+86QhlVGpUrwsifvm4opwZcI9woJbY+wM4hnbnnqnv44vovLvj+sk5H6iOPcqx9PGduthTGlby8MJaWkjv7U8pnWHzHZafK8W7th0eHDnj26I7vDSPwaNuSyr9+pbrEhTK9RVc6f/Uu0qdNs+kv9YGpGKssi08e7SwqkIaiIrz6CPnj4tWWKBttUBDhr9ZRtKCxSN5mKVJsNML6F2DnZ/VfUxdZh+CqsRB+tYiH9jMtHJtT2a3xsdIWCoix1PdUcQ5VpkSnhmjBWDN2Dkz907IfEi+Me3Vx3deAKMknG88d6aLSKFz2Rr5s698WF0ZuLqW6Uia0ncBn8Q/wXY9XcNG48HSPpy+qeELu7NmU/fGH3fHmM0W6dd5nn5H2lyi2oXUXPnb/iBwkIPa774h6+k48jYepSi0iaW0oqT8ViDjgmH7k/GHRyI54W6Q/y3o9JWssMbmyTod7W0v4VuAEUZQ35933SHtYqN/FrWri6olVJfDNSCHbCrZ1LOur4OOIohQRH21t0FubKjK5OyjZZ153cPcXIW6lWfZtVM6fZffC2xEW5cOLdZuEWElUtzTJApsLZ5jL7e34HH4yRbqd7/dGxSlc9ka+8LvvlO2K1GSKqosI9Qpl4NpX6bxsqlMyI8v/r73zDo+qzP74503vvRdIAoQOofeqICAugmtfRbDhWlbRVbHX1bWga1t/WNeGHSwoEKSDSi+hhQAB0hvpPbm/P96pyaRPyIS8n+fJk5k7773zztzk3HPPe873bDcpaNIZGKeePfCcWn+hNvymUQTfMAWvsDxjk4PMQ7j4VVJbbfw6a4JHoYXGGZ67T5qIzxXzCH/9NQCq9q42GNCaoiKcexkLK5xjY/GaNcvsfe39z3Mfz90fy9/JW+RC2q8mqpN125U1hb7KsZuxQYvBky/Lt7zPP/bDPXvAMxSKlZFvEyW5UJwtPeqqUuN27zaU5YPRoHuEwPXfynUVvYRA/hmZUbXGRNgsUukqdQQ2beQrT5+mbPd23PrKFm3pd9+LS4VGkGk3n2cD6vd0bCFV6el4zZoJQND9iwm7YQTd5rghHB0JfvwxnKONOenu85/G7/rr5NrUz/fKMEZRBk5e1WbHPLNwIdXCGHYIuH0RAF4zZuDUowelm9fB4R/QqiqozsjAMdQ41jEsjPClr9Jz4wZ8b7iB0BdfOL+651XlEG+SIrbtdRl71ZN/Vn5ukwygeqTulheHM3/qOvMIY1MHkFWN3cfLohVL+EbJ23uPYOnJN/ZeisZ5fQC8Uidt8YaVbW8GEjNJnsOLn5Q56UNvlM0wAD6cCT/fZxx7yQvKyHcQNqsnX3DsEGlzZHcaV3GEUjzR8gu4cqsgqG+d9l5bXoHNL8O1X0LvmS16n9qSEmry8nCOjaX3Cy8gnJwQTy8GXS2T3/XX4xVRzPHbdRkDfjFGL/TYL3BqExSl4+hvXsFXfuAAWb9JSePuF+Xg1jdKvhD/JB6+GeSdcKYk0wkt/me0qiocIyKJ/OB9ijduws5NVuU6hoQQ8mgrFzrbgn6RVK8pXpfkzfDBxdIAP5AIO96TXnqISR78e7rG2vuXQ4+p4BVm3oTBIxAWrGp6Lp6hskNP2TmVldEaijLMvXc9PZqXTtwo9o71z6G+7L+qRBZP6VEGvsOwSU++qraKF765y/C82tWokeFSCUEHdX1L9beGm1+Wv9e3UPLz9HZKfpcdXFwjPLBzdjb3mHULVA4O5YQMyydosW4B1cEZ7tW1FDseD8WZOAQZPXHfG6RaXeFPsgmJa0ClsWhk2+u4OMgUzDMbAji7WC6muvTpjce4cR1j1OuSkyh/3/A9TDFZ7F2k63bz2zPyd3Gm1DP55QH4aBZsfU2GzypNjEpVmdQr92rlmomnrnT8RP01E0Uz2PGe+XNnL7j6c8tjrYFrAwqvIQMtb1e0Ozbpya9NXotforE69Ucvd4IjoE8KVDpAYNYJqn0H4zD1cdhibL5N5kFpZOwdLRzVhFObZYNgrZaSY7EI+1pc/7wTLvmrccEIZIPesCFQmodv7yq49Xbjaz6REDtTFvS4+SG8Qwl9/n6coqOxc3Hh3KefAuAxcQzCbgVsf1PmgwOeEebhpaCHH8I1Lg6bQR8nD+gN3cfCjmWycYSlf9QPpsnfFYVSl8TVV6ZFgky3S9sj73ZMNT9agptuLeK7m2URiqL57Fsu73JNuW2jbDrdXgghlR/T9spUzb66LmvtITGgaBY2Z+Q1TePX+P9y5w4Zg60YVsLqAW5kDLbno9dr8C7XKNnuTfqZbPr8vRox7CbjIiHIBrtNdWnZ8AJotWgaFCfm4x5cLeUy/hVm7NAOMqMkbIjM8XXzqx/D9IuWC5M1lRDcH585sr2YaXpk+FvvwgfH5K2r7vbVzkHDr08xeUdlZon/TTe14ptqR/QVkXoRqbt2GpsaL/gVPmokJPbTP4zCTXHXSSMPsstPawjphBIOtoI+XGLnCLW6BIX2NPB6+l4mfxQ2gc0Z+WPnjlF89hQAVfbw7ngnTrhJz/xwJIxPgEJkbLc6KwvHKY9KIx93vWyuW5bXuJHf/xWc2Q5AcaoLVSUOBPTTyd5qNUajBMamvQWp4GYhx9fNT+pKVxaDT5Rhs52LC4H3L8Z18GDsnJws5iP7TBnCueNJRM0ulVkI7dj+q1HSD0gtEdN4eXkBOLob74hcTZo5dBsjszLG/UOGYL6/TX5+U4p1d2H958o7gcoSy/rhzcHNTzY5PrWldft3ZTx1/wcLV8u/r9rqxscrLkhsLiafXJiMly6k+8hCB7a5yWrQhQMWcjLE3JNOuuhiNBc/eKrAqLWhL58vSK2fkaFpMn6se5idHoedsz3e0RYWpkBqptRUw+lt5upzetxM0hpjJpu9FHDrrbiP1C029TcWWPHXj2DhWpxv/4w+K17HxfUcvBABOcctz6E9KUiVzZPreuZl+Q0XyggB9yXIrJg+l8LDZ+G6byyPdQ+QDYojRxpz31uDe6AMF6kMG3OyjsCaR4355wWpsv+onuJMGWKLGC5z2tuxWbTCdrEtI5+TSOqu9/HRSbXUuhs9j/uG3cfcYdIY2TkZp11+VMoAGAxuaa5c5Hytn3m8HuDgt1BRSGWRPanbfKk4cQbX2EiEHeYCTHftkoU7Z/6UGjTV5bJSsy6mRj58aMOfa+St8Eg63HcYBsyT5fsuXhA73XiHcGpTY9+M9amthXU6DZn0fcauP1lHIGmduffeGHZ28nM8kiZ1x0HeVV1pQZCstfhGyXCRNToTXUj89gz8/pZc/K+tgf8MhqV94JkAWYORFC8XWhVdGpsy8jWVpZzddIjJ+wX2zjW8lieLbvQt+7pPnoGw0whfNI3I95YBkP2f/1C0foPx1rQgBbJ0KYAHvjJ/g8TV4BZA5rnZFKXIO4TAh56CuctgpkkDhIBecqEw97hRj8M7ov6Ew4fJ366+TWtgO7mBtwUNeL1eSGurAZvbneeP/8rFXz0nfjNPcdN7gO+MlsVHLW2I4OQON6+BxUfg8nfa3tnHFL0HmnHQesfsCFY/AgcauOtpDcd0VdM5iZB/2hh3r60yava7neciOoXN0e4xeSHEDOA/gD3wvqZpLzY0trzGjqvjAWpwCa2iW2UVB0Mvh2GLAXCMm0af+M8hdIjh9r9kyxZKtmyh15bN8sOsfczY/dzk9r62vJwzb+8kYEpPhLsxFOE8YDC4jILqSgjsA1N0KYxj7zYvCAoyql0a8I6AmS/LuHNr8Y1CinXlNH+fwz/IEEZBCqy4XaY21lbLRUpLBS411VJ3BmDYAiklsPtjWal49acyQ6Yky3yflsxHj7Nn+6wthMbJNYKkeOgzq+nxtope92fQlU2PPfOH9NCP/SJF3fThrrR94OgKwsSpKM6E726xfJxLX7W8XdFlaFcjL4SwB94GpgEpwE4hxI+aph22NL6o2viHK5yQRmhqHVEuvfcMBC5eTPbSpQCUHTiAp5MnVBZR/PUb5B7yp9tfSgxSweWHj1CWXsXZL84AMmfdb/587HQqkzg4wZ1/mk7e+PjmePA0Ec0yZdRtjX4HTWJnLxcXG5IKyDsp/+HjdDLJ55KNejIDr5LCT/81ucjctEquH9RUw/9mywuXaeph2h4Zmjr6M/SfZ8xfL8k2j3nHTGrb57Imji5S6+boLzDr1bbF9zuKlvRDLc4yb6ZSnm8sBFumOy+m6yC/v2V87OpnlLu+6pOGm1grugzt/d8yEkjSNO2kpmmVwJfAnIYG+5jIpvt2L6F6ymON5td6TjN2r6nOzqZ0yuekbPMlZYsfpdnOVKZnGVrHVRw5ZLZvxLv/JXjJw43P/vbNsudke1fr+feEhO9kLDWzzvXvjSFSl/70dmko9uoKWRzdLLdRS1wjf29+Gc78Drs/kr/1/O8yudALsjrRPQiEnbwr0C1KM+Uxo+a7rdBntgwjnVgvm4DnnujoGbWMisLmjzWVAwCjRtK+5cZtZ3Vy1V51QoA3x8vcdL8e9ZIBFF2T9g7XhAOmvdtSADNtWSHEbcBtAP2dpVcde2Ua9vaQ4d6TBvxnAJyjo4n5+SdOzr6MmoJCTi94GnA1vH5ydSDelX8n7K0PqPzNWPkX9d23uPZvRqaBac58exI2xNhY+eQGCNaFhkyVHz+aaZ7vDLJ9np5x98oYuz7McnKj8bXsY+AVAYUmC5duATD2HnkH4xsls3v0cxh5q9xuS8TqPNvPr5AXxdwkWXRVkiNfm/Z0298j94RsUn3F++Yppdag3ESOtyzf8sK2pskF5tTd5tszDkLKDvjxbuO2La/Ki/PMf8NXf5Pbrv4cAnrKEJxCoaO9PXlLCkhmeXCapi3TNG24pmnDz3lAwp2zsddFba76vgCtibQ5px49wM6Oc199Wf/FWkHBuu2ybd/Z09i71BC+YFTzDPz5xDSzZ80jkJEg/+GL64RwTA18VamsKuw+Hvx7yXRG32jjhUGYnNqD38g0Oj9dIcy0Z+DeA7ILEMj1hhMbZA/PEbc2P7PmfOLqI/XLQRp4kIVo2UcsdyJqCXs/k5//zaFwbJVMmbUmG1+E/5gUdZkugJvy6VzZ7LooHea8LbWYAL6/xWjgA3qDj9REQtjJoqNhMjGBqHH1j6no8rS3J58CmOqZRgBpDQ0OjerPlXe/TFH+Q1z97684U15DTnElgZ4Nh2yEEFBbS3VaeoNjCtespjTLGZcwN7zue6cVH6Od6V7nn/PdcfIf2dHV8ngXHxmn1Wrlou9U2TkKv2g4rsvWKc6EyNHG2/ohf5Piars+hDF3mWcDxUyWMXqwnCpqK9wSD68PkusMZ/+UxWsgF2Vby2d/lQu6puhCfFahsgQ2vmB8budgXnCnpzRP3sXpGXilDFW6eJvfBVzzhbyD++QvxuKmWS/DuHsa1o1RdGna25PfCfQSQkQLIZyAa4Afm9rJ0yeAhxfIPp/rj2Y2Mdoct1GjcJ84ATsvY35wxhNPUVNhh2NMX+vfhlsDn0hYsNp8W/5poxrkiFukVvff/4AZ/4aFa4zjTIW//KKlca8ohtIcCB0ke6aCDD3594BLnq+f7tlrmvHxkBus97msjbMnPHQKFv4qFxWD+sv51lS0bGHTlLoGHqRy5vLrGta6bwmmayxe4XJt4cT6+sc2NfAD/mpci7r4KeP2iQ/KcIy+QYcee0ejxK9CUYd29eQ1TasWQtwFrEGmUH6oadqhJnYDYESUH/3DvHjyx0NcMTQCB/umr0fOvXrR/X8fA5A0/RJqC80Xuxy7nwfdjtbSfQxMf07eyhfXubCNvUc2TwYI6mueBRNhIhfgGy1/5x6X3p9bgOwqP+LmxrMsfKOMj5vK97cV+s6WP3s+gb2fyhBOYGzT+9XFzd+8yTgY72q2vwkXPV5/n5agb3gy6xW51rH7Yzi8UoblLtfdVe79HDa/JL32v34IUSZGfPhC6DZWOid6GV8hYM47HSeFoehUtHsumqZpv2iaFqtpWg9N05qtBezqZM/8MVGUV9WSlt94U5Dee3YTvORhun38kWFb5Dtv4zfNPPbuEmehn6gtMfZuWW1bF6c6LfKEgAkPwKhFxu48YPTmVsqWgbgHSKNtqZCrLoOvbb1SZEfSbYz8fXpr02ML0+Xi6p/LoEh/x5NrjHHftRtuMZE0zj5q+TjNobJE1mzom5D3uVT+HnaTrAg+8pMMC9XWwA9/l+NiJkPPi+svegf1MRp4PUOuh35/af38FF0GmxMoM6WbvwytPPXTIT68aUSD4+zc3PCbP99sm3PPngQvup68eFnc5NwtGLfxU9tvstbCxUuGZU5vg1U6vXxLfVAteZiBfeTvLF2IoCXt3ea+27J52gr6C9vP98kLVUGK9M5NG4xUFMMLdVINizOkFDLIUFjoIBnTrjER8Tq9XRrilsjkntwkq6+PrZJ3Ao668KCpwF2/OVJM7/R2Y6U2QI+Lmv8+CkUzsWkjP6y7XEg6lVPSxMgG8OlG5MRc8AzC49WN1ptYexPUV/5UlcPvbzffyDi6yNv9bxfK53W9vwsR0/DSzg9g7aNyIXuBsVG6wZs2JW2fLABz9pKL13rFTXuTf4myPNl7wHTNojEqS+WCKMheAyCzoFx8zL3zCJ3DknFQZtKAjNcrvXxFO2DTpYOO9nbcMbkHZ/JKqalthQJh8AA8plyMxwPt2AnHSuQUV1BSUUcKduxdcP+Rlh0oyCREpY/jX+jM09VArNVlGdVNgTStJwDp6eedlIui4UPrN5n5+58w/yfpheuzlZrD6e3Gx4m/Gh/XDYO5+ckitJxjMg3WyQPuPSj1fxQKK2PTRh4gzMeVmlqNnOJWpLU5OMO1X5y/oqZWcDq3hPzSSoY/t46/vNWMuHJTBMTKhdrrvmk4BfNCw5IM9LIpMi4OkGqSsjjwSikHce4UpO4yxuNNCeojM1iixktPvrkcXlE/nXPmSzD7tfpjPYNlIVfqHqnN01kWvBWdDpsO1wCEeMkq2MNphXg4O+DubDtTPptXyr9+OcK/5g7E171lFaIp50q58cMdnMwuITZYxtxPZLcyLGWKnR1Mf7btx+lMeIVJCQrvSKmvvv8LmYt++EfITIDd/wPPMJj/o1QY3WiikddYSCsgVhp5TbMs/FaX1L0ySyppnXx+6VKZ2WQJtwDIPysVJMfc2fzPqlC0kE7gyUsjv+DjnfR/cg1/nsxtYo/2R9M0Bj21hgkvbeDXhAyWbTnZ9E4m/LAvlfH/3sBJnVFPzDR2VmqqwlfRAKGDZRhk4BXGbfFPSPGuyiK5PaCX3D5sgVFKuUcji/G+UVIf6K3hTUtBV5XJbJzQOKmtP3mJUVTOEi5ekHVIVjHrM4QUinbA5o18nxDzpgcPfnegg2ZipLiimsJyY/z8x31pzTbOmqbxjy/3Nfh6YZlq0dYmuo+TaYhglE/2CDbvzuUZLHXv79rVeLMXfeZObpK8I2iMzEOyAjd0sIytT3648XCZaRVrYO/Gj61QtAGbN/L2doJf/zGBa0fK2+pm3DS3O3kllYbH/cO8SM0vI3rJLzy28iAV1Y17fKZe++xBoZx6wVwfPa2gzLqT7Wo4usLfvpPhGZAiZg8kmklUAzIGrvfsG8K0iXhj+vrVFfC+Lv0xrJkNyy8xkTroCllQig7D5o08QN9QL16YN5AF46LILKzo8JBGrs7If3jTcN6fb6w4/eyPM3z6++lG9z2dK0M0Uf5uPDG7H0IIZg8y5kpnFDRe+KVoJvqOSG3RU/cIhJG6fgGleQ2PO2FSQNXc2oTgfrIl5D371KKrol3pFEZeT6SvG2VVNZzNa723W1BWxZpDGfXTFVtAbrE08n7uzoR6u/L4bGPXqOdWHTHz9Oty26dSRvbTm0cRpFtUXnpVHKvvnQDU9+QTUgs4m9dAo3FFw+hDIA01JG8uk5fI33WlD0zRy1Dc+EPzFmj1OLlJvSGFoh3pVEY+3FfGOCe+vKGJkZYpr6ph8NNruf3T3bzwawvzz01IzCwCIDpApsvdPD6aZ+cY89OPpFtuEFFQapQK9vcwZuM4OdjRK0jqkDy6IoHyKmPIZ/abW5nwUus+b5emt64YKf9M247j4iN1/Bs7jl4SOnJ0295LoWgHOpeR9zEuZJkawuby4LfGRduMgtbLyR7LKCLC1xVvV2MRzbyhRn2YpfGJrDucWS+slJBmXGxzdTS/Rbe3M3qAI55fR3ZRhdlFoVXFYF2ZmMny96Br2nYcOzup037kR1j3NMQ/KSuRTSnJBmdvWXGsUNgYncrIDwg33nr/57fjLdpX0zR+3J9m9ry1ZBdVEOpt/g/t5mQ02rtPn+OWT3Yx642tnCuppKZW44Fv9nPP8r0APDqrr9TBr8PPd8uinqLyau78fA/7U4xytPpYvqKZuAfAk/nNa5rdFCEDoeAsbF0qG5Ts+D848A0U6RQm80+Dd3jjx1AoOohOZeQBPHXFUHm6uHhZZQ13L99LUlZRo/tlFJp7X1lFFdTWajz83QEOmXjYzSG3pAJ/d3M9GSEEP9xp3vzjSHohz646zI5TeXy7O4Xckkou6R/MrRMta3+bXsR2JOex9nCG4bk+RKRoAS2JjzdG3cXU+Cdkt6ZlU6SqZfYxWTilUNggnc7If7RAijtpui6CW45n89P+NC5eupk7P9/Dt7tTLO435y2pZ/LhTcOZNzScvJJKMovK+XLnWa57788WzSG3uNIspq5ncKQPa+6dyLrFkwzbjqQXkXLOuHA6KbbxbI/v7jAWxnz2xxlGRkk1xeRctfjaYURPlC0W61KUJlsGnjulmnYobJZOZ+SHR/kRF+lj0JhPSDMucq46mM4D3+yntk78uryqhqwiGYMP9nLBz82J1Pwy1iRIT7mgrIof9qWSXdR0nD67qIK80sp64Ro9vUM8DQuyACeyiw3ZMa9fHcfVIxpPsRvW3c/s+egYP/zdnUhurRKnou0E9YW7d0kpY2fd3ZZpoxUwlwxWKGyITmfkQS7Abk3KIbuogr1nzuFgZ35bHvPIL3yw9RS/HclkZ3Ie649mme2rvwQ89ZOxNds/vtzHos92N/nemxOz0TSY0qes7lY8AAAgAElEQVRhj9zeTnDdqG7ERfpQWV3LuiNZ+Lg5cvmQcLMF1oZIfvFS/HVaOLMGhdLd341kFZPveOa+a2z+MeoO89esFRpSKKyM7ah9tQD9Iufklzfg4eLApYNCOZJeyPGsYkNnvGd/Plxvvy0PTsHHzYlxPf35YOupeq+fzC6ut60uW5NycHW0rye3UJd/zR3I8cwipr22mcPphQwMb1m+9q7HZGm+EIKoAHd+P9Hxmj0KoP/lUgAtajws2irlDFbcbmxAolDYGJ3Sk799Ug/cnewpqawhs7CCEC8Xfrp7PInPzWTHIxdZdKoCPJyI9JNdeqb2CeaVK+vLD1c3kaZ4OreElftSmTkwpFkeeahJyqe+y1VzEUIYMnCi/N1JLyintFLp2nQ4sZfAo5kQMkBm3Qy+Bh4+CxHDmt5XoegAOqWR7xnkwVe3GxcoNcDZwR5HezuCvFzYcP9ks/HT+gWz9SFztcHewfWbIBeVV1NUXlVvu55tSbloGtwztQnNEx0ezg54ucibpe5+LTPypvQIlFLEJ60hRaxoO3Xz4V0av6tTKDqSTmnkAbPFzen9gs1eizJ57Zbx0Tw6qy8udYqPegV70CvIg49uGkH/MOM/6cVLN1FdU0tJRTWrDqSbLeKezC7G2cGObi0w2ME66YLINhh5vd78vP9u55tdZxsdezSjkCd+SOCHfam8uvYYh9MsV98qFIquQaeMyQNmzUOGR/k1OO4xE10ZU1wc7YnXpTqO6eHPyewSZr2xhczCCh5dkUBFdQ0r96WxeFos91wkPfeTOSVEB7hj14xQjZ65Q8N5afUxovxb39pN78lXVtfyr1+OcOXwhjN0Xlp9jPVHs/hEJ5T25vokdj56MYGeLWhGrVAoLhg6rZEHePu6ofi6OVp87dqRkTg7NE/dz8XRnthgDybGBrI5MZuvTLzlpfGJLI1PJMzbhbSCcib0CmjRHO+Y1IMJPQMZEN76W3o7O8GVwyL4ZncKxRXVaJpmsWIWINK3vob5Ja9vZs/jzWxGrVAoLig6bbgG4NJBoYztadnovjBvEE/9pb/F1yzhYG/HJwtHEtXAAmmaTgI4JqBlHrkQgoER3g0a5eby7ysG8c9LelNVo5FZaJ7Pv+FoFtNf20RFdQ1VuvDSpQONedt5JZUdLs+sUCg6hk5t5NuD2yf1wMne+LXsePQiXpw30PB8yay+HTEt7OwEQ7v5AvUlDh7/IYHEzGIOpxVSWFZFdIA7/7zEvNvQuBfXs+9sPgqFomvRqcM17cG1I7sxb2g4e8/kU1pZTZCnC9eM7MaQbr4UlVfVW8A9n+gXYI9nFTMxNhCAAyn5pJyTGvQJaYUUlVfj6eJAVIA77/5tGH1DPZn08kbSCsp54Jv9ZpILCoXiwqdNnrwQ4mUhxFEhxAEhxAohhI/Ja0uEEElCiGNCiEvaPtXzh7ODPaNj/Jnax5i10zvEs9EF3vOBv4czfu5OfLnjDFU1tWiaxjXL/jC8fjavlIKyKrxc5DrFjAEhZplASVnFZBWpzlMKRVeireGaeGCApmmDgERgCYAQoh9wDdAfmAG8I4RQPc6sQLCXC8ezivnsj9MkpBZSWmnU1d93Jp+T2cVmhVd11wJW7Ek9b3NVKBQdT5uMvKZpazVN05dh/gHoO2fMAb7UNK1C07RTQBIwsi3vpZC8/FfZXHrjsWxDB6rF02K5Y3IPdiTnUVheXa/Q656pPbl1QjQBHs6cyC6mtlZTC7EKRRfBmjH5hcBXusfhSKOvJ0W3rR5CiNuA2wC6dVNd65tiQLg3C8dF8+G2U2xKlG3n7prSkzWHjNrzl8eZf9WLp8tF2MPphazcm8bXu1KICXRnfZ3KYIVCceHRpCcvhFgnhEiw8DPHZMyjQDXwuX6ThUNZdB01TVumadpwTdOGBwYGtuYzdDlun2SuXW5nJ8x0crwbqB147vKBuDvLqJmSSFAougZNevKapl3c2OtCiPnAbOAizRgDSAFMyzIjgLS6+ypah14qAeDzW0YBEBPoTriPK1cOj2hoN6ID3BnSzddMelmhUFzYtClcI4SYATwETNI0zbR10Y/AF0KIpUAY0AvY0Zb3Upjz+5KpONnb4e8h5Qq8XBzZ9vDUJvaSDVL0pOaXmTVHVygUFx5tza55C/AE4oUQ+4QQ7wJomnYI+Bo4DKwG7tQ0rabhwyhaSqi3q8HAt4T7pxl7kY57cb3hsaZp5JVUWmVuCoXCdmiTJ69pWs9GXnseeL4txweoqqoiJSWF8nLbz+92cXEhIiICR0fLMXFbYGzPAD68aTgLP94FyPaEZ/JK2XP6HG+uT2LrQ1OI8G29YqZCobAtbL7iNSUlBU9PT6Kiotqs/9KeaJpGbm4uKSkpREdHd/R0GmVqn2Deum4Id32xl5s+2sHZvDLDa5mFFcrIKxQXEDavXVNeXo6/v79NG3iQRUf+/v6d4o4DYPagMAAzAw9QXGH97lObErNVI3KFooOweSMP9as2bZXOMs/GyC+1flx+/oc7mPrqRqsf15TSymquevd39p45167vo1B0NjqFkVe0D09eZmyocs9UubxyzmTxdXNiNiOfX8eD3+43bMsrqeSZnw5TXtW8dfTqmloAmmif2yY0TaPfE2vYkZzHku8Ptt8bKRSdEGXkm8mKFSsQQnD06NGOnorVWDDOuHbwj4tjcbQXZOi06n8/kcuNH+4gq6iCr3elGMa9svYYH247xbe7U+odzxL5ZQ33zDVle1IOp1oZ0klINbY4rKiupaJaJXIpFHqUkW8my5cvZ/z48Xz55ZcdPRWrsuXBKfx2/yTs7QQRvm6cyZOGdmdyntm48qoaTuWU8MWfZwCpaPne5pMGT70hmhP+Sc4p4br3/2TJ9wda9Rm2ncgBYErvQE7llND7sdVqDUCh0KGMfDMoLi5m27ZtfPDBBxeckY/0czP0kO3m58bpXFnTVrcxSWp+Gb8dyTQ8/3h7Ms//coSV+xovZD6WUWz2fN3hTI7rjn00o5Coh1fx2R+yH+3+swWt+gyH0wrxd3di0aQehm2PrDhIQmrrjqdQXEjYfAqlKU//dIjDaYVND2wB/cK8ePKyxtsErly5khkzZhAbG4ufnx979uxh6NChVp2HLdDd341NidnU1Gr1jPzeM/nsPVO/s1R6flm9baa8u+kEAO5O9lTX1HLLJ7twcrAj8bmZvLImEYAPtp0CwNnR3OeoqK7Bwc4O+0Yap2cVlfPj/jTs7QRx3XyI8HUl5VwZ20/kMvvNrUzoFUB6QTnf/32sQWdfoehKKE++GSxfvpxrrrkGgGuuuYbly5d38IzahxBvqYnzWnwiJ7NLuDwuzNCN6oFv9rPxWBZDuvmY7ZNWUMbD3x0g7pm19Y635Xg2B3XedEllDftT5EWisrqWr3eeZZ3uzkCveJRfWsV17/1BSUU1tbUag59ey31f7Wt0zvoLz+0TY3B2sGfLg1MYadLcZcvxHJKyivlhr3V09DVN42R2cdMDFQoboVN58k153O1Bbm4u69evJyEhASEENTU1CCF46aWXLoiUSVNmDQjlpdXHeGtDEgCTewexeFpvJr68AZCG+rYJMYzp4U9eSSW3/G8XKefK2HJcxsQzC8vNxNNOZEljKIQ05Ff893fDaw9+Zzn+vv1ELm9vSGJ6/xDKq2r5cX8ab1w7pME5H0otwN5OcM9FvXTvJSitqp/rn1/avAXgpvhmdwoPfnuA/7thGJf0D7HKMRWK9kR58k3w7bffcuONN3L69GmSk5M5e/Ys0dHRbN26taOnZnWiAtyZYWK4+oR61pMtHhXjj4+bEzGBHvQJ9TQYeIBjGeYhnrPnynCyt2PzP6fg5tR4Y7B5Q40a+EfSCzmUZoynpxc0HBLaezafnoEeZr139Y3Y19w7kY8XjACgyApFXuVVNTz4rbw46bX8FQpbRxn5Jli+fDlz584123bFFVfwxRdfdNCM2pe/je4OSO+7T4gXXi7mN3t+7k6Gx9eP6m72mr6hOMj8+A+2nqKbvxuRfm5s/OdkVvx9LA9Mj8US9+samwBsOJbNoysSDM+36i4kmqZRY5Jwn1lYztakHCb3Me9D8NrVcdw5pQe9gjyY3DuIAA9nisqlJ59dVEH84Uz2tLBoqqqmlj6PrzY8Tz3X+FqEQmErdKpwTUewcePGetvuueee8z+R88S4nv48O6c/k2KDABn+SH7xUk7llJjJFMuxAXx3x1gWf72P07mlnD1nVJv+p87jTdKFbII8XQjydKFvqBduTg488/NhAL64dRSbE3MI93Hl4wUjuOmjnYZj9Ary4HhWMekFUipiaXwib65P4rObR/H2hiTmDglH02BK7yCzeXX3d+efl/QxPPdycWD5jrPcNbWXmfJm8ouXNvt72X4i1/DY2cGOlHOljYxWKGwH5ckrzBBCcMOYKLNm4CAbjsRF+tQbP6y7L5v+OYUwbxeydIVU1TW1rNAtdP5r7kCz8S6O9iwcH83AcG8m9ApgbI8AHp4pDfLk3kH0CZH9aW8ZH83js/sR4OFMmi6D5831cq3gvS0n+f1kLk/+eAiAmAD3Rj9TYbkM1ZgaeDBegJqDPu3zq9tGc9XwSCXLrOg0KE9eYRUCPJ3JLq5gZ3IeL/xyBJBpk9eNsty3d+Wd47CUGfnxgpEcSS9kSh/pnYf7uJCaX2ZWDauP15dV1TAmxp8gk8VeS1Q1ULB18dJNzfbmD6cV4u3qyKgYf7Ym5VBQVkVtrYZdI+mdCoUtoDx5hVUI9HBmc2I2V777O3t0aY0/3T2+wfH2dsJidlKIt4vBwINsjrLleA5TXtlo2JZTbPSiJ/duui+wp8m6wu0TY3jKRLMn9tFf643/bncKZ3KN4Zjqmlp+PpjO+F4BAHi7OlKrQVG59RU7FQprozx5hVXoEeTBbya9Y5+7fAAxukrathDqY/TSw31c6RvqyZH0Ir64dRSH0gqZFNu0kX/z2iG8tu447904DGcHe0PoBaCyjpefV1LJ/d9IQTa9l59TXElldS1je/gD4OUqM44GP7OWq4ZH8NJfB7ftQ7aSqppazuSVGiqWFQpLKE9eYRXuntqTO6cYZQX0WTptZXh3Y2HT5gen8P78EWx9aArd/d2ZNTAUd+em/ZQh3Xz5ZOFInB1kmmVonb62pumas/6zxfD42mV/cCqnxJDCGaILC0X4Gvf/elcK+8/WrwSuS22txi8H05vU+mkJ/7fpBBe9uslMbkKhqIsy8gqr4OniyAO6NEhnB+v9Wc0aGMLXt48h6fmZBnmDthaheTg78M2iMYbnl76xlZKKasqrasgoNDZ9+f1kLl/uOGPQ8wnTXRzGxPibHe+1dYlNvueqg+n8/fM9vLflVJvmbsraw9K4b0vKbXRcba3WaK2B4sJGGflmYG9vT1xcHIMHD2bo0KFs3769o6dkkwghWHbDMNbcO9GqxxwZ7YeDvXX/VOuGOB74Zj/v6Cp937txuEFfP72gnC3Hc/BxcyQ22NMwpzeuHcLIaHmXsfFYNhkFjXcEO67L5DmQ0rTX3xw0TTNUFNfVGarLoysPMuaF9VbXfVJ0DlRMvhm4urqyb5/UUFmzZg1Llixh06ZNHTwr22R6Jyn193N3YulVgwnzceWaZX/wa0IGawTERfowrV8w0/oF8+epPNILykjLL2dMjL+ZUNpfBofxl8FhJKQWMPvNrfx5KpdQb1dGRPlavNPQZwelN3ExaA4r96Zyr4mmT10vvaK6BoHASXdH9dsRuVbyw/5U+oV5tfn9FZ0L5cm3kMLCQnx9fTt6GgorMG9oBMO6+xLgIat4azXzit5IPzd2Jp8jNb/M4LXXJTbYEyd7O/75zQGu+r/fDXIHNbWaWfOSs3ky5HMiq9isarelVFbXmhn4eUPCSS8oR9OMx5zw7w1M1usNVVSTUyzrF/44ad4jQNE16Fye/K8PQ4aV27uFDISZLzY6pKysjLi4OMrLy0lPT2f9+vWNjld0Hhzt7dj12DTWH81k4ce7DMYYIMqkIGx0nTi8HicHO4K9nQ0N0R/67gDr75/Mg98eYNXBdH64cxyDIrw5nVuCq6M9RRXVvL/lJLebaN+3hLWHMwyPl986mkNpBXy/N5XMwgp83BxJzS8jq0ga9bWHMrjt090ADOnmw4GUAoorqvFoxmK14sJBefLNQB+uOXr0KKtXr+bGG28085wUnZ9JsUHMHhTKM3MGGLZdO1IWck3rF0zf0IbDHEGexjTPzMIK3lh/nFUH0wGY8/Y2nv35COdKq7hLF+e3pMtvypLvDxL18CpW7k0lLb/M8Ld275d7ueuLvYCsvB3Tw5+JuhTS0S/8Rp/HV3PRq8Ywot7AA9w8PpqaWk1p7nRBOtclvQmP+3wwZswYcnJyyM7OJigoqOkdFJ0CezvBW9eZN4Lx93BuVkWsQ52qV728g54PdU1RZg4I4fM/TrP6UAarEzKYMaD++kVCagHLd8gWi/qwzJvXDuGywWH8sF924frs5lGM0t1Z9ApqOkf+gemxBHo4AxB/OIPeOukIRddAefIt5OjRo9TU1ODvb/n2XdH1uH50dy4bHMa7fxsGwNGM+tku14/qRkygB2m6hdenfjxUr+F4yrlSZr9ZX8L65wPSuLs42HPL+GhD5S3ITB9H+8ZTSifFBhHoKY38K2ubTvdUXFhYxcgLIR4QQmhCiADdcyGEeEMIkSSEOCCE6NS98vQx+bi4OK6++mr+97//YW/fuD66ouvwl8FhvHntEGYMCOHivsEcSTemKk6MDWT/E9N5fLaUUtALsGUUltP7sdXE63LdNyVm88FWYw79bRNjDI93Jp+jpKKasqoa/HUeuSmPXdqv3jaAYC9nZg8KpXeIp6HrF9CmhV9F56PN4RohRCQwDThjsnkm0Ev3Mwr4r+53p6SmpqbpQQoFshm6npV3jqNHoDueJr1lP7tlFDd9tIOEVHkhuPWTXXx+yyjmf7jDMMbD2YG7p/Zk2eaTgJRa+H5PCoAhE8iU+WOjuHFMd6KX/ALA2B7+zBoYyiX9QwwevBN2PDG7H8/8fJiE1AIGW1AU7YxomsZdy/ey41QeH900ggHh3h09JZvDGp78a8CDgKl7MAf4RJP8AfgIIUKt8F4KhU1z09gow+NB4d5mBh4gwMOZ7+4Yy926RVjAzPP3cnFg+5KpeLo4sv/J6bytWyd4/Acpqzy5t+V1ICEE2x6eyoJxUSy9Ko6/je5uMPB6rhgaAcCXO88CsCs5j/VHO58kQkJqAUOeWcv2pBzSCspZdSCd7KIKrv6/33l9XaJhTaMhqmpqqay2nryErdMmIy+E+AuQqmna/jovhQNnTZ6n6LZZOsZtQohdQohd2dmqpZqic9PN3415Q8K5ZkRkgzLEzg72zB1i/Hcw7ai1fclFeOkuDN6ujgwIN2b1PHf5gHqG25RwH1eevKy/WWjGFH0rx+U7znAyu5i/vvs7Cz/exV1f7OFEJ2lOfjyziNlvbuVcaRVvrk8iR5cuesfkHlTVary+7jhLvm88zXrG65sZ9PSa8zFdm6BJIy+EWCeESLDwMwd4FHjC0m4WtlkMBGqatkzTtOGapg0PDGxaUVChsHWWXh3Hi1cManRMTKAHT+ji9B9vTwbgi1tG1cth7+5vbIgyvmcA1sK0veLPB9JZ+PHORkbbBhkF5Ux7bbPhubuzPbkl0shP7xfMTJNsJX2jGUucyC6hvMo2PPmK6ppG52oNmjTymqZdrGnagLo/wEkgGtgvhEgGIoA9QogQpOceaXKYCCDN+tNXKDovpl757ZNiGNuAEf/yttHMiQszi/e3lmfn9Aek+JopTWnv2AJbjpvf6WcXVRh6CwR4OHPlMKPJqdvDV9M0Xl5zlFUH0tt/oi3gzs/3MvbF9e26GN7qcI2maQc1TQvSNC1K07QopGEfqmlaBvAjcKMuy2Y0UKBpmm19uwpFB2Nq5JfM7NvguNEx/vznmiFW6UJ1w5govrpttOH5ZzfLfAh3ZwebL/D7audZs+f7Uwp4UNdLONDTmfG9Ajj+/ExcHO3Yczqf2lrNIOmQVVTB2xtOcOcXewz7W1P2uTUkpBawTicTvd9KwnWWaK88+V+Qnn4S8B7w93Z6H4Wi0zI4wocRUb4smdmn6cFWxDQENK6nPw/O6E1eSSVDno0HpDRxZqFtefb7zuaz67T0zmcNrF9E5uIoU5od7e0YFO7D7jPneH/rSYY/t46Uc6VmchV66jamtxa1tRrrj2aSUVBOeVXDmXlfmCwQz3tnO6WV7dNpzGoVrzpvXv9YA+601rFtgYyMDO6991527tyJs7MzUVFRvP7668TGxnb01BSdFFcne75ZNPa8v2+wlzPzhobj4+qEEIJB4TKdMr+0ipn/2UJcpDfLd5xlYLi3WQvHnOIKCsqqeOKHBCb0CmRRK/V3WoO+McpTl/XjpnHRHM0o5OaPd5GaX8b/3TDMbOzQ7r58sPWk4XliZpEhZfWhGX04nlXE93tS+WhbMg9c0tvqc92ZnMfCj3cBsgju+TrN7PUczyzC3k4YQjUHUgoa1EhqC51L1qCD0DSNuXPnMn/+fL788ksA9u3bR2ZmpjLyik6HEIKlV8UZnpsqbB5JLzSkdB5MlR2z8koqySmuYLrJoue2pNzzauQTM4uICXTnpnHRAPQJ8WLbw1Mtju0b6klVjUairvJ4c2IOh9IKiA32YNGkGMqqali5N5W3NiQxf2xUoxlLrcG08cz3e1INRj6nuILknBKGR8nv+2xeGTMHhHA8s5hjmUXsOXOuXYy8kjVoBhs2bMDR0ZFFixYZtsXFxTFhwoQOnJVCYR2cHOxIfvFSPrppRL3X3t9ykqHPxpu1RdRzvmLaxRXVbEvKZVAzC51CvWUHrzJdqGT90SxyiivpFeyJEAI3Jwc+0H3W07klbZ6fpmkcTCkwrGmYaheVV9cYvqf7vtrHX9/9nV8OpvPcz4fJLakgwteNNfdNpLu/GwmpBRaP31Y6lSf/7x3/5mjeUases49fHx4a+VCjYxISEhg2bFijYxSKzs6oGKNHP6N/CKsPZfDcqiMAVNdqjIz2Y8cpoyb9lqQcpjRQnGVNTmWXUFxRbVHQzRKhdeoEzuji8aZN3/VjMuuIybWGFXtTWfy1LBXa8MBkXo0/hpO9HU9c1o/HVibwanwilw4MNawL/P1z4+KvvoI53Me12RlOyTkl2NsJIpuZbaU8eYVCAYCbkwN3TO7B3CHh9ZqkuDvZ8+qVg7k8LsywbcFH1sutL6+q4ZmfDpNdVN/opuk6X+k99KYI93HlmhEynfLq4ca0yiAvY1gm2FNv5Nu+wLzleI7h8cq9qZRX1TK1T5Ch8ft/N55g9ptbSc6tv/irDxUFe7kY+gA0RkV1DZNf2ciElzZQUtG8hdpO5ck35XG3F/379+fbb7/tkPdWKM4nD82QmT5f7zKmKx56+hKEkBeB168Zwkt/Hczcd7ZxKK2Q3OIK7ITA172+pk5L+G5PCh9uO4WGxpOX9Td77XadLn6wl+VK3rrY2QlevGIQT17WHxdHO2JDPFmxN4XrdP0BAHzcHPF0ceBkTusrfVfsTcHT2dHQDUxuSwVg0eQeBHs54+vmyLnShrN4RkXLGHyQpzMp58r4z7rj/OPiXg2O/35PquHx6oQMrhgW0eQ8lSffDKZOnUpFRQXvvfeeYdvOnTtVn1fFBUtvXdPyAA8n3J0dcHMy+oNODnbcP10mHFy0dBPDnosnqw0e8cnsYkMFbmNFQZbE2RrD1ckeIQQ3j4/m57sn4ONm3F8IQb9QL7Yez6GqFWsLN3+8k/u+2s8tn+wir6TSsP1MXikezg70D/Mi1NuVvU9M5yUL1c+h3i68f+NwgwTF3KFS5sL04mqJYxlFuDvZ083PzdCYpimUkW8GQghWrFhBfHw8PXr0oH///jz11FOEhYU1vbNC0QkZHOnDsedmsOmfUyy+3s1P5trnl1ZRq8mQxYZjWTy28iBZRS0z+Cv3Gr3TT34/TYGJ56vPZX9kVh8c7K1rrq4YFkFybimbjmWzbPMJaptZdbr2UAa/Hc0y25b0/EzD48dn98XRZK6zBplrM07oFcC2h6Zycb9gw7Y+IV7cc1Ev0gvK6vUZMCU5t4SoAHcGR/qQlNW8u5BOFa7pSMLCwvj66687ehoKxXnD2cGehtrBRviax8cf/v4AVTXSSH72xxkSnr6k2b1kvzMJQQC8/luiIWQz+Om1AFaRdKiLftH4lk9kTvuIKD+GdPNtcr/X1x03e75u8SSzC9C0fuYLxB7ODmz+5xQmvryBH+4c16DMc3c/N2o1SD1XRkyg5Y5fZ3JL6RPqSbS/G6sOpFFWWYOrU+O9LZQnr1AoWoyLo71Z60G9gdfz0/40qmpqm5RKqK6pJb2gjLum9OTivtKzLSyrJiG1gGWbTxjGNTeTpCUEejpzUR9jdlBheTXJOSXc//X+RqtPTcMzyS9eSk/d9+DlIi9qvm6O9fbp5u9G8ouXNqrjr/+MZyxU54IMZZ09V0p3f3fG9QygVoMFH+9gW1KOxfF6lCevUChaRfziSQCsOpDOnV/sYelVg1mxN5Utx3OorK5l+mubGR3jzwvzLFd8gtRsqdUgzMeVRZN7MOWVjXy3J4XvdE1S9LSHkQeYPTjUEHrJLa7g378e5XB6If3CvLh5vCy8WvL9Qb7ceQZNg8ER3mQUlnN5XBhzh5oveq66ZwJn8koRonUaQ71DPHF1tGd1QobFvgGbE7OpqtHoGejBqBh/Rkb58cfJPP44+Wejx1WevEKhaBOXDgol+cVLmTc0gneul01OnvzxEKdySli+40yjRVM/7ZeLh3GRPng4OxjaJJry5W2jDRr71uayQWEs08ki/HwgncO6at9nfz4MQFllDct3SAMPUhQNYFzPALO8e5AXonFtkIP2dnVkev9g1h7OtKh5sykxG1dHe2YPljH+fmFe9cZYQhl5hUJhNZrf76AAAApCSURBVCzF4dccarj71LGMIuIifQwGa2i3+uGM9ij11+Ngb8e0fsF4Ojuwvs5iatTDq+j7xGqL+zU3Z7+lzBsaQV5JpUGd0pTDafIOw9lBxuDvmxbLU5dZ7u9rijLyCoXCaggh+Nvobmbb9PK+1TW1fPbHacqralidkMHmxGySc0uICTSqYkb4unHjmO6G5wvGRZ2XOUcFGOdg6W7ig/nD2fHoRUT6udIv1IvhUU0v0LaGuAh5kTOtfq2uqeWpHw+xIzmPfqFG793b1ZGbxkUT6df4BUfF5BUKhVV57vKBlFfVMry7Lw/rWvEtjU8kMaOI1YcyeGylsSuVnZAVqqY8M2cAcZE+2NsJ5sRZ7BpqdRaMi2Lx1/u5bWKMmSEFuDwujPG9AnB2sGfD/ZOxtxOtjrs3hZerA072doZmKACH0goN3cP6htYP0QyK8GFrI8dURr4Z2NvbM3DgQKqqqnBwcGD+/Pnce++92NmpGyGFwhKvXDkYACHgoe8O8sZvxy2Oq9Ushz7mDW26ktOazBsawdgeAfi6O5oZ2FMvzDIz6NbO1a+LEAJ/DydDsxOAvSZdrvqGetbb5+3rhvLO9Q0fU1mpZuDq6sq+ffs4dOgQ8fHx/PLLLzz99NMdPS2Fwubxd29axreuoFhHEeLtgrODvUFz5i+Dw9rNY29qHt/uTqG8qoac4gqe+umw4bXeIfWNfFMoI99CgoKCWLZsGW+99ZbNt0tTKDoaS1rt147sxtge/gaZglAf2zDyeuztBPuemMbSqwZ3yPsXlcsc/VfWHDNIId86IZrkFy81k5doLp0qXJPxr39RccS6UsPOffsQ8sgjLdonJiaG2tpasrKyCA4ObnoHhaKL0t3fPL99XE9j3vzNH+/kt6NZhHq1T6ZKWzDVuTnfPD67H/M/3EH8kUySsqV0QVvCV53KyNsSyotXKJrG1Fg+Oqsv140yZt5M7x9MdnEFXq7KDJkyKTaQSweFsupAOqd18sTNVeC0RKf6dlvqcbcXJ0+exN7enqCg9m+YoFB0dl6YN5Al3x9kQmwA7iZ59FeP6MbVI7o1smfXJdLX/A7IklRCc1Ex+RaSnZ3NokWLuOuuuzpkUUah6GxcO7IbJ/81iz4hzavQVMDlQ4wKt246yeTW0qk8+Y6irKyMuLg4QwrlDTfcwOLFizt6WgpFp8HOTjlELaFPiBdf3DKK697/s83ZR8rIN4Oamob1nRUKhaI96KVr3HLPRQ13imoOysgrFAqFDRLo6Uzyi5e2+TgqJq9QKBQXMJ3CyHeWdMXOMk+FQtF1sHkj7+LiQm5urs0bUE3TyM3NxcXFtqr3FApF16bNMXkhxN3AXUA1sErTtAd125cANwM1wD2apq1pzfEjIiJISUkhOzu7rVNtd1xcXIiIOL/CSgqFQtEYbTLyQogpwBxgkKZpFUKIIN32fsA1QH8gDFgnhIjVNK3FaSqOjo5ER0e3ZZoKhULRZWlruOYO4EVN0yoANE3Tt1aZA3ypaVqFpmmngCRgZBvfS6FQKBQtpK1GPhaYIIT4UwixSQgxQrc9HDhrMi5Ft60eQojbhBC7hBC7OkNIRqFQKDoTTYZrhBDrgBALLz2q298XGA2MAL4WQsQAlsrbLK6capq2DFgGMHz4cNteXVUoFIpORpNGXtO0ixt6TQhxB/C9JlNfdgghaoEApOceaTI0Akhr6r12795dLIQ41uSsJd5AgRXGtHRsR43ryPduj88SAOR0wHur83d+j9nc89zcY15I340137t3g69omtbqH2AR8IzucSwyRCOQC677AWcgGjgJ2DfjeLta8N7LrDGmpWM7alxnmGMLP0uzzrWtf5YL6fy103t3yP90J/lurPbejX3PbU2h/BD4UAiRAFQC8zX5joeEEF8Dh5GplXdqrcisaYKfrDSmpWM7alxHvnd7fJbmYuuf5UI6f+11TGu+94X03bTHe9dD6K4CNoEQYpemacM7eh6K9ked666BOs/nh8a+Z1ureF3W0RNQnDfUue4aqPN8fmjwe7YpT16hUCgU1sXWPHmFQqFQWBFl5M8zQojiJl7fKIRQMcxOjjrPXYPOcJ47xMg39cUoLhzUue4aqPNsuyhPvgMQQkwWQvxs8vwtIcRNHTglRTugznPXwNbPc4cZeSGEhxDiNyHEHiHEQSHEHN32KCHEESHEe0KIQ0KItUII146ap6LtqHPdNVDn2TbpSE++HJiradpQYArwqhBCr3nTC3hb07T+QD5wRQfNUWEd1LnuGqjzbIN0ZCNvAfxLCDERqEWqVAbrXjulado+3ePdQNT5n167Uo35BfZCbyfVVc+1Os/qPHc4HenJXw8EAsM0TYsDMjF+ORUm42ro2ItRe3Aa6CeEcBZCeAMXdfSE2pmueq7VeVbnucPpyC/aG8jSNK1K12GqewfO5bwghHAAKjRNO6vT9jkAHAf2duzM2p0uda7VeVbnuWNnZs55N/L6Lwb4HPhJCLEL2AccPd9z6QD6AycANNkL98G6AzRNm3ye59RudOFzrc6zOs/otk8+z3Oqx3mXNRBCDAbe0zStS7UDFEIsAu4B7tU0bW1Hz+d80BXPtTrPXYPOdJ7Pq5HvTF+Mom2oc901UOfZ9lECZQqFQnEBoypeFQqF4gKmXY28ECJSCLFBV+12SAjxD912PyFEvBDiuO63r267EEK8IYRIEkIcEEIMNTnWfN3440KI+e05b0XLsfK5Xi2EyDctFVfYBtY6z0KIOCHE77pjHBBCXN2Rn+uCprk9BlvzA4QCQ3WPPYFEoB/wEvCwbvvDwL91j2cBvyKLKkYDf+q2+yH7xPoBvrrHvu05d/XTMeda99pFwGXAzx39udRP+5xnZE/oXrrHYUA64NPRn+9C/GlXT17TtHRN0/boHhcBR5BVcHOA/+mG/Q+4XPd4DvCJJvkD8BFChAKXAPGapuVpmnYOiAdmtOfcFS3DiucaTdN+A4rO5/wVzcNa51nTtERN047rjpMGZCELqRRW5rzF5IUQUcAQ4E8gWNO0dJB/NECQblg4cNZktxTdtoa2K2yQNp5rRSfBWudZCDEScEKXc66wLufFyAshPIDvkGlWhY0NtbBNa2S7wsawwrlWdAKsdZ51d2+fAgs0Tau17iwVcB6MvBDCEfnH8Lmmad/rNmfqb811v7N021OASJPdI4C0RrYrbAgrnWuFjWOt8yyE8AJWAY/pQjmKdqC9s2sE8AFwRNO0pSYv/QjoM2TmAz+YbL9RtyI/GijQ3fqtAaYLIXx1q/bTddsUNoIVz7XChrHWeRZCOAErkPH6b87T9Lsm7bmqC4xH3podQGpZ7EOutvsDvyHFfH4D/HTjBfA2MjZ3EBhucqyFQJLuZ0FHr1irn3Y911uAbKAM6Qle0tGfT/1Y9zwDfwOqTI6xD4jr6M93If6oileFQqG4gFEVrwqFQnEBo4y8QqFQXMAoI69QKBQXMMrIKxQKxQWMMvIKhUJxAaOMvEKhUFzAKCOvUCgUFzD/D/PofI5s8+8WAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randn(1000, 4),\n",
    "                      index=ts.index, columns=list('ABCD'))\n",
    "ts=df.cumsum()\n",
    "ts.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x13c379f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['A'].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x180d5bd0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(np.random.rand(10, 4), columns=['a', 'b', 'c', 'd'])\n",
    "df2.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x18222cd0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2.plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x181035b0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1813fa30>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2.plot.barh(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x18325970>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD4CAYAAAAD6PrjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAXfElEQVR4nO3dfZBddX3H8feHEFmiYEiyaMwmbtRAITYkumBmYodIxCJSAiW02Io7lLqI2IIPlaeO0o6ZaqvGMjbQVSiBIhgVSmqlbQJExUnAIDEmhIctpMk1kazhuZBA4Ns/7m+Pl3A3eze5557du5/XzJ0953d/55zvmcB+9nceFRGYmZkBHFB0AWZmNnQ4FMzMLONQMDOzjEPBzMwyDgUzM8scWHQB+2PChAnR3t5edBlmZsPKfffd95uIaK323bAOhfb2dtasWVN0GWZmw4qk/+3vOx8+MjOzTO6hIGmUpPsl/SDNT5V0j6RHJH1H0utS+0Fpvid93553bWZm9mqNGClcCGysmP8ysCgipgFPAuem9nOBJyPiHcCi1M/MzBoo13MKktqADwELgU9LEnAC8CepyxLgCuAqYH6aBvge8A1JCj+Hw8yGoJdeeolSqcTOnTuLLqVfLS0ttLW1MXr06JqXyftE89eBzwGHpPnxwFMRsTvNl4BJaXoSsAUgInZLejr1/03lCiV1AV0AU6ZMybV4M7P+lEolDjnkENrb2yn/vTu0RAQ7duygVCoxderUmpfL7fCRpFOA7RFxX2Vzla5Rw3e/bYjojoiOiOhoba16RZWZWe527tzJ+PHjh2QgAEhi/Pjxgx7J5DlSmAOcKulkoAU4lPLIYaykA9NooQ3YmvqXgMlASdKBwBuBJ3Ksz8xsvwzVQOizL/XlNlKIiEsjoi0i2oGzgDsj4k+Bu4AFqVsncFuaXpbmSd/f6fMJZmaNVcTNaxcDN0v6InA/cE1qvwa4QVIP5RHCWQXUZma2TxYtf7iu6/vUiUfUdX21akgoRMRKYGWafhQ4rkqfncCZjajHrCHu+rtCNrto9xmFbLeoX2JWX76j2cxsmDrttNN497vfzfTp0+nu7q7LOof1s4/MzEaya6+9lnHjxvHCCy9w7LHHcsYZZzB+/Pj9WqdDwcxsmLryyiu59dZbAdiyZQuPPPKIQ8HMbCRauXIlK1asYNWqVYwZM4a5c+fW5e5qn1MwMxuGnn76aQ477DDGjBnDgw8+yOrVq+uyXo8UzMzqoNFXX5100klcffXVzJgxgyOPPJLZs2fXZb0OBTOzYeiggw7i9ttvr/t6ffjIzMwyDgUzM8s4FMzMLONzCtbUFq9dXNi2P1HYls32nUcKZmaWcSiYmVnGh4/MzOqh3k/Ffd+lA3bZtGkTp5xyCuvXr6/bZj1SMDOzjEPBzGwY2717N52dncyYMYMFCxbw/PPP79f6HApmZsPYQw89RFdXF+vWrePQQw9l8eL9u+Iut1CQ1CLpXkm/kLRB0t+k9uskPSZpbfrMTO2SdKWkHknrJL0rr9rMzJrF5MmTmTNnDgAf+chHuPvuu/drfXmeaN4FnBARz0kaDdwtqe9BHX8VEd/bo/8HgWnp8x7gqvTTzMz6IWmv84OV20ghyp5Ls6PTJ/ayyHzg+rTcamCspIl51Wdm1gw2b97MqlWrALjpppt473vfu1/ry/WSVEmjgPuAdwD/FBH3SDofWCjp88AdwCURsQuYBGypWLyU2rbtsc4uoAtgypQpeZZvZla7Gi4hzcNRRx3FkiVLOO+885g2bRrnn3/+fq0v11CIiJeBmZLGArdKeidwKfBr4HVAN3Ax8LdAtTHPa0YWEdGdlqOjo2NvIw8zs6bW3t7OAw88UNd1NuTqo4h4ClgJnBQR29Ihol3AvwDHpW4lYHLFYm3A1kbUZ2ZmZXlefdSaRghIOhh4P/Bg33kClc+GnAb03Yq3DPhougppNvB0RGyrsmozM8tJnoePJgJL0nmFA4ClEfEDSXdKaqV8uGgt8PHU/4fAyUAP8DxwTo61mZlZFbmFQkSsA2ZVaT+hn/4BXJBXPWZmNjDf0WxmZhmHgpmZZfzobDOzOqj3W/4+MbOYd/d5pGBmZhmHgpnZMHX99dczY8YMjjnmGM4+++y6rNOHj8zMhqENGzawcOFCfvrTnzJhwgSeeOKJuqzXIwUzs2HozjvvZMGCBUyYMAGAcePG1WW9DgUzs2EoIvb7MdnVOBTMzIahefPmsXTpUnbs2AFQt8NHPqdgZlYHjb6EdPr06Vx++eUcf/zxjBo1ilmzZnHdddft93odCmZmw1RnZyednZ11XacPH5mZWcahYGZmGYeCmdk+Kj/ceejal/ocCmZm+6ClpYUdO3YM2WCICHbs2EFLS8uglvOJZjOzfdDW1kapVKK3t7foUvrV0tJCW1vboJZxKJiZ7YPRo0czderUosuoOx8+MjOzTG6hIKlF0r2SfiFpg6S/Se1TJd0j6RFJ35H0utR+UJrvSd+351WbmZlVl+dIYRdwQkQcA8wETpI0G/gysCgipgFPAuem/ucCT0bEO4BFqZ+ZmTVQbqEQZc+l2dHpE8AJwPdS+xLgtDQ9P82Tvp+nPJ72ZGZm/cr1nIKkUZLWAtuB5cD/AE9FxO7UpQRMStOTgC0A6fungfFV1tklaY2kNUP5rL+Z2XCUayhExMsRMRNoA44DjqrWLf2sNip4zQXAEdEdER0R0dHa2lq/Ys3MrDFXH0XEU8BKYDYwVlLfpbBtwNY0XQImA6Tv3wjU51mwZmZWk9zuU5DUCrwUEU9JOhh4P+WTx3cBC4CbgU7gtrTIsjS/Kn1/ZwzVWwXNarD4qXXFbPgNZxSzXWsKed68NhFYImkU5RHJ0oj4gaQHgJslfRG4H7gm9b8GuEFSD+URwlk51mZmZlXkFgoRsQ6YVaX9UcrnF/Zs3wmcmVc9ZmY2MN/RbGZmGT/7yMzqYtHyhwvb9qdOPKKwbTcbjxTMzCzjUDAzs4xDwczMMg4FMzPLOBTMzCzjUDAzs4xDwczMMg4FMzPLOBTMzCzjUDAzs4xDwczMMg4FMzPL+IF4Zk1m9ubuQra7ekpXIdu1+vJIwczMMg4FMzPL5BYKkiZLukvSRkkbJF2Y2q+Q9CtJa9Pn5IplLpXUI+khSb+fV21mZlZdnucUdgOfiYifSzoEuE/S8vTdooj4SmVnSUdTfi/zdOAtwApJR0TEyznWaGZmFXIbKUTEtoj4eZp+FtgITNrLIvOBmyNiV0Q8BvRQ5V3OZmaWn5pCQdI792cjktqBWcA9qemTktZJulbSYaltErClYrESVUJEUpekNZLW9Pb27k9ZZma2h1pHCldLulfSJySNHcwGJL0B+D5wUUQ8A1wFvB2YCWwDvtrXtcri8ZqGiO6I6IiIjtbW1sGUYmZmA6gpFCLivcCfApOBNZK+LenEgZaTNJpyINwYEbekdT0eES9HxCvAN/ntIaJSWn+fNmBrzXtiZmb7reZzChHxCPDXwMXA8cCVkh6U9IfV+ksScA2wMSK+VtE+saLb6cD6NL0MOEvSQZKmAtOAewezM2Zmtn9quvpI0gzgHOBDwHLgD9JVRW8BVgG3VFlsDnA28EtJa1PbZcCHJc2kfGhoE3AeQERskLQUeIDylUsX+MojM7PGqvWS1G9QPtRzWUS80NcYEVsl/XW1BSLibqqfJ/hhfxuJiIXAwhprMjOzOqs1FE4GXuj7y13SAUBLRDwfETfkVp2ZmTVUrecUVgAHV8yPSW1mZtZEag2Floh4rm8mTY/JpyQzMytKraHwf5Le1Tcj6d3AC3vpb2Zmw1Ct5xQuAr4rqe++gYnAH+dTkpmZFaWmUIiIn0n6HeBIylcUPRgRL+VamZmZNdxgnpJ6LNCelpkliYi4PpeqzMysELXevHYD5ecVrQX6bigLwKFgZtZEah0pdABHR8RrHlBnZmbNo9arj9YDb86zEDMzK16tI4UJwAOS7gV29TVGxKm5VGVmZoWoNRSuyLMIMzMbGmq9JPVHkt4KTIuIFZLGAKPyLc3MzBqt1tdxfgz4HvDPqWkS8G95FWVmZsWo9UTzBZTfj/AMZC/cOTyvoszMrBi1hsKuiHixb0bSgVR5f7KZmQ1vtZ5o/pGky4CD07uZPwH8e35lmdXJYz8pugKzYaXWkcIlQC/wS8qvz/wh5fc1m5lZE6kpFCLilYj4ZkScGREL0vReDx9JmizpLkkbJW2QdGFqHydpuaRH0s/DUrskXSmpR9K6ykd1m5lZY9R69dFjkh7d8zPAYruBz0TEUcBs4AJJR1MeddwREdOAO9I8wAeBaenTBVy1D/tjZmb7YTDPPurTApwJjNvbAhGxDdiWpp+VtJHypazzgbmp2xJgJXBxar8+jUBWSxoraWJaj5mZNUCtN6/t2KPp65LuBj5fy/KS2oFZwD3Am/p+0UfENkl9l7ZOArZULFZKba8KBUldlEcSTJkypZbNmxViy1PFvJxwViFbtWZR66OzK4/vH0B55HBIjcu+Afg+cFFEPCOp365V2l5z3iIiuoFugI6ODl8Wa2ZWR7UePvpqxfRuYBPwRwMtJGk05UC4MSJuSc2P9x0WkjQR2J7aS8DkisXbgK2YmVnD1Hr46H2DXbHKQ4JrgI0R8bWKr5YBncCX0s/bKto/Kelm4D3A0z6fYGbWWLUePvr03r7f45d+nznA2cAvJa1NbZdRDoOlks4FNlM+aQ3lex9OBnqA54FzaqnNzMzqZzBXHx1L+a95gD8AfsyrTwy/SkTcTfXzBADzqvQPys9YMjOzggzmJTvviohnASRdAXw3Iv48r8LMzKzxan3MxRTgxYr5F4H2uldjZmaFqnWkcANwr6RbKV8mejpwfW5VWdNZvHZx0SWYWQ1qvfpooaTbgd9LTedExP35lWVmZkWo9fARwBjgmYj4R6AkaWpONZmZWUFqfSDeFyg/n+jS1DQa+Ne8ijIzs2LUOlI4HTgV+D+AiNhKjY+5MDOz4aPWUHgx3UcQAJJen19JZmZWlFpDYamkfwbGSvoYsAL4Zn5lmZlZEWq9+ugr6d3MzwBHAp+PiOW5VmZmZg03YChIGgX8V0S8H3AQmJk1sQEPH0XEy8Dzkt7YgHrMzKxAtd7RvJPy006Xk65AAoiIv8ylKjMzK0StofAf6WNmZk1sr6EgaUpEbI6IJY0qyMzMijPQOYV/65uQ9P2cazEzs4INFAqVL8l5W56FmJlZ8QYKhehnekCSrpW0XdL6irYrJP1K0tr0Obniu0sl9Uh6SNLvD2ZbZmZWHwOdaD5G0jOURwwHp2nSfETEoXtZ9jrgG7z2vQuLIuIrlQ2SjgbOAqYDbwFWSDoiXQ5rZmYNstdQiIhR+7riiPixpPYau88Hbo6IXcBjknqA44BV+7p9MzMbvMG8T6FePilpXTq8dFhqmwRsqehTSm2vIalL0hpJa3p7e/Ou1cxsRGl0KFwFvB2YCWwDvpraVaVv1XMYEdEdER0R0dHa2ppPlWZmI1RDQyEiHo+IlyPiFcpPWT0ufVUCJld0bQO2NrI2MzNrcChImlgxezrQd2XSMuAsSQel13xOA+5tZG1mZlb7Yy4GTdJNwFxggqQS8AVgrqSZlA8NbQLOA4iIDZKWAg8Au4ELfOWRmVnj5RYKEfHhKs3X7KX/QmBhXvWYmdnAirj6yMzMhiiHgpmZZRwKZmaWcSiYmVnGoWBmZhmHgpmZZRwKZmaWcSiYmVnGoWBmZhmHgpmZZRwKZmaWcSiYmVnGoWBmZhmHgpmZZRwKZmaWcSiYmVnGoWBmZhmHgpmZZXILBUnXStouaX1F2zhJyyU9kn4eltol6UpJPZLWSXpXXnWZmVn/8hwpXAectEfbJcAdETENuCPNA3wQmJY+XcBVOdZlZmb9yC0UIuLHwBN7NM8HlqTpJcBpFe3XR9lqYKykiXnVZmZm1TX6nMKbImIbQPp5eGqfBGyp6FdKba8hqUvSGklrent7cy3WzGykGSonmlWlLap1jIjuiOiIiI7W1tacyzIzG1kaHQqP9x0WSj+3p/YSMLmiXxuwtcG1mZmNeI0OhWVAZ5ruBG6raP9ougppNvB032EmMzNrnAPzWrGkm4C5wARJJeALwJeApZLOBTYDZ6buPwROBnqA54Fz8qrLzMz6l1soRMSH+/lqXpW+AVyQVy1mZlab3ELBzIqx7ICeQrZ7+MBdbBgYKlcfmZnZEOBQMDOzjEPBzMwyDgUzM8s4FMzMLONQMDOzjEPBzMwyDgUzM8v45jUzG/YWLX+4kO1+6sQjCtlunhwKZlYXszd3F7bt1VO6Ctt2s/HhIzMzyzgUzMws41AwM7OMQ8HMzDIOBTMzyzgUzMwsU8glqZI2Ac8CLwO7I6JD0jjgO0A7sAn4o4h4soj6zMxGqiJHCu+LiJkR0ZHmLwHuiIhpwB1p3szMGmgo3bw2H5ibppcAK4GLiyrG6uyxnxRdgZnVoKiRQgD/Lek+SX23Ir4pIrYBpJ9VX/kqqUvSGklrent7G1SumdnIUNRIYU5EbJV0OLBc0oO1LhgR3UA3QEdHR+RVYDNavHZx0SWY2RBXyEghIramn9uBW4HjgMclTQRIP7cXUZuZ2UjW8FCQ9HpJh/RNAx8A1gPLgM7UrRO4rdG1mZmNdEUcPnoTcKukvu1/OyL+U9LPgKWSzgU2A2cWUJuZ2YjW8FCIiEeBY6q07wDmNboea25bnnqh6BLMhhXf0WxmZhmHgpmZZRwKZmaWcSiYmVnGoWBmZhmHgpmZZRwKZmaWcSiYmVnGoWBmZhmHgpmZZRwKZmaWcSiYmVnGoWBmZhmHgpmZZRwKZmaWKeodzWZmdTN7c3dBW/5KQdvNj0cKZmaW8UjBzOpi2QE9hW371FfeUch2Fy1/uJDtAnzqxCNyWe+QCwVJJwH/CIwCvhURXyq4pLpbvHZx0SWYmVU1pEJB0ijgn4ATgRLwM0nLIuKBYitrEo/9pLBN+13JZsPDkAoF4DigJyIeBZB0MzAfqHso+K91s+ZR1KGrwwvZar6GWihMArZUzJeA91R2kNQFdKXZ5yQ9VPH1BOA3uVY4NI3E/fY+jwxDfJ9vy2vFA+73p/dv/W/t74uhFgqq0havmonoBqpefyZpTUR05FHYUDYS99v7PDKMxH2GYvd7qF2SWgImV8y3AVsLqsXMbMQZaqHwM2CapKmSXgecBSwruCYzsxFjSB0+iojdkj4J/BflS1KvjYgNg1hFUbc1Fm0k7rf3eWQYifsMBe63ImLgXmZmNiIMtcNHZmZWIIeCmZllmjIUJP2FpIckbZD090XX0yiSPispJE0oupZGkPQPkh6UtE7SrZLGFl1TXiSdlP6b7pF0SdH15E3SZEl3SdqY/j++sOiaGkXSKEn3S/pBEdtvulCQ9D7Kd0HPiIjpNOOzbauQNJny40E2F11LAy0H3hkRM4CHgUsLricXFY9/+SBwNPBhSUcXW1XudgOfiYijgNnABSNgn/tcCGwsauNNFwrA+cCXImIXQERsL7ieRlkEfI49bvZrZhHx3xGxO82upnxfSzPKHv8SES8CfY9/aVoRsS0ifp6mn6X8S3JSsVXlT1Ib8CHgW0XV0IyhcATwe5LukfQjSccWXVDeJJ0K/CoiflF0LQX6M+D2oovISbXHvzT9L8g+ktqBWcA9xVbSEF+n/MfdK0UVMKTuU6iVpBXAm6t8dTnlfTqM8pDzWGCppLfFML/2doB9vgz4QGMraoy97XdE3Jb6XE75cMONjaytgQZ8/EuzkvQG4PvARRHxTNH15EnSKcD2iLhP0tyi6hiWoRAR7+/vO0nnA7ekELhX0iuUHy7V26j68tDfPkv6XWAq8AtJUD6E8nNJx0XErxtYYi729m8NIKkTOAWYN9yDfy9G5ONfJI2mHAg3RsQtRdfTAHOAUyWdDLQAh0r614j4SCOLaLqb1yR9HHhLRHxe0hHAHcCUJv6F8SqSNgEdETGEnyxZH+mFTF8Djo+IYR36eyPpQMon0ucBv6L8OJg/GeTd/sOKyn/hLAGeiIiLiq6n0dJI4bMRcUqjt92M5xSuBd4maT3lE3KdIyUQRqBvAIcAyyWtlXR10QXlIZ1M73v8y0ZgaTMHQjIHOBs4If3brk1/QVvOmm6kYGZm+64ZRwpmZraPHApmZpZxKJiZWcahYGZmGYeCmZllHApmZpZxKJiZWeb/ARWnkOgS41n9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df4 = pd.DataFrame({'a': np.random.randn(1000) + 1, 'b': np.random.randn(1000),\n",
    "                        'c': np.random.randn(1000) - 1}, columns=['a', 'b', 'c'])\n",
    "df4.plot.hist(alpha=0.5)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
